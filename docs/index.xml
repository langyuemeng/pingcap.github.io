<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on MySQL at Scale</title>
    <link>https://pingcap.com/docs/</link>
    <description>Recent content in Docs on MySQL at Scale</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://pingcap.com/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/TOC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/TOC/</guid>
      <description>TiDB Documentation Documentation List  Introduction Concepts  Architecture Key Features Horizontal Scalability MySQL Compatible Syntax Replicate from and to MySQL Distributed Transactions with Strong Consistency Cloud Native Architecture Minimize ETL with HTAP Fault Tolerance &amp;amp; Recovery with Raft Automatic Rebalancing Deployment and Orchestration with Ansible, Kubernetes, Docker JSON Support Spark Integration Read Historical Data Without Restoring from Backup Fast Import and Restore of Data Hybrid of Column and Row Storage SQL Plan Management Open Source Online Schema Changes  How-to  Get Started Start a Local Cluster  From Binary From Homebrew From DBdeployer In Kubernetes In Docker Compose  Explore SQL with TiDB Import Example Database Read Historical Data TiDB-Binlog Tutorial TiDB Data Migration Tutorial Deploy Hardware Recommendations From Binary Tarball  For Testing Environments For Production Environments  Orchestrated Deployment  Ansible Deployment (Recommended) Ansible Offline Deployment Docker Deployment Kubernetes Deployment Overview of Ansible Operations  Geographic Redundancy  Overview Configure Location Awareness  TiSpark Data Migration with Ansible Configure Time Zone Memory Control Secure Transport Layer Security (TLS)  Enable TLS For MySQL Clients Enable TLS Between TiDB Components  Generate Self-signed Certificates Monitor Overview Monitor a TiDB Cluster Migrate Overview Migrate from MySQL  Migrate the Full Data Migrate the Incremental Data  Migrate from Aurora Migrate from CSV Maintain Backup and Restore Identify Slow Queries Scale Scale a TiDB Cluster Scale using Ansible Upgrade Upgrade to TiDB 3.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/deployment/</guid>
      <description>Build for deployment Overview  Note:
The easiest way to deploy TiDB is to use TiDB Ansible, see Ansible Deployment.**
 Before you start, check the supported platforms and prerequisites first.
Building and installing TiDB components You can use the build script to build and install TiDB components in the bin directory.
You can use the update script to update all the TiDB components to the latest version.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/development/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/development/</guid>
      <description>Build For Development Overview If you want to develop the TiDB project, you can follow this guide.
Before you begin, check the supported platforms and prerequisites first.
Build TiKV  Get TiKV source code from GitHub
git clone https://github.com/pingcap/tikv.git cd tikv Run all unit tests:
make test Build in release mode:
make release  Build TiDB  Make sure the GOPATH environment is set correctly.
 Get the TiDB source code.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/requirements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/requirements/</guid>
      <description>Build requirements Supported platforms The following table lists TiDB support for common architectures and operating systems.
   Architecture Operating System Status     AMD64 Linux Ubuntu (14.04+) Stable   AMD64 Linux CentOS (7+) Stable   AMD64 Mac OSX Experimental    Prerequisites  Go 1.9+ Rust nightly version GCC 4.8+ with static library CMake 3.1+  The check requirement script can help you check prerequisites and install the missing ones automatically.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/v2.1/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/README/</guid>
      <description>TiDB Documentation Documentation List  About TiDB  TiDB Introduction TiDB Architecture  Quick Start  TiDB Quick Start Guide Basic SQL Statements Bikeshare Example Database  TiDB User Guide  TiDB Server Administration The TiDB Server The TiDB Command Options The TiDB Data Directory The TiDB System Database The TiDB System Variables The TiDB Specific System Variables The TiDB Server Logs The TiDB Access Privilege System TiDB User Account Management Use Encrypted Connections SQL Optimization and Execution SQL Optimization Process Understand the Query Execution Plan Introduction to Statistics Language Structure Literal Values Schema Object Names Keywords and Reserved Words User-Defined Variables Expression Syntax Comment Syntax Globalization Character Set Support Character Set Configuration Time Zone Support Data Types Numeric Types Date and Time Types String Types JSON Types The ENUM data type The SET Type Data Type Default Values Functions and Operators Function and Operator Reference Type Conversion in Expression Evaluation Operators Control Flow Functions String Functions Numeric Functions and Operators Date and Time Functions Bit Functions and Operators Cast Functions and Operators Encryption and Compression Functions Information Functions JSON Functions Aggregate (GROUP BY) Functions Miscellaneous Functions Precision Math SQL Statement Syntax Data Definition Statements Data Manipulation Statements Transactions Database Administration Statements Prepared SQL Statement Syntax Utility Statements TiDB SQL Syntax Diagram Generated Columns Connectors and APIs TiDB Transaction Isolation Levels Error Codes and Troubleshooting Compatibility with MySQL TiDB Memory Control Slow Query Log Advanced Usage Read Data From History Versions Garbage Collection (GC)  TiDB Operations Guide  Hardware and Software Requirements Deploy Ansible Deployment (Recommended) Offline Deployment Using Ansible Docker Deployment Docker Compose Deployment Cross-DC Deployment Solutions Kubernetes Deployment Configure Configuration Flags Configuration File Description Modify Component Configuration Using Ansible Enable TLS Authentication Generate Self-signed Certificates Cluster Topology Configuration Monitor Monitoring Framework Overview Key Monitoring Metrics  Overview TiDB PD TiKV  Monitor a TiDB Cluster Scale Scale a TiDB Cluster Scale Using Ansible Upgrade Upgrade the Component Version TiDB 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/v2.1/dev-guide/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/dev-guide/deployment/</guid>
      <description>Build for deployment Overview  Note:
The easiest way to deploy TiDB is to use TiDB Ansible, see Ansible Deployment.
 Before you start, check the supported platforms and prerequisites first.
Building and installing TiDB components You can use the build script to build and install TiDB components in the bin directory.
You can use the update script to update all the TiDB components to the latest version.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/v2.1/dev-guide/development/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/dev-guide/development/</guid>
      <description>Build For Development Overview If you want to develop the TiDB project, you can follow this guide.
Before you begin, check the supported platforms and prerequisites first.
Build TiKV  Get TiKV source code from GitHub
git clone https://github.com/pingcap/tikv.git cd tikv Run all unit tests:
make test Build in release mode:
make release  Build TiDB  Make sure the GOPATH environment is set correctly.
 Get the TiDB source code.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/v2.1/dev-guide/requirements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/dev-guide/requirements/</guid>
      <description>Build requirements Supported platforms The following table lists TiDB support for common architectures and operating systems.
   Architecture Operating System Status     AMD64 Linux Ubuntu (14.04+) Stable   AMD64 Linux CentOS (7+) Stable   AMD64 Mac OSX Experimental    Prerequisites  Go 1.9+ Rust nightly version GCC 4.8+ with static library CMake 3.1+  The check requirement script can help you check prerequisites and install the missing ones automatically.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/v2.1/op-guide/pd-api-v1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/pd-api-v1/</guid>
      <description>Placement Driver API API documentation$(document).ready(function() { $(&#39;.page-header pre code, .top-resource-description pre code, .modal-body pre code&#39;).each(function(i, block) { hljs.highlightBlock(block); }); $(&#39;[data-toggle]&#39;).click(function() { var selector = $(this).data(&#39;target&#39;) + &#39; pre code&#39;; $(selector).each(function(i, block) { hljs.highlightBlock(block); }); }); // open modal on hashes like #_action_get $(window).bind(&#39;hashchange&#39;, function(e) { var anchor_id = document.location.hash.substr(1); //strip # var element = $(&#39;#&#39; + anchor_id); // do we have such element + is it a modal? -- show it if (element.</description>
    </item>
    
    <item>
      <title>ADD COLUMN | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/add-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/add-column/</guid>
      <description>ADD COLUMN The ALTER TABLE.. ADD COLUMN statement adds a column to an existing table. This operation is online in TiDB, which means that neither reads or writes to the table are blocked by adding a column.
Synopsis AlterTableStmt:
AlterTableSpec:
ColumnKeywordOpt:
ColumnDef:
ColumnPosition:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 VALUES (NULL); Query OK, 1 row affected (0.</description>
    </item>
    
    <item>
      <title>ADD INDEX | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/add-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/add-index/</guid>
      <description>ADD INDEX The ALTER TABLE.. ADD INDEX statement adds an index to an existing table. This operation is online in TiDB, which means that neither reads or writes to the table are blocked by adding an index.
Synopsis AlterTableStmt:
AlterTableSpec:
ColumnKeywordOpt:
ColumnDef:
ColumnPosition:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.</description>
    </item>
    
    <item>
      <title>ADMIN | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/admin/</guid>
      <description>ADMIN This statement is a TiDB extension syntax, used to view the status of TiDB and check the data of tables in TiDB.
ADMIN SHOW DDL ADMIN SHOW DDL JOBS ADMIN SHOW DDL JOB QUERIES job_id [, job_id] ... ADMIN CANCEL DDL JOBS job_id [, job_id] ... ADMIN CHECK TABLE tbl_name [, tbl_name] ...  ADMIN SHOW DDL: To view the currently running DDL jobs. ADMIN SHOW DDL JOBS: To view all the results in the current DDL job queue (including tasks that are running and waiting to be run) and the last ten results in the completed DDL job queue.</description>
    </item>
    
    <item>
      <title>ALTER TABLE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/alter-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/alter-table/</guid>
      <description>ALTER TABLE This statement modifies an existing table to conform to a new table structure. The statement ALTER TABLE can be used to:
 ADD, DROP, or RENAME indexes ADD, DROP, MODIFY or CHANGE columns  Synopsis AlterTableStmt:
TableName:
AlterTableSpec:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.</description>
    </item>
    
    <item>
      <title>ALTER USER | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/alter-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/alter-user/</guid>
      <description>ALTER USER This statement changes an existing user inside the TiDB privilege system. In the MySQL privilege system, a user is the combination of a username and the host from which they are connecting from. Thus, it is possible to create a user &#39;newuser2&#39;@&#39;192.168.1.1&#39; who is only able to connect from the IP address 192.168.1.1. It is also possible to have two users have the same user-portion, and different permissions as they login from different hosts.</description>
    </item>
    
    <item>
      <title>ANALYZE TABLE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/analyze-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/analyze-table/</guid>
      <description>ANALYZE TABLE This statement updates the statistics that TiDB builds on tables and indexes. It is recommended to run ANALYZE TABLE after performing a large batch update or import of records, or when you notice that query execution plans are sub-optimal.
TiDB will also automatically update its statistics over time as it discovers that they are inconsistent with its own estimates.
Synopsis AnalyzeTableStmt:
TableNameList:
TableName:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Aggregate (GROUP BY) Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/aggregate-group-by-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/aggregate-group-by-functions/</guid>
      <description>Aggregate (GROUP BY) Functions This document describes details about the supported aggregate functions in TiDB.
Supported aggregate functions This section describes the supported MySQL group (aggregate) functions in TiDB.
   Name Description     COUNT() Return a count of the number of rows returned   COUNT(DISTINCT) Return the count of a number of different values   SUM() Return the sum   AVG() Return the average value of the argument   MAX() Return the maximum value   MIN() Return the minimum value   GROUP_CONCAT() Return a concatenated string     Unless otherwise stated, group functions ignore NULL values.</description>
    </item>
    
    <item>
      <title>Aggregate (GROUP BY) Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/aggregate-group-by-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/aggregate-group-by-functions/</guid>
      <description>Aggregate (GROUP BY) Functions This document describes details about the supported aggregate functions in TiDB.
Supported aggregate functions This section describes the supported MySQL group (aggregate) functions in TiDB.
   Name Description     COUNT() Return a count of the number of rows returned   COUNT(DISTINCT) Return the count of a number of different values   SUM() Return the sum   AVG() Return the average value of the argument   MAX() Return the maximum value   MIN() Return the minimum value   GROUP_CONCAT() Return a concatenated string     Unless otherwise stated, group functions ignore NULL values.</description>
    </item>
    
    <item>
      <title>BEGIN | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/begin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/begin/</guid>
      <description>BEGIN This statement starts a new transaction inside of TiDB. It is similar to the statements START TRANSACTION and SET autocommit=0.
In the absense of a BEGIN statement, every statement will by default autocommit in its own transaction. This behavior ensures MySQL compatibility.
Synopsis BeginTransactionStmt:
Examples mysql&amp;gt; CREATE TABLE t1 (a int NOT NULL PRIMARY KEY); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; BEGIN; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Backup and Restore</title>
      <link>https://pingcap.com/docs/dev/how-to/maintain/backup-and-restore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/maintain/backup-and-restore/</guid>
      <description>Backup and Restore About This document describes how to back up and restore the data of TiDB. Currently, this document only covers full backup and restoration.
Here we assume that the TiDB service information is as follows:
   Name Address Port User Password     TiDB 127.0.0.1 4000 root *    Use the following tools for data backup and restoration:
 mydumper: to export data from TiDB loader: to import data into TiDB  Download TiDB toolset (Linux) # Download the tool package.</description>
    </item>
    
    <item>
      <title>Backup and Restore</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/backup-restore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/backup-restore/</guid>
      <description>Backup and Restore About This document describes how to back up and restore the data of TiDB. Currently, this document only covers full backup and restoration.
Here we assume that the TiDB service information is as follows:
   Name Address Port User Password     TiDB 127.0.0.1 4000 root *    Use the following tools for data backup and restoration:
 mydumper: to export data from TiDB loader: to import data into TiDB  Download TiDB toolset (Linux) # Download the tool package.</description>
    </item>
    
    <item>
      <title>Bikeshare Example Database</title>
      <link>https://pingcap.com/docs/v2.1/bikeshare-example-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/bikeshare-example-database/</guid>
      <description>Bikeshare Example Database Examples used in the TiDB manual use System Data from Capital Bikeshare, released under the Capital Bikeshare Data License Agreement.
Download all data files The system data is available for download in .zip files organized per year. Downloading and extracting all files requires approximately 3GB of disk space. To download all files for years 2010-2017 using a bash script:
mkdir -p bikeshare-data &amp;amp;&amp;amp; cd bikeshare-data for YEAR in 2010 2011 2012 2013 2014 2015 2016 2017; do wget https://s3.</description>
    </item>
    
    <item>
      <title>Binlog Slave Client User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/binlog-slave-client/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/binlog-slave-client/</guid>
      <description>Binlog Slave Client User Guide Binlog Slave Client is used to consume TiDB slave binlog data from Kafka and output the data in a specific format. Currently, Drainer supports multiple kinds of down streaming, including MySQL, TiDB, file and Kafka. But sometimes users have customized requirements for outputting data to other formats, for example, Elasticsearch and Hive, so this feature is introduced.
Configure Drainer Modify the configuration file of Drainer and set it to output the data to Kafka:</description>
    </item>
    
    <item>
      <title>Binlog Slave Client User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/binlog-slave-client/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/binlog-slave-client/</guid>
      <description>Binlog Slave Client User Guide Binlog Slave Client is used to parse the binlog data and output the data in a specific format to Kafka. Currently, Drainer supports outputting data in multiple formats including MySQL, TiDB, TheFlash, and pb. But sometimes users have customized requirements for outputting data to other formats, for example, Elasticsearch and Hive, so this feature is introduced. After data is output to Kafka, the user writes code to read data from Kafka and then processes the data.</description>
    </item>
    
    <item>
      <title>Bit Functions and Operators</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/bit-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/bit-functions-and-operators/</guid>
      <description> Bit Functions and Operators In TiDB, the usage of bit functions and operators is similar to MySQL. See Bit Functions and Operators.
Bit functions and operators
   Name Description     BIT_COUNT() Return the number of bits that are set as 1   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   &amp;lt;&amp;lt; Left shift   &amp;gt;&amp;gt; Right shift    </description>
    </item>
    
    <item>
      <title>Bit Functions and Operators</title>
      <link>https://pingcap.com/docs/v2.1/sql/bit-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/bit-functions-and-operators/</guid>
      <description> Bit Functions and Operators In TiDB, the usage of bit functions and operators is similar to MySQL. See Bit Functions and Operators.
Bit functions and operators
   Name Description     BIT_COUNT() Return the number of bits that are set as 1   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   &amp;lt;&amp;lt; Left shift   &amp;gt;&amp;gt; Right shift    </description>
    </item>
    
    <item>
      <title>CHANGE COLUMN | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/change-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/change-column/</guid>
      <description>CHANGE COLUMN The ALTER TABLE.. CHANGE COLUMN statement changes a column on an existing table. The change can include both renaming the column, and changing the data type to a compatible type.
Synopsis AlterTableStmt:
AlterTableSpec:
ColumnKeywordOpt:
ColumnName:
ColumnDef:
ColumnPosition:
Examples mysql&amp;gt; CREATE TABLE t1 (id int not null primary key auto_increment, col1 INT); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (col1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.</description>
    </item>
    
    <item>
      <title>COMMIT | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/commit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/commit/</guid>
      <description>COMMIT This statement commits a transaction inside of the TIDB server.
In the absense of a BEGIN or START TRANSACTION statement, the default behavior of TiDB is that every statement will be its own transaction and autocommit. This behavior ensures MySQL compatibility.
Synopsis CommitStmt:
Examples mysql&amp;gt; CREATE TABLE t1 (a int NOT NULL PRIMARY KEY); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; START TRANSACTION; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>CREATE DATABASE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/create-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/create-database/</guid>
      <description>CREATE DATABASE This statement creates a new database in TiDB. The MySQL terminology for &amp;lsquo;database&amp;rsquo; most closely maps to a schema in the SQL standard.
Synopsis CreateDatabaseStmt:
DatabaseSym:
IfNotExists:
DBName:
DatabaseOptionListOpt:
Examples mysql&amp;gt; CREATE DATABASE mynewdatabase; Query OK, 0 rows affected (0.09 sec) mysql&amp;gt; USE mynewdatabase; Database changed mysql&amp;gt; CREATE TABLE t1 (a int); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; SHOW TABLES; +-------------------------+ | Tables_in_mynewdatabase | +-------------------------+ | t1 | +-------------------------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>CREATE INDEX | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/create-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/create-index/</guid>
      <description>CREATE INDEX This statement adds a new index to an existing table. It is an alternative syntax to ALTER TABLE .. ADD INDEX, and included for MySQL compatibility.
Synopsis CreateIndexStmt:
CreateIndexStmtUnique:
Identifier:
IndexTypeOpt:
TableName:
IndexColNameList:
IndexOptionList:
IndexOption:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.10 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.</description>
    </item>
    
    <item>
      <title>CREATE TABLE LIKE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/create-table-like/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/create-table-like/</guid>
      <description>CREATE TABLE LIKE This statement copies the definition of an existing table, without copying any data.
Synopsis CreateTableStmt:
LikeTableWithOrWithoutParen:
TableName:
Examples mysql&amp;gt; CREATE TABLE t1 (a INT NOT NULL); Query OK, 0 rows affected (0.13 sec) mysql&amp;gt; INSERT INTO t1 VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.02 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql&amp;gt; SELECT * FROM t1; +---+ | a | +---+ | 1 | | 2 | | 3 | | 4 | | 5 | +---+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>CREATE TABLE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/create-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/create-table/</guid>
      <description>CREATE TABLE This statement creates a new table in the currently selected database. See also CREATE TABLE AS, which is documented separately.
Synopsis CreateTableStmt:
IfNotExists:
TableName:
TableElementListOpt:
TableElement:
PartitionOpt:
ColumnDef:
ColumnName:
Type:
ColumnOptionListOpt:
TableOptionListOpt:
Examples mysql&amp;gt; CREATE TABLE t1 (a int); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; CREATE TABLE t2 LIKE t1; Query OK, 0 rows affected (0.10 sec) mysql&amp;gt; DESC t1; +-------+---------+------+------+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------+------+------+---------+-------+ | a | int(11) | YES | | NULL | | +-------+---------+------+------+---------+-------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>CREATE USER | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/create-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/create-user/</guid>
      <description>CREATE USER This statement creates a new user, specified with a password. In the MySQL privilege system, a user is the combination of a username and the host from which they are connecting from. Thus, it is possible to create a user &#39;newuser2&#39;@&#39;192.168.1.1&#39; who is only able to connect from the IP address 192.168.1.1. It is also possible to have two users have the same user-portion, and different permissions as they login from different hosts.</description>
    </item>
    
    <item>
      <title>CREATE VIEW | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/create-view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/create-view/</guid>
      <description>CREATE VIEW The CREATE VIEW statement saves a SELECT statement as a queryable object, similar to a table. Views in TiDB are non-materialized. This means that as a view is queried, TiDB will internally rewrite the query to combine the view definition with the SQL query.
Synopsis CreateViewStmt:
OrReplace:
ViewAlgorithm:
ViewDefiner:
ViewSQLSecurity:
ViewName:
ViewFieldList:
ViewCheckOption:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Cast Functions and Operators</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/cast-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/cast-functions-and-operators/</guid>
      <description>Cast Functions and Operators    Name Description     BINARY Cast a string to a binary string   CAST() Cast a value as a certain type   CONVERT() Cast a value as a certain type    Cast functions and operators enable conversion of values from one data type to another.
For details, see here.</description>
    </item>
    
    <item>
      <title>Cast Functions and Operators</title>
      <link>https://pingcap.com/docs/v2.1/sql/cast-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/cast-functions-and-operators/</guid>
      <description>Cast Functions and Operators    Name Description     BINARY Cast a string to a binary string   CAST() Cast a value as a certain type   CONVERT() Cast a value as a certain type    Cast functions and operators enable conversion of values from one data type to another.
For details, see here.</description>
    </item>
    
    <item>
      <title>Character Set Configuration</title>
      <link>https://pingcap.com/docs/v2.1/sql/character-set-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/character-set-configuration/</guid>
      <description>Character Set Configuration Currently, TiDB only supports the utf8 character set, which is the equivalent to utf8mb4 in MySQL. Since MySQL 5.7 defaults to latin1, this difference is documented under default differences between TiDB and MySQL.
For more information, see Character Set Configuration in MySQL.</description>
    </item>
    
    <item>
      <title>Character Set Support</title>
      <link>https://pingcap.com/docs/dev/reference/sql/character-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/character-set/</guid>
      <description>Character Set Support A character set is a set of symbols and encodings. A collation is a set of rules for comparing characters in a character set.
Currently, TiDB supports the following character sets:
mysql&amp;gt; SHOW CHARACTER SET; +---------|---------------|-------------------|--------+ | Charset | Description | Default collation | Maxlen | +---------|---------------|-------------------|--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------|---------------|-------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>Character Set Support</title>
      <link>https://pingcap.com/docs/v2.1/sql/character-set-support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/character-set-support/</guid>
      <description>Character Set Support A character set is a set of symbols and encodings. A collation is a set of rules for comparing characters in a character set.
Currently, TiDB supports the following character sets:
mysql&amp;gt; SHOW CHARACTER SET; +---------|---------------|-------------------|--------+ | Charset | Description | Default collation | Maxlen | +---------|---------------|-------------------|--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------|---------------|-------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>Cluster Topology Configuration</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/geographic-redundancy/location-awareness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/geographic-redundancy/location-awareness/</guid>
      <description>Cluster Topology Configuration Overview PD schedules according to the topology of the TiKV cluster to maximize the TiKV&amp;rsquo;s capability for disaster recovery.
Before you begin, see Deploy TiDB Using Ansible (Recommended) and Deploy TiDB Using Docker.
TiKV reports the topological information TiKV reports the topological information to PD according to the startup parameter or configuration of TiKV.
Assuming that the topology has three structures: zone &amp;gt; rack &amp;gt; host, use lables to specify the following information:</description>
    </item>
    
    <item>
      <title>Cluster Topology Configuration</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/location-awareness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/location-awareness/</guid>
      <description>Cluster Topology Configuration Overview PD schedules according to the topology of the TiKV cluster to maximize the TiKV&amp;rsquo;s capability for disaster recovery.
Before you begin, see Deploy TiDB Using Ansible (Recommended) and Deploy TiDB Using Docker.
TiKV reports the topological information TiKV reports the topological information to PD according to the startup parameter or configuration of TiKV.
Assuming that the topology has three structures: zone &amp;gt; rack &amp;gt; host, use lables to specify the following information:</description>
    </item>
    
    <item>
      <title>Comment Syntax</title>
      <link>https://pingcap.com/docs/dev/reference/sql/language-structure/comment-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/language-structure/comment-syntax/</guid>
      <description>Comment Syntax TiDB supports three comment styles:
 Use # to comment a line. Use -- to comment a line, and this style requires at least one whitespace after --. Use /* */ to comment a block or multiple lines.  Example:
mysql&amp;gt; SELECT 1+1; # This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; SELECT 1+1; -- This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>Comment Syntax</title>
      <link>https://pingcap.com/docs/v2.1/sql/comment-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/comment-syntax/</guid>
      <description>Comment Syntax TiDB supports three comment styles:
 Use # to comment a line. Use -- to comment a line, and this style requires at least one whitespace after --. Use /* */ to comment a block or multiple lines.  Example:
mysql&amp;gt; SELECT 1+1; # This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; SELECT 1+1; -- This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>Compatibility with MySQL</title>
      <link>https://pingcap.com/docs/dev/reference/mysql-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/mysql-compatibility/</guid>
      <description>Compatibility with MySQL TiDB supports both the MySQL wire protocol and the majority of its syntax. This means that you can use your existing MySQL connectors and clients, and your existing applications can often be migrated to TiDB without changing any application code.
Currently TiDB Server advertises itself as MySQL 5.7 and works with most MySQL database tools such as PHPMyAdmin, Navicat, MySQL Workbench, mysqldump, and mydumper/myloader.
 Note:</description>
    </item>
    
    <item>
      <title>Compatibility with MySQL</title>
      <link>https://pingcap.com/docs/v2.1/sql/mysql-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/mysql-compatibility/</guid>
      <description>Compatibility with MySQL TiDB supports the majority of the MySQL 5.7 syntax, including cross-row transactions, JOIN, subquery, and so on. You can connect to TiDB directly using your own MySQL client. If your existing business is developed based on MySQL, you can replace MySQL with TiDB to power your application without changing a single line of code in most cases.
TiDB is compatible with most of the MySQL database management &amp;amp; administration tools such as PHPMyAdmin, Navicat, MySQL Workbench, and so on.</description>
    </item>
    
    <item>
      <title>Configuration Flags</title>
      <link>https://pingcap.com/docs/dev/reference/configuration/tidb-server/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/configuration/tidb-server/configuration/</guid>
      <description>Configuration Flags TiDB is configurable using command-line flags and environment variables. The default TiDB ports are 4000 for client requests and 10080 for status report.
--advertise-address  The IP address on which to advertise the apiserver to the TiDB server Default: &amp;ldquo;&amp;rdquo; This address must be reachable by the rest of the TiDB cluster and the user.  --binlog-socket  The TiDB services use the unix socket file for internal connections, such as the Pump service Default: &amp;ldquo;&amp;rdquo; You can use &amp;ldquo;/tmp/pump.</description>
    </item>
    
    <item>
      <title>Configuration Flags</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/configuration/</guid>
      <description>Configuration Flags TiDB, TiKV and PD are configurable using command-line flags and environment variables.
TiDB The default TiDB ports are 4000 for client requests and 10080 for status report.
--advertise-address  The IP address on which to advertise the apiserver to the TiDB server Default: &amp;ldquo;&amp;rdquo; This address must be reachable by the rest of the TiDB cluster and the user.  --binlog-socket  The TiDB services use the unix socket file for internal connections, such as the Pump service Default: &amp;ldquo;&amp;rdquo; You can use &amp;ldquo;/tmp/pump.</description>
    </item>
    
    <item>
      <title>Connect with us</title>
      <link>https://pingcap.com/docs/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/community/</guid>
      <description> Connect with us  Twitter: @PingCAP Reddit: https://www.reddit.com/r/TiDB/ Stack Overflow: https://stackoverflow.com/questions/tagged/tidb Mailing list: Google Group  </description>
    </item>
    
    <item>
      <title>Connect with us</title>
      <link>https://pingcap.com/docs/v2.1/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/community/</guid>
      <description> Connect with us  Twitter: @PingCAP Reddit: https://www.reddit.com/r/TiDB/ Stack Overflow: https://stackoverflow.com/questions/tagged/tidb Mailing list: Google Group  </description>
    </item>
    
    <item>
      <title>Connectors and APIs</title>
      <link>https://pingcap.com/docs/dev/reference/supported-clients/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/supported-clients/</guid>
      <description>Connectors and APIs Database Connectors provide connectivity to the TiDB server for client programs. APIs provide low-level access to the MySQL protocol and MySQL resources. Both Connectors and the APIs enable you to connect and execute MySQL statements from another language or environment, including ODBC, Java (JDBC), Perl, Python, PHP, Ruby and C.
TiDB is compatible with all Connectors and APIs of MySQL (5.6, 5.7), including:
 MySQL Connector/C MySQL Connector/C++ MySQL Connector/J MySQL Connector/Net MySQL Connector/ODBC MySQL Connector/Python MySQL C API MySQL PHP API MySQL Perl API MySQL Python API MySQL Ruby APIs MySQL Tcl API MySQL Eiffel Wrapper Mysql Go API  Connect to TiDB using MySQL Connectors Oracle develops the following APIs and TiDB is compatible with all of them:</description>
    </item>
    
    <item>
      <title>Connectors and APIs</title>
      <link>https://pingcap.com/docs/v2.1/sql/connection-and-APIs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/connection-and-APIs/</guid>
      <description>Connectors and APIs Database Connectors provide connectivity to the TiDB server for client programs. APIs provide low-level access to the MySQL protocol and MySQL resources. Both Connectors and the APIs enable you to connect and execute MySQL statements from another language or environment, including ODBC, Java (JDBC), Perl, Python, PHP, Ruby and C.
TiDB is compatible with all Connectors and APIs of MySQL (5.6, 5.7), including:
 MySQL Connector/C MySQL Connector/C++ MySQL Connector/J MySQL Connector/Net MySQL Connector/ODBC MySQL Connector/Python MySQL C API MySQL PHP API MySQL Perl API MySQL Python API MySQL Ruby APIs MySQL Tcl API MySQL Eiffel Wrapper Mysql Go API  Connect to TiDB using MySQL Connectors Oracle develops the following APIs and TiDB is compatible with all of them:</description>
    </item>
    
    <item>
      <title>Constraints</title>
      <link>https://pingcap.com/docs/dev/reference/sql/constraints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/constraints/</guid>
      <description>Constraints Overview TiDB supports the same basic constraints supported in MySQL with the follwing exceptions:
 PRIMARY KEY and UNIQUE constraints are checked lazily by default. By batching checks until when the transaction commits, TiDB is able to reduce network communication. This behavior can be changed by setting tidb_constraint_check_in_place to TRUE.
 FOREIGN KEY constraints are not currently enforced by DML.
  Foreign Key TiDB currently only supports FOREIGN KEY creation in DDL commands.</description>
    </item>
    
    <item>
      <title>Contribute</title>
      <link>https://pingcap.com/docs/contribute/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/contribute/</guid>
      <description>Contribute Contribute to TiDB We recommend starting with an existing issue with the help-wanted label. These issues are well suited for new contributors.
If a PR (Pull Request) submitted to the TiDB/TiKV/TiSpark/PD/Docs/Docs-cn projects by you is approved and merged, then you become a TiDB Contributor.
Before submitting a pull request, sign the CLA.
If you want to work on a new idea of relatively small scope:
 Submit an issue describing your proposed change to the repo in question.</description>
    </item>
    
    <item>
      <title>Control Flow Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/control-flow-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/control-flow-functions/</guid>
      <description> Control Flow Functions    Name Description     CASE Case operator   IF() If/else construct   IFNULL() Null if/else construct   NULLIF() Return NULL if expr1 = expr2    </description>
    </item>
    
    <item>
      <title>Control Flow Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/control-flow-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/control-flow-functions/</guid>
      <description> Control Flow Functions    Name Description     CASE Case operator   IF() If/else construct   IFNULL() Null if/else construct   NULLIF() Return NULL if expr1 = expr2    </description>
    </item>
    
    <item>
      <title>Cross-DC Deployment Solutions</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/geographic-redundancy/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/geographic-redundancy/overview/</guid>
      <description>Cross-DC Deployment Solutions As a NewSQL database, TiDB excels in the best features of the traditional relational database and the scalability of the NoSQL database and is of course, highly available across data centers (hereinafter referred to as DC). This document is to introduce different deployment solutions in cross-DC environment.
3-DC Deployment Solution TiDB, TiKV and PD are distributed among 3 DCs, which is the most common deployment solution with the highest availability.</description>
    </item>
    
    <item>
      <title>Cross-DC Deployment Solutions</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/cross-dc-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/cross-dc-deployment/</guid>
      <description>Cross-DC Deployment Solutions As a NewSQL database, TiDB excels in the best features of the traditional relational database and the scalability of the NoSQL database and is of course, highly available across data centers (hereinafter referred to as DC). This document is to introduce different deployment solutions in cross-DC environment.
3-DC Deployment Solution TiDB, TiKV and PD are distributed among 3 DCs, which is the most common deployment solution with the highest availability.</description>
    </item>
    
    <item>
      <title>DEALLOCATE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/deallocate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/deallocate/</guid>
      <description>DEALLOCATE The DEALLOCATE statement provides an SQL interface to server-side prepared statements.
Synopsis DeallocateStmt:
DeallocateSym:
Identifier:
Examples mysql&amp;gt; PREPARE mystmt FROM &amp;#39;SELECT ? as num FROM DUAL&amp;#39;; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; SET @number = 5; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; EXECUTE mystmt USING @number; +------+ | num | +------+ | 5 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; DEALLOCATE PREPARE mystmt; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>DELETE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/delete/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/delete/</guid>
      <description>DELETE The DELETE statement removes rows from a specified table.
Synopsis DeleteFromStmt:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.03 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql&amp;gt; SELECT * FROM t1; +----+----+ | id | c1 | +----+----+ | 1 | 1 | | 2 | 2 | | 3 | 3 | | 4 | 4 | | 5 | 5 | +----+----+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>DESC | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/desc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/desc/</guid>
      <description>DESC This statement is an alias to EXPLAIN. It is included for compatibility with MySQL.</description>
    </item>
    
    <item>
      <title>DESCRIBE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/describe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/describe/</guid>
      <description>DESCRIBE This statement is an alias to EXPLAIN. It is included for compatibility with MySQL.</description>
    </item>
    
    <item>
      <title>DM Benchmark Report</title>
      <link>https://pingcap.com/docs/benchmark/dm-v1-alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/dm-v1-alpha/</guid>
      <description>DM Benchmark Report This DM benchmark report describes the test purpose, environment, scenario, and result.
Test purpose The purpose of this test is to test the performance of DM incremental replication.
 Note:
The results of the testing might vary based on different environmental dependencies.
 Test environment Machine information System information:
   Machine IP Operation system Kernel version File system type     192.168.0.6 CentOS Linux release 7.</description>
    </item>
    
    <item>
      <title>DM-worker Introduction</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/dm-worker-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/dm-worker-intro/</guid>
      <description>DM-worker Introduction DM-worker is a tool used to synchronize data from MySQL/MariaDB to TiDB.
It has the following features:
 Acts as a slave of any MySQL or MariaDB instance Reads the binlog events from MySQL/MariaDB and persists them to the local storage A single DM-worker supports synchronizing the data of one MySQL/MariaDB instance to multiple TiDB instances Multiple DM-workers support synchronizing the data of multiple MySQL/MariaDB instances to one TiDB instance  DM-worker processing unit A DM-worker task contains multiple logic units, including relay log, Dumper, Loader, and binlog replication.</description>
    </item>
    
    <item>
      <title>DM-worker Introduction</title>
      <link>https://pingcap.com/docs/v2.1/tools/dm-worker-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/dm-worker-intro/</guid>
      <description>DM-worker Introduction DM-worker is a tool used to synchronize data from MySQL/MariaDB to TiDB.
It has the following features:
 Acts as a slave of any MySQL or MariaDB server Reads the binlog events from MySQL/MariaDB and persists them to the local storage A single DM-worker supports synchronizing the data of one MySQL/MariaDB instance to multiple TiDB instances Multiple DM-workers support synchronizing the data of multiple MySQL/MariaDB instances to one TiDB instance  DM-worker processing unit A DM-worker task contains multiple logic units, including relay log, Dumper, Loader, and binlog replication.</description>
    </item>
    
    <item>
      <title>DO | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/do/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/do/</guid>
      <description>DO This statement executes an expression, without returning a result. In MySQL, a common use-case is to excecute stored programs without needing to handle the result. Since TiDB does not provide stored routines, this function has a more limited use.
Synopsis DoStmt:
ExpressionList:
Expression:
Examples mysql&amp;gt; SELECT SLEEP(5); +----------+ | SLEEP(5) | +----------+ | 0 | +----------+ 1 row in set (5.00 sec) mysql&amp;gt; DO SLEEP(5); Query OK, 0 rows affected (5.</description>
    </item>
    
    <item>
      <title>DROP COLUMN | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/drop-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/drop-column/</guid>
      <description>DROP COLUMN This statement drops a column from a specified table. DROP COLUMN is online in TiDB, which means that it does not block read or write operations.
Synopsis AlterTableStmt:
AlterTableSpec:
ColumnKeywordOpt:
ColumnName:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, col1 INT NOT NULL, col2 INT NOT NULL); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; INSERT INTO t1 (col1,col2) VALUES (1,1),(2,2),(3,3),(4,4),(5,5); Query OK, 5 rows affected (0.</description>
    </item>
    
    <item>
      <title>DROP DATABASE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/drop-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/drop-database/</guid>
      <description>DROP DATABASE The DROP DATABASE statement permanently removes a specified database schema, and all of the tables and views that were created inside. User privileges that are associated with the dropped database remain unaffected.
Synopsis DropDatabaseStmt:
DatabaseSym:
IfExists:
DBName:
Examples mysql&amp;gt; SHOW DATABASES; +--------------------+ | Database | +--------------------+ | INFORMATION_SCHEMA | | PERFORMANCE_SCHEMA | | mysql | | test | +--------------------+ 4 rows in set (0.00 sec) mysql&amp;gt; DROP DATABASE test; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>DROP INDEX | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/drop-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/drop-index/</guid>
      <description>DROP INDEX This statement removes an index from a specified table, marking space as free in TiKV.
Synopsis AlterTableStmt:
AlterTableSpec:
KeyOrIndex:
Identifier:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.10 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.02 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql&amp;gt; EXPLAIN SELECT * FROM t1 WHERE c1 = 3; +---------------------+----------+------+-------------------------------------------------------------+ | id | count | task | operator info | +---------------------+----------+------+-------------------------------------------------------------+ | TableReader_7 | 10.</description>
    </item>
    
    <item>
      <title>DROP TABLE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/drop-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/drop-table/</guid>
      <description>DROP TABLE This statement drops a table from the currently selected database. An error is returned if the table does not exist, unless the IF EXISTS modifier is used.
By design DROP TABLE will also drop views, as they share the same namespace as tables.
Synopsis DropTableStmt:
TableOrTables:
TableNameList:
Examples mysql&amp;gt; CREATE TABLE t1 (a INT); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; DROP TABLE t1; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>DROP USER | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/drop-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/drop-user/</guid>
      <description>DROP USER This statement removes a user from the TiDB system database. The optional keyword IF EXISTS can be used to silence an error if the user does not exist.
Synopsis DropUserStmt:
Username:
Examples mysql&amp;gt; DROP USER idontexist; ERROR 1396 (HY000): Operation DROP USER failed for idontexist@% mysql&amp;gt; DROP USER IF EXISTS idontexist; Query OK, 0 rows affected (0.01 sec) mysql&amp;gt; CREATE USER newuser IDENTIFIED BY &amp;#39;mypassword&amp;#39;; Query OK, 1 row affected (0.</description>
    </item>
    
    <item>
      <title>DROP VIEW | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/drop-view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/drop-view/</guid>
      <description>DROP VIEW This statement drops an view object from the currently selected database. It does not effect any base tables that a view references.
Synopsis DropViewStmt:
TableNameList:
TableName:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.03 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql&amp;gt; CREATE VIEW v1 AS SELECT * FROM t1 WHERE c1 &amp;gt; 2; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Data Definition Statements</title>
      <link>https://pingcap.com/docs/v2.1/sql/ddl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/ddl/</guid>
      <description>Data Definition Statements DDL (Data Definition Language) is used to define the database structure or schema, and to manage the database and statements of various objects in the database.
Currently, TiDB has implemented concurrent execution of the ADD INDEX operation and the GENERAL operation (namely the non-ADD INDEX DDL operation) across different tables. In this case, two workers process the ADD INDEX operation and a GENERAL operation respectively. When the operation requests are on the same table, workers execute these operations in the order of receiving the DDL operation requests.</description>
    </item>
    
    <item>
      <title>Data Migration Cluster Operations</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/cluster-operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/cluster-operations/</guid>
      <description>Data Migration Cluster Operations This document introduces the DM cluster operations and considerations when you administer a DM cluster using DM-Ansible.
Start a cluster Run the following command to start all the components (including DM-master, DM-worker and the monitoring component) of the whole DM cluster:
$ ansible-playbook start.yml Stop a cluster Run the following command to stop all the components (including DM-master, DM-worker and the monitoring component) of the whole DM cluster:</description>
    </item>
    
    <item>
      <title>Data Migration Cluster Operations</title>
      <link>https://pingcap.com/docs/v2.1/tools/data-migration-cluster-operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/data-migration-cluster-operations/</guid>
      <description>Data Migration Cluster Operations This document introduces the DM cluster operations and considerations when you administer a DM cluster using DM-Ansible.
Start a cluster Run the following command to start all the components (including DM-master, DM-worker and the monitoring component) of the whole DM cluster:
$ ansible-playbook start.yml Stop a cluster Run the following command to stop all the components (including DM-master, DM-worker and the monitoring component) of the whole DM cluster:</description>
    </item>
    
    <item>
      <title>Data Migration Configuration File Overview</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/configure/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/configure/overview/</guid>
      <description>Data Migration Configuration File Overview This document gives an overview of configuration files of DM (Data Migration).
DM process configuration files  inventory.ini: The configuration file of deploying DM using DM-Ansible. You need to edit it based on your machine topology. For details, see Edit the inventory.ini file to orchestrate the DM cluster. dm-master.toml: The configuration file of running the DM-master process, including the topology information of the DM cluster and the corresponding relationship between the MySQL instance and DM-worker (must be one-to-one relationship).</description>
    </item>
    
    <item>
      <title>Data Migration Configuration File Overview</title>
      <link>https://pingcap.com/docs/v2.1/tools/dm-configuration-file-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/dm-configuration-file-overview/</guid>
      <description>Data Migration Configuration File Overview This document gives an overview of configuration files of DM (Data Migration).
DM process configuration files  inventory.ini: The configuration file of deploying DM using DM-Ansible. You need to edit it based on your machine topology. For details, see Edit the inventory.ini file to orchestrate the DM cluster. dm-master.toml: The configuration file of running the DM-master process, including the topology information of the DM cluster and the corresponding relationship between the MySQL instance and DM-worker (must be one-to-one relationship).</description>
    </item>
    
    <item>
      <title>Data Migration Monitoring Metrics</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/monitor/</guid>
      <description>Data Migration Monitoring Metrics If your DM cluster is deployed using DM-Ansible, the monitoring system is also deployed at the same time. This document describes the monitoring metrics provided by DM-worker.
 Note:
Currently, DM-master does not provide monitoring metrics yet.
 Task In the Grafana dashboard, the default name of DM is DM-task.
overview overview contains some monitoring metrics of all the DM-worker instances in the currently selected task.</description>
    </item>
    
    <item>
      <title>Data Migration Monitoring Metrics</title>
      <link>https://pingcap.com/docs/v2.1/tools/dm-monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/dm-monitor/</guid>
      <description>Data Migration Monitoring Metrics If your DM cluster is deployed using DM-Ansible, the monitoring system is also deployed at the same time. This document describes the monitoring metrics provided by DM-worker.
 Note:
Currently, DM-master does not provide monitoring metrics yet.
 Task    Metric name Description Alert     task state the state of subtasks 10 minutes after subtasks become paused    Relay log    Metric name Description Alert     storage capacity The storage capacity of the disk occupied by the relay log N/A   storage remain The remaining storage capacity of the disk occupied by the relay log An alert is needed once the value is smaller than 10G.</description>
    </item>
    
    <item>
      <title>Data Migration Overview</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/overview/</guid>
      <description>Data Migration Overview DM (Data Migration) is an integrated data synchronization task management platform that supports the full data migration and the incremental data migration from MySQL/MariaDB into TiDB. It can help to reduce the operations cost and simplify the troubleshooting process.
Architecture The Data Migration tool includes three components: DM-master, DM-worker, and dmctl.
DM-master DM-master manages and schedules the operation of data synchronization tasks.
 Storing the topology information of the DM cluster Monitoring the running state of DM-worker processes Monitoring the running state of data synchronization tasks Providing a unified portal for the management of data synchronization tasks Coordinating the DDL synchronization of sharded tables in each instance under the sharding scenario  DM-worker DM-worker executes specific data synchronization tasks.</description>
    </item>
    
    <item>
      <title>Data Migration Overview</title>
      <link>https://pingcap.com/docs/v2.1/tools/data-migration-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/data-migration-overview/</guid>
      <description>Data Migration Overview Data Migration (DM) is an integrated data synchronization task management platform that supports the full data migration and the incremental data migration from MySQL/MariaDB into TiDB. It can help to reduce the operations cost and simplify the troubleshooting process.
Architecture The Data Migration tool includes three components: DM-master, DM-worker, and dmctl.
DM-master DM-master manages and schedules the operation of data synchronization tasks.
 Storing the topology information of the DM cluster Monitoring the running state of DM-worker processes Monitoring the running state of data synchronization tasks Providing a unified portal for the management of data synchronization tasks Coordinating the DDL synchronization of sharded tables in each instance under the sharding scenario  DM-worker DM-worker executes specific data synchronization tasks.</description>
    </item>
    
    <item>
      <title>Data Migration Query Status</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/query-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/query-status/</guid>
      <description>Data Migration Query Status This document introduces the query result and subtask status of Data Migration (DM).
Query result  query-status { &amp;#34;result&amp;#34;: true, # Whether the query is successful. &amp;#34;msg&amp;#34;: &amp;#34;&amp;#34;, # Describes the cause for the unsuccessful query. &amp;#34;workers&amp;#34;: [ # DM-worker list. { &amp;#34;result&amp;#34;: true, &amp;#34;worker&amp;#34;: &amp;#34;172.17.0.2:10081&amp;#34;, # The `host:port` information of the DM-worker. &amp;#34;msg&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;subTaskStatus&amp;#34;: [ # The information of all the subtasks of the DM-worker.</description>
    </item>
    
    <item>
      <title>Data Migration Relay Log</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/relay-log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/relay-log/</guid>
      <description>Data Migration Relay Log The Data Migration (DM) relay log consists of a set of numbered files containing events that describe database changes, and an index file that contains the names of all used relay log files.
After DM-worker is started, it automatically synchronizes the upstream binlog to the local configuration directory (the default synchronization directory is &amp;lt;deploy_dir&amp;gt;/relay_log if DM is deployed using DM-Ansible). When DM-worker is running, it synchronizes the upstream binlog to the local file in real time.</description>
    </item>
    
    <item>
      <title>Data Migration Shard Merge Scenario</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/usage-scenarios/shard-merge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/usage-scenarios/shard-merge/</guid>
      <description>Data Migration Shard Merge Scenario This document shows how to use Data Migration (DM) in the shard merge scenario where the sharded schemas and sharded tables data of three upstream MySQL instances need to be synchronized to a downstream TiDB cluster.
Upstream instances Assume that the upstream schemas are as follows:
 Instance 1
   Schema Tables     user information, log_north, log_bak   store_01 sale_01, sale_02   store_02 sale_01, sale_02    Instance 2</description>
    </item>
    
    <item>
      <title>Data Migration Sharding Solution</title>
      <link>https://pingcap.com/docs/v2.1/tools/dm-sharding-solution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/dm-sharding-solution/</guid>
      <description>Data Migration Sharding Solution This document introduces the sharding solution provided by Data Migration, its background, design details, and sharding DDL restrictions.
Data Migration supports merging the data of multiple sharded MySQL instances and tables into a single TiDB instance. Generally, Data Migration does it automatically and you need to do nothing. But when some abnormal conditions occur, you need to handle them manually. For details, see Troubleshooting Sharding DDL Locks.</description>
    </item>
    
    <item>
      <title>Data Migration Simple Usage Scenario</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/usage-scenarios/simple-synchronization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/usage-scenarios/simple-synchronization/</guid>
      <description>Data Migration Simple Usage Scenario This document shows how to use Data Migration (DM) in a simple data synchronization scenario where the data of three upstream MySQL instances needs to be synchronized to a downstream TiDB cluster (no sharding data).
Upstream instances Assume that the upstream schemas are as follows:
 Instance 1
   Schema Tables     user information, log   store store_bj, store_tj   log messages    Instance 2</description>
    </item>
    
    <item>
      <title>Data Migration Task Configuration File</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/configure/task-configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/configure/task-configuration-file/</guid>
      <description>Data Migration Task Configuration File This document introduces the task configuration file of Data Migration &amp;ndash; task.yaml, including Global configuration and Instance configuration.
For the feature and configuration of each configuration item, see Data Synchronization Features.
Important concepts For description of important concepts including source-id and the DM-worker ID, see Important concepts.
Configuration order  Edit the global configuration. Edit the instance configuration based on the global configuration.  Global configuration Basic configuration name: test # The name of the task.</description>
    </item>
    
    <item>
      <title>Data Migration Task Configuration File</title>
      <link>https://pingcap.com/docs/v2.1/tools/dm-task-configuration-file-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/dm-task-configuration-file-intro/</guid>
      <description>Data Migration Task Configuration File This document introduces the task configuration file of Data Migration &amp;ndash; task.yaml, including Global configuration and Instance configuration.
For description of configuration items, see Data Migration Task Configuration Options.
Important concepts For description of important concepts including instance-id and the DM-worker ID, see Important concepts.
Global configuration Basic information configuration name: test # The name of the task. Should be globally unique. task-mode: all # The task mode.</description>
    </item>
    
    <item>
      <title>Data Migration Task Configuration Options</title>
      <link>https://pingcap.com/docs/v2.1/tools/dm-task-config-argument-description/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/dm-task-config-argument-description/</guid>
      <description>Data Migration Task Configuration Options This document introduces the configuration options that apply to Data Migration tasks.
task-mode  String (full/incremental/all) The task mode of data migration to be executed Default value: all
 full: Only makes a full backup of the upstream database and then restores it to the downstream database. incremental: Only synchronizes the incremental data of the upstream database to the downstream database using the binlog. all: full + incremental.</description>
    </item>
    
    <item>
      <title>Data Migration Troubleshooting</title>
      <link>https://pingcap.com/docs/dev/how-to/troubleshoot/data-migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/troubleshoot/data-migration/</guid>
      <description>Data Migration Troubleshooting This document summarizes some commonly encountered issues when you use Data Migration, and provides the solutions.
If you encounter errors while running Data Migration, try the following solution:
 Check the log content related to the error you encountered. The log files are on the DM-master and DM-worker deployment nodes. You can then view common errors to find the corresponding solution.
 If the error you encountered is not involved yet, and you cannot solve the problem yourself by checking the log or monitoring metrics, you can contact the corresponding sales support staff.</description>
    </item>
    
    <item>
      <title>Data Migration Troubleshooting</title>
      <link>https://pingcap.com/docs/v2.1/tools/data-migration-troubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/data-migration-troubleshooting/</guid>
      <description>Data Migration Troubleshooting This document summarizes some commonly encountered issues when you use Data Migration, and provides the solutions.
If you encounter errors while running Data Migration, try the following solution:
 Check the log content related to the error you encountered. The log files are on the DM-master and DM-worker deployment nodes. You can then view common errors to find the corresponding solution.
 If the error you encountered is not involved yet, and you cannot solve the problem yourself by checking the log or monitoring metrics, you can contact the corresponding sales support staff.</description>
    </item>
    
    <item>
      <title>Data Synchronization Features</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/features/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/features/overview/</guid>
      <description>Data Synchronization Features This document describes the data synchronization features provided by the Data Migration tool and explains the configuration of corresponding parameters.
Table routing The table routing feature enables DM to synchronize a certain table of the upstream MySQL or MariaDB instance to the specified table in the downstream.
 Note:
 Configuring multiple different routing rules for a single table is not supported. The match rule of schema needs to be configured separately, which is used to synchronize create/drop schema xx, as shown in rule-2 of the parameter configuration.</description>
    </item>
    
    <item>
      <title>Database Administration Statements</title>
      <link>https://pingcap.com/docs/v2.1/sql/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/admin/</guid>
      <description>Database Administration Statements TiDB manages the database using a number of statements, including granting privileges, modifying system variables, and querying database status.
Privilege management See Privilege Management.
SET statement The SET statement has multiple functions and forms.
Assign values to variables SET variable_assignment [, variable_assignment] ... variable_assignment: user_var_name = expr | param_name = expr | local_var_name = expr | [GLOBAL | SESSION] system_var_name = expr | [@@global. | @@session. | @@] system_var_name = expr You can use the above syntax to assign values to variables in TiDB, which include system variables and user-defined variables.</description>
    </item>
    
    <item>
      <title>Date and Time Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/date-and-time-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/date-and-time-functions/</guid>
      <description>Date and Time Functions The usage of date and time functions is similar to MySQL. For more information, see here.
Date/Time functions
   Name Description     ADDDATE() Add time values (intervals) to a date value   ADDTIME() Add time   CONVERT_TZ() Convert from one time zone to another   CURDATE() Return the current date   CURRENT_DATE(), CURRENT_DATE Synonyms for CURDATE()   CURRENT_TIME(), CURRENT_TIME Synonyms for CURTIME()   CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP Synonyms for NOW()   CURTIME() Return the current time   DATE() Extract the date part of a date or datetime expression   DATE_ADD() Add time values (intervals) to a date value   DATE_FORMAT() Format date as specified   DATE_SUB() Subtract a time value (interval) from a date   DATEDIFF() Subtract two dates   DAY() Synonym for DAYOFMONTH()   DAYNAME() Return the name of the weekday   DAYOFMONTH() Return the day of the month (0-31)   DAYOFWEEK() Return the weekday index of the argument   DAYOFYEAR() Return the day of the year (1-366)   EXTRACT() Extract part of a date   FROM_DAYS() Convert a day number to a date   FROM_UNIXTIME() Format Unix timestamp as a date   GET_FORMAT() Return a date format string   HOUR() Extract the hour   LAST_DAY Return the last day of the month for the argument   LOCALTIME(), LOCALTIME Synonym for NOW()   LOCALTIMESTAMP, LOCALTIMESTAMP() Synonym for NOW()   MAKEDATE() Create a date from the year and day of year   MAKETIME() Create time from hour, minute, second   MICROSECOND() Return the microseconds from argument   MINUTE() Return the minute from the argument   MONTH() Return the month from the date passed   MONTHNAME() Return the name of the month   NOW() Return the current date and time   PERIOD_ADD() Add a period to a year-month   PERIOD_DIFF() Return the number of months between periods   QUARTER() Return the quarter from a date argument   SEC_TO_TIME() Converts seconds to &amp;lsquo;HH:MM:SS&amp;rsquo; format   SECOND() Return the second (0-59)   STR_TO_DATE() Convert a string to a date   SUBDATE() Synonym for DATE_SUB() when invoked with three arguments   SUBTIME() Subtract times   SYSDATE() Return the time at which the function executes   TIME() Extract the time portion of the expression passed   TIME_FORMAT() Format as time   TIME_TO_SEC() Return the argument converted to seconds   TIMEDIFF() Subtract time   TIMESTAMP() With a single argument, this function returns the date or datetime expression; with two arguments, the sum of the arguments   TIMESTAMPADD() Add an interval to a datetime expression   TIMESTAMPDIFF() Subtract an interval from a datetime expression   TO_DAYS() Return the date argument converted to days   TO_SECONDS() Return the date or datetime argument converted to seconds since Year 0   UNIX_TIMESTAMP() Return a Unix timestamp   UTC_DATE() Return the current UTC date   UTC_TIME() Return the current UTC time   UTC_TIMESTAMP() Return the current UTC date and time   WEEK() Return the week number   WEEKDAY() Return the weekday index   WEEKOFYEAR() Return the calendar week of the date (1-53)   YEAR() Return the year   YEARWEEK() Return the year and week    For details, see here.</description>
    </item>
    
    <item>
      <title>Date and Time Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/date-and-time-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/date-and-time-functions/</guid>
      <description>Date and Time Functions The usage of date and time functions is similar to MySQL. For more information, see here.
Date/Time functions
   Name Description     ADDDATE() Add time values (intervals) to a date value   ADDTIME() Add time   CONVERT_TZ() Convert from one time zone to another   CURDATE() Return the current date   CURRENT_DATE(), CURRENT_DATE Synonyms for CURDATE()   CURRENT_TIME(), CURRENT_TIME Synonyms for CURTIME()   CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP Synonyms for NOW()   CURTIME() Return the current time   DATE() Extract the date part of a date or datetime expression   DATE_ADD() Add time values (intervals) to a date value   DATE_FORMAT() Format date as specified   DATE_SUB() Subtract a time value (interval) from a date   DATEDIFF() Subtract two dates   DAY() Synonym for DAYOFMONTH()   DAYNAME() Return the name of the weekday   DAYOFMONTH() Return the day of the month (0-31)   DAYOFWEEK() Return the weekday index of the argument   DAYOFYEAR() Return the day of the year (1-366)   EXTRACT() Extract part of a date   FROM_DAYS() Convert a day number to a date   FROM_UNIXTIME() Format Unix timestamp as a date   GET_FORMAT() Return a date format string   HOUR() Extract the hour   LAST_DAY Return the last day of the month for the argument   LOCALTIME(), LOCALTIME Synonym for NOW()   LOCALTIMESTAMP, LOCALTIMESTAMP() Synonym for NOW()   MAKEDATE() Create a date from the year and day of year   MAKETIME() Create time from hour, minute, second   MICROSECOND() Return the microseconds from argument   MINUTE() Return the minute from the argument   MONTH() Return the month from the date passed   MONTHNAME() Return the name of the month   NOW() Return the current date and time   PERIOD_ADD() Add a period to a year-month   PERIOD_DIFF() Return the number of months between periods   QUARTER() Return the quarter from a date argument   SEC_TO_TIME() Converts seconds to &amp;lsquo;HH:MM:SS&amp;rsquo; format   SECOND() Return the second (0-59)   STR_TO_DATE() Convert a string to a date   SUBDATE() Synonym for DATE_SUB() when invoked with three arguments   SUBTIME() Subtract times   SYSDATE() Return the time at which the function executes   TIME() Extract the time portion of the expression passed   TIME_FORMAT() Format as time   TIME_TO_SEC() Return the argument converted to seconds   TIMEDIFF() Subtract time   TIMESTAMP() With a single argument, this function returns the date or datetime expression; with two arguments, the sum of the arguments   TIMESTAMPADD() Add an interval to a datetime expression   TIMESTAMPDIFF() Subtract an interval from a datetime expression   TO_DAYS() Return the date argument converted to days   TO_SECONDS() Return the date or datetime argument converted to seconds since Year 0   UNIX_TIMESTAMP() Return a Unix timestamp   UTC_DATE() Return the current UTC date   UTC_TIME() Return the current UTC time   UTC_TIMESTAMP() Return the current UTC date and time   WEEK() Return the week number   WEEKDAY() Return the weekday index   WEEKOFYEAR() Return the calendar week of the date (1-53)   YEAR() Return the year   YEARWEEK() Return the year and week    For details, see here.</description>
    </item>
    
    <item>
      <title>Date and Time Types</title>
      <link>https://pingcap.com/docs/sql/date-and-time-types/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/date-and-time-types/</guid>
      <description>Date and Time Types TiDB supports the following data types to store temporal values: DATE, TIME, DATETIME, TIMESTAMP, and YEAR. Each of these types has its own range of valid values, and uses a zero value to indicate that it is an invalid value. In addition, the TIMESTAMP and DATETIME types can automatically generate new time values on modification.
When dealing with date and time value types, note:
 Although TiDB tries to interpret different formats, the date-portion must be in the format of year-month-day (for example, &amp;lsquo;1998-09-04&amp;rsquo;), rather than month-day-year or day-month-year.</description>
    </item>
    
    <item>
      <title>Deploy Data Migration Using DM-Ansible</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/data-migration-with-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/data-migration-with-ansible/</guid>
      <description>Deploy Data Migration Using DM-Ansible DM-Ansible is a cluster deployment tool developed by PingCAP based on the Playbooks feature of Ansible (an IT automation tool). This guide shows how to quickly deploy a Data Migration (DM) cluster using DM-Ansible.
Prepare Before you start, make sure you have the following machines as required.
 Several target machines that meet the following requirements:
 CentOS 7.3 (64-bit) or later, x86_64 architecture (AMD64) Network between machines Closing the firewall, or opening the service port  A Control Machine that meets the following requirements:</description>
    </item>
    
    <item>
      <title>Deploy Data Migration Using DM-Ansible</title>
      <link>https://pingcap.com/docs/v2.1/tools/data-migration-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/data-migration-deployment/</guid>
      <description>Deploy Data Migration Using DM-Ansible DM-Ansible is a cluster deployment tool developed by PingCAP based on the Playbooks feature of Ansible (an IT automation tool). This guide shows how to quickly deploy a Data Migration (DM) cluster using DM-Ansible.
Prepare Before you start, make sure you have the following machines as required.
 Several target machines that meet the following requirements:
 CentOS 7.3 (64-bit) or later, x86_64 architecture (AMD64) Network between machines Closing the firewall, or opening the service port  A Control Machine that meets the following requirements:</description>
    </item>
    
    <item>
      <title>Deploy TiDB Offline Using Ansible</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/offline-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/offline-ansible/</guid>
      <description>Deploy TiDB Offline Using Ansible This guide describes how to deploy a TiDB cluster offline using Ansible.
Prepare Before you start, make sure that you have:
 A download machine
 The machine must have access to the Internet in order to download TiDB-Ansible, TiDB and related packages. For Linux operating system, it is recommended to install CentOS 7.3 or later.  Several target machines and one Control Machine</description>
    </item>
    
    <item>
      <title>Deploy TiDB Offline Using Ansible</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/offline-ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/offline-ansible-deployment/</guid>
      <description>Deploy TiDB Offline Using Ansible This guide describes how to deploy a TiDB cluster offline using Ansible.
Prepare Before you start, make sure that you have:
 A download machine
 The machine must have access to the Internet in order to download TiDB-Ansible, TiDB and related packages. For Linux operating system, it is recommended to install CentOS 7.3 or later.  Several target machines and one Control Machine</description>
    </item>
    
    <item>
      <title>Deploy TiDB Using Ansible</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/ansible/</guid>
      <description>Deploy TiDB Using Ansible This guide describes how to deploy a TiDB cluster using Ansible. For the production environment, it is recommended to deploy TiDB using Ansible.
Overview Ansible is an IT automation tool that can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.
TiDB-Ansible is a TiDB cluster deployment tool developed by PingCAP, based on Ansible playbook. TiDB-Ansible enables you to quickly deploy a new TiDB cluster which includes PD, TiDB, TiKV, and the cluster monitoring modules.</description>
    </item>
    
    <item>
      <title>Deploy TiDB Using Ansible</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/ansible-deployment/</guid>
      <description>Deploy TiDB Using Ansible This guide describes how to deploy a TiDB cluster using Ansible. For the production environment, it is recommended to deploy TiDB using Ansible.
Overview Ansible is an IT automation tool that can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.
TiDB-Ansible is a TiDB cluster deployment tool developed by PingCAP, based on Ansible playbook. TiDB-Ansible enables you to quickly deploy a new TiDB cluster which includes PD, TiDB, TiKV, and the cluster monitoring modules.</description>
    </item>
    
    <item>
      <title>Deploy TiDB Using Docker</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/docker/</guid>
      <description>Deploy TiDB Using Docker This page shows you how to manually deploy a multi-node TiDB cluster on multiple machines using Docker.
To learn more, see TiDB architecture and Software and Hardware Recommendations.
Preparation Before you start, make sure that you have:
 Installed the latest version of Docker Pulled the latest images of TiDB, TiKV and PD from Docker Hub. If not, pull the images using the following commands:</description>
    </item>
    
    <item>
      <title>Deploy TiDB Using Docker</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/docker-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/docker-deployment/</guid>
      <description>Deploy TiDB Using Docker This page shows you how to manually deploy a multi-node TiDB cluster on multiple machines using Docker.
To learn more, see TiDB architecture and Software and Hardware Requirements.
Preparation Before you start, make sure that you have:
 Installed the latest version of Docker Pulled the latest images of TiDB, TiKV and PD from Docker Hub. If not, pull the images using the following commands:</description>
    </item>
    
    <item>
      <title>Deploy TiDB to Kubernetes Locally</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-kubernetes/</guid>
      <description>Deploy TiDB to Kubernetes Locally This document describes how to deploy a TiDB cluster to Kubernetes on your laptop (Linux or macOS) for development or testing.
Docker in Docker (DinD) runs Docker containers as virtual machines and runs another layer of Docker containers inside the first layer of Docker containers. kubeadm-dind-cluster uses this technology to run the Kubernetes cluster in Docker containers. TiDB Operator uses a modified DinD script to manage the DinD Kubernetes cluster.</description>
    </item>
    
    <item>
      <title>Download</title>
      <link>https://pingcap.com/docs/dev/reference/tools/download/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/download/</guid>
      <description>Download This document collects the available downloads for most officially maintained versions of TiDB enterprise tools.
TiDB-Binlog and Lightning If you want to download the latest version of TiDB-Binlog or Lightning, directly download the TiDB package, because both TiDB-Binlog and Lightning are included in the TiDB package.
In addition, the Kafka version of TiDB-Binlog is also provided.
   Package name OS Architecture SHA256 checksum     tidb-latest-linux-amd64.</description>
    </item>
    
    <item>
      <title>EXECUTE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/execute/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/execute/</guid>
      <description>EXECUTE The EXECUTE statement provides an SQL interface to server-side prepared statements.
Synopsis ExecuteStmt:
Identifier:
Examples mysql&amp;gt; PREPARE mystmt FROM &amp;#39;SELECT ? as num FROM DUAL&amp;#39;; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; SET @number = 5; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; EXECUTE mystmt USING @number; +------+ | num | +------+ | 5 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; DEALLOCATE PREPARE mystmt; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>EXPLAIN ANALYZE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/explain-analyze/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/explain-analyze/</guid>
      <description>EXPLAIN ANALYZE The EXPLAIN ANALYZE statement works similar to EXPLAIN, with the major difference being that it will actually execute the statement. This allows you to compare the estimates used as part of query planning to actual values encountered during execution. If the estimates differ significantly from the actual values, you should consider running ANALYZE TABLE on the affected tables.
Synopsis ExplainSym:
ExplainStmt:
ExplainableStmt:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>EXPLAIN | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/explain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/explain/</guid>
      <description>EXPLAIN The EXPLAIN statement shows the execution plan for a query without executing it. It is complimented by EXPLAIN ANALYZE which will execute the query. If the output of EXPLAIN does not match the expected result, consider executing ANALYZE TABLE on each table in the query.
The statements DESC and DESCRIBE are aliases of this statement. The alternative usage of EXPLAIN &amp;lt;tableName&amp;gt; is documented under SHOW [FULL] COLUMNS FROM.</description>
    </item>
    
    <item>
      <title>Enable TLS Authentication</title>
      <link>https://pingcap.com/docs/dev/how-to/secure/enable-tls-between-components/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/secure/enable-tls-between-components/</guid>
      <description>Enable TLS Authentication Overview This document describes how to enable TLS authentication in the TiDB cluster. The TLS authentication includes the following two conditions:
 The mutual authentication between TiDB components, including the authentication among TiDB, TiKV and PD, between TiKV Control and TiKV, between PD Control and PD, between TiKV peers, and between PD peers. Once enabled, the mutual authentication applies to all components, and it does not support applying to only part of the components.</description>
    </item>
    
    <item>
      <title>Enable TLS Authentication</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/security/</guid>
      <description>Enable TLS Authentication Overview This document describes how to enable TLS authentication in the TiDB cluster. The TLS authentication includes the following two conditions:
 The mutual authentication between TiDB components, including the authentication among TiDB, TiKV and PD, between TiKV Control and TiKV, between PD Control and PD, between TiKV peers, and between PD peers. Once enabled, the mutual authentication applies to all components, and it does not support applying to only part of the components.</description>
    </item>
    
    <item>
      <title>Enable TLS for MySQL Clients</title>
      <link>https://pingcap.com/docs/dev/how-to/secure/enable-tls-clients/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/secure/enable-tls-clients/</guid>
      <description>Enable TLS for MySQL Clients It is recommended to use the encrypted connection to ensure data security because non-encrypted connection might lead to information leak.
The TiDB server supports the encrypted connection based on the TLS (Transport Layer Security). The protocol is consistent with MySQL encrypted connections and is directly supported by existing MySQL clients such as MySQL operation tools and MySQL drivers. TLS is sometimes referred to as SSL (Secure Sockets Layer).</description>
    </item>
    
    <item>
      <title>Encryption and Compression Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/encryption-and-compression-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/encryption-and-compression-functions/</guid>
      <description> Encryption and Compression Functions    Name Description     MD5() Calculate MD5 checksum   PASSWORD() Calculate and return a password string   RANDOM_BYTES() Return a random byte vector   SHA1(), SHA() Calculate an SHA-1 160-bit checksum   SHA2() Calculate an SHA-2 checksum   AES_DECRYPT() Decrypt using AES   AES_ENCRYPT() Encrypt using AES   COMPRESS() Return result as a binary string   UNCOMPRESS() Uncompress a string compressed   UNCOMPRESSED_LENGTH() Return the length of a string before compression   CREATE_ASYMMETRIC_PRIV_KEY() Create private key   CREATE_ASYMMETRIC_PUB_KEY() Create public key   CREATE_DH_PARAMETERS() Generate shared DH secret   CREATE_DIGEST() Generate digest from string   ASYMMETRIC_DECRYPT() Decrypt ciphertext using private or public key   ASYMMETRIC_DERIVE() Derive symmetric key from asymmetric keys   ASYMMETRIC_ENCRYPT() Encrypt cleartext using private or public key   ASYMMETRIC_SIGN() Generate signature from digest   ASYMMETRIC_VERIFY() Verify that signature matches digest    </description>
    </item>
    
    <item>
      <title>Encryption and Compression Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/encryption-and-compression-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/encryption-and-compression-functions/</guid>
      <description> Encryption and Compression Functions    Name Description     MD5() Calculate MD5 checksum   PASSWORD() Calculate and return a password string   RANDOM_BYTES() Return a random byte vector   SHA1(), SHA() Calculate an SHA-1 160-bit checksum   SHA2() Calculate an SHA-2 checksum   AES_DECRYPT() Decrypt using AES   AES_ENCRYPT() Encrypt using AES   COMPRESS() Return result as a binary string   UNCOMPRESS() Uncompress a string compressed   UNCOMPRESSED_LENGTH() Return the length of a string before compression   CREATE_ASYMMETRIC_PRIV_KEY() Create private key   CREATE_ASYMMETRIC_PUB_KEY() Create public key   CREATE_DH_PARAMETERS() Generate shared DH secret   CREATE_DIGEST() Generate digest from string   ASYMMETRIC_DECRYPT() Decrypt ciphertext using private or public key   ASYMMETRIC_DERIVE() Derive symmetric key from asymmetric keys   ASYMMETRIC_ENCRYPT() Encrypt cleartext using private or public key   ASYMMETRIC_SIGN() Generate signature from digest   ASYMMETRIC_VERIFY() Verify that signature matches digest    </description>
    </item>
    
    <item>
      <title>Error Codes and Troubleshooting</title>
      <link>https://pingcap.com/docs/dev/reference/error-codes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/error-codes/</guid>
      <description>Error Codes and Troubleshooting This document describes the problems encountered during the use of TiDB and provides the solutions.
Error codes TiDB is compatible with the error codes in MySQL, and in most cases returns the same error code as MySQL. In addition, TiDB has the following unique error codes:
   Error code Description Solution     8001 The memory used by the request exceeds the threshold limit for the TiDB memory usage.</description>
    </item>
    
    <item>
      <title>Error Codes and Troubleshooting</title>
      <link>https://pingcap.com/docs/v2.1/sql/error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/error/</guid>
      <description>Error Codes and Troubleshooting This document describes the problems encountered during the use of TiDB and provides the solutions.
Error codes TiDB is compatible with the error codes in MySQL, and in most cases returns the same error code as MySQL. In addition, TiDB has the following unique error codes:
   Error code Description Solution     8001 The memory used by the request exceeds the threshold limit for the TiDB memory usage.</description>
    </item>
    
    <item>
      <title>Explore SQL with TiDB</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/explore-sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/explore-sql/</guid>
      <description>Explore SQL with TiDB After you successfully deploy a TiDB cluster, you can run SQL statements in TiDB. Because TiDB is compatible with MySQL, you can use THE MySQL client to connect to TiDB and run MySQL statements directly in most of the cases. For more information, see Compatibility with MySQL.
This page includes some basic SQL statements such as CRUD operations. For a complete list of the statements, see TiDB SQL Syntax Diagram.</description>
    </item>
    
    <item>
      <title>Expression Syntax</title>
      <link>https://pingcap.com/docs/dev/reference/sql/language-structure/expression-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/language-structure/expression-syntax/</guid>
      <description>Expression Syntax The following rules define the expression syntax in TiDB. You can find the definition in parser/parser.y. The syntax parsing in TiDB is based on Yacc.
Expression: singleAtIdentifier assignmentEq Expression | Expression logOr Expression | Expression &amp;#34;XOR&amp;#34; Expression | Expression logAnd Expression | &amp;#34;NOT&amp;#34; Expression | Factor IsOrNotOp trueKwd | Factor IsOrNotOp falseKwd | Factor IsOrNotOp &amp;#34;UNKNOWN&amp;#34; | Factor Factor: Factor IsOrNotOp &amp;#34;NULL&amp;#34; | Factor CompareOp PredicateExpr | Factor CompareOp singleAtIdentifier assignmentEq PredicateExpr | Factor CompareOp AnyOrAll SubSelect | PredicateExpr PredicateExpr: PrimaryFactor InOrNotOp &amp;#39;(&amp;#39; ExpressionList &amp;#39;)&amp;#39; | PrimaryFactor InOrNotOp SubSelect | PrimaryFactor BetweenOrNotOp PrimaryFactor &amp;#34;AND&amp;#34; PredicateExpr | PrimaryFactor LikeOrNotOp PrimaryExpression LikeEscapeOpt | PrimaryFactor RegexpOrNotOp PrimaryExpression | PrimaryFactor PrimaryFactor: PrimaryFactor &amp;#39;|&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;&amp;amp;&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;&amp;lt;&amp;lt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;&amp;gt;&amp;gt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;+&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;-&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;*&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;/&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;%&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;DIV&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;MOD&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;^&amp;#39; PrimaryFactor | PrimaryExpression PrimaryExpression: Operand | FunctionCallKeyword | FunctionCallNonKeyword | FunctionCallAgg | FunctionCallGeneric | Identifier jss stringLit | Identifier juss stringLit | SubSelect | &amp;#39;!</description>
    </item>
    
    <item>
      <title>Expression Syntax</title>
      <link>https://pingcap.com/docs/v2.1/sql/expression-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/expression-syntax/</guid>
      <description>Expression Syntax The following rules define the expression syntax in TiDB. You can find the definition in parser/parser.y. The syntax parsing in TiDB is based on Yacc.
Expression: singleAtIdentifier assignmentEq Expression | Expression logOr Expression | Expression &amp;#34;XOR&amp;#34; Expression | Expression logAnd Expression | &amp;#34;NOT&amp;#34; Expression | Factor IsOrNotOp trueKwd | Factor IsOrNotOp falseKwd | Factor IsOrNotOp &amp;#34;UNKNOWN&amp;#34; | Factor Factor: Factor IsOrNotOp &amp;#34;NULL&amp;#34; | Factor CompareOp PredicateExpr | Factor CompareOp singleAtIdentifier assignmentEq PredicateExpr | Factor CompareOp AnyOrAll SubSelect | PredicateExpr PredicateExpr: PrimaryFactor InOrNotOp &amp;#39;(&amp;#39; ExpressionList &amp;#39;)&amp;#39; | PrimaryFactor InOrNotOp SubSelect | PrimaryFactor BetweenOrNotOp PrimaryFactor &amp;#34;AND&amp;#34; PredicateExpr | PrimaryFactor LikeOrNotOp PrimaryExpression LikeEscapeOpt | PrimaryFactor RegexpOrNotOp PrimaryExpression | PrimaryFactor PrimaryFactor: PrimaryFactor &amp;#39;|&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;&amp;amp;&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;&amp;lt;&amp;lt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;&amp;gt;&amp;gt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;+&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;-&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;*&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;/&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;%&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;DIV&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;MOD&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;^&amp;#39; PrimaryFactor | PrimaryExpression PrimaryExpression: Operand | FunctionCallKeyword | FunctionCallNonKeyword | FunctionCallAgg | FunctionCallGeneric | Identifier jss stringLit | Identifier juss stringLit | SubSelect | &amp;#39;!</description>
    </item>
    
    <item>
      <title>FAQs After Upgrade</title>
      <link>https://pingcap.com/docs/faq/upgrades/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/faq/upgrades/</guid>
      <description>FAQs After Upgrade This document lists some FAQs and their solutions after you upgrade TiDB.
The character set (charset) errors when executing DDL operations In v2.1.0 and earlier versions (including all versions of v2.0), the character set of TiDB is UTF-8 by default. But starting from v2.1.1, the default character set has been changed into UTF8MB4.
If you explicitly specify the charset of a newly created table as UTF-8 in v2.</description>
    </item>
    
    <item>
      <title>FAQs After Upgrade</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/upgrade-faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/upgrade-faq/</guid>
      <description>FAQs After Upgrade This document lists some FAQs and their solutions after you upgrade TiDB.
The character set (charset) errors when executing DDL operations In v2.1.0 and earlier versions (including all versions of v2.0), the character set of TiDB is UTF-8 by default. But starting from v2.1.1, the default character set has been changed into UTF8MB4.
If you explicitly specify the charset of a newly created table as UTF-8 in v2.</description>
    </item>
    
    <item>
      <title>FLUSH PRIVILEGES | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/flush-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/flush-privileges/</guid>
      <description>FLUSH PRIVILEGES This statement triggers TiDB to reload the in-memory copy of privileges from the privilege tables. You should execute FLUSH PRIVILEGES after making manual edits to tables such as mysql.user. Executing this statement is not required after using privilege statements such as GRANT or REVOKE.
Synopsis FlushStmt:
NoWriteToBinLogAliasOpt:
FlushOption:
Examples mysql&amp;gt; FLUSH PRIVILEGES; Query OK, 0 rows affected (0.01 sec) MySQL compatibility This statement is understood to be fully compatible with MySQL.</description>
    </item>
    
    <item>
      <title>FLUSH STATUS | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/flush-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/flush-status/</guid>
      <description>FLUSH STATUS This statement is included for compatibility with MySQL. It has no effect on TiDB, which uses Prometheus and Grafana for centralized metrics collection instead of SHOW STATUS.
Synopsis FlushStmt:
NoWriteToBinLogAliasOpt:
FlushOption:
Examples mysql&amp;gt; show status; +--------------------+--------------------------------------+ | Variable_name | Value | +--------------------+--------------------------------------+ | Ssl_cipher_list | | | server_id | 93e2e07d-6bb4-4a1b-90b7-e035fae154fe | | ddl_schema_version | 141 | | Ssl_verify_mode | 0 | | Ssl_version | | | Ssl_cipher | | +--------------------+--------------------------------------+ 6 rows in set (0.</description>
    </item>
    
    <item>
      <title>FLUSH TABLES | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/flush-tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/flush-tables/</guid>
      <description>FLUSH TABLES This statement is included for compatibility with MySQL. It has no effective usage in TiDB.
Synopsis FlushStmt:
NoWriteToBinLogAliasOpt:
FlushOption:
TableOrTables:
TableNameListOpt:
WithReadLockOpt:
Examples mysql&amp;gt; FLUSH TABLES; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; FLUSH TABLES WITH READ LOCK; ERROR 1105 (HY000): FLUSH TABLES WITH READ LOCK is not supported. Please use @@tidb_snapshot MySQL compatibility  TiDB does not have a concept of table cache as in MySQL.</description>
    </item>
    
    <item>
      <title>Function and Operator Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/reference/</guid>
      <description>Function and Operator Reference The usage of the functions and operators in TiDB is similar to MySQL. See Functions and Operators in MySQL.
In SQL statements, expressions can be used on the ORDER BY and HAVING clauses of the SELECT statement, the WHERE clause of SELECT/DELETE/UPDATE statements, and SET statements.
You can write expressions using literals, column names, NULL, built-in functions, operators and so on.</description>
    </item>
    
    <item>
      <title>Function and Operator Reference</title>
      <link>https://pingcap.com/docs/v2.1/sql/functions-and-operators-reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/functions-and-operators-reference/</guid>
      <description>Function and Operator Reference The usage of the functions and operators in TiDB is similar to MySQL. See Functions and Operators in MySQL.
In SQL statements, expressions can be used on the ORDER BY and HAVING clauses of the SELECT statement, the WHERE clause of SELECT/DELETE/UPDATE statements, and SET statements.
You can write expressions using literals, column names, NULL, built-in functions, operators and so on.</description>
    </item>
    
    <item>
      <title>GRANT &lt;privileges&gt; | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/grant-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/grant-privileges/</guid>
      <description>GRANT  This statement allocates privileges to a pre-existing user in TiDB. The privilege system in TiDB follows MySQL, where credentials are assigned based on a database/table pattern.
Synopsis GrantStmt:
PrivElemList:
PrivElem:
PrivType:
ObjectType:
PrivLevel:
UserSpecList:
Examples mysql&amp;gt; CREATE USER newuser IDENTIFIED BY &amp;#39;mypassword&amp;#39;; Query OK, 1 row affected (0.02 sec) mysql&amp;gt; GRANT ALL ON test.* TO &amp;#39;newuser&amp;#39;; Query OK, 0 rows affected (0.03 sec) mysql&amp;gt; SHOW GRANTS FOR &amp;#39;newuser&amp;#39;; +-------------------------------------------------+ | Grants for newuser@% | +-------------------------------------------------+ | GRANT USAGE ON *.</description>
    </item>
    
    <item>
      <title>Generate Self-signed Certificates</title>
      <link>https://pingcap.com/docs/dev/how-to/secure/generate-self-signed-certificates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/secure/generate-self-signed-certificates/</guid>
      <description>Generate Self-signed Certificates Overview This document describes how to generate self-signed certificates using cfssl.
Assume that the topology of the instance cluster is as follows:
   Name Host IP Services     node1 172.16.10.1 PD1, TiDB1   node2 172.16.10.2 PD2, TiDB2   node3 172.16.10.3 PD3   node4 172.16.10.4 TiKV1   node5 172.16.10.5 TiKV2   node6 172.16.10.6 TiKV3    Download cfssl Assume that the host is x86_64 Linux:</description>
    </item>
    
    <item>
      <title>Generate Self-signed Certificates</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/generate-self-signed-certificates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/generate-self-signed-certificates/</guid>
      <description>Generate Self-signed Certificates Overview This document describes how to generate self-signed certificates using cfssl.
Assume that the topology of the instance cluster is as follows:
   Name Host IP Services     node1 172.16.10.1 PD1, TiDB1   node2 172.16.10.2 PD2, TiDB2   node3 172.16.10.3 PD3   node4 172.16.10.4 TiKV1   node5 172.16.10.5 TiKV2   node6 172.16.10.6 TiKV3    Download cfssl Assume that the host is x86_64 Linux:</description>
    </item>
    
    <item>
      <title>Generated Columns</title>
      <link>https://pingcap.com/docs/dev/reference/sql/generated-columns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/generated-columns/</guid>
      <description>Generated Columns TiDB supports generated columns as part of MySQL 5.7 compatibility. One of the primary use cases for generated columns is to extract data out of a JSON data type and enable it to be indexed.
Index JSON using generated column In both MySQL 5.7 and TiDB, columns of type JSON can not be indexed directly. i.e. The following table structure is not supported:
CREATE TABLE person ( id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, address_info JSON, KEY (address_info) ); In order to index a JSON column, you must first extract it as a generated column.</description>
    </item>
    
    <item>
      <title>Generated Columns</title>
      <link>https://pingcap.com/docs/v2.1/sql/generated-columns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/generated-columns/</guid>
      <description>Generated Columns TiDB supports generated columns as part of MySQL 5.7 compatibility. One of the primary use cases for generated columns is to extract data out of a JSON data type and enable it to be indexed.
Index JSON using generated column In both MySQL 5.7 and TiDB, columns of type JSON can not be indexed directly. i.e. The following table structure is not supported:
CREATE TABLE person ( id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, address_info JSON, KEY (address_info) ); In order to index a JSON column, you must first extract it as a generated column.</description>
    </item>
    
    <item>
      <title>Handle Sharding DDL Locks Manually in DM</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/features/manually-handling-sharding-ddl-locks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/features/manually-handling-sharding-ddl-locks/</guid>
      <description>Handle Sharding DDL Locks Manually in DM DM uses the sharding DDL lock to ensure operations are performed in the correct order. This locking mechanism resolves sharding DDL locks automatically in most cases, but you need to use the unlock-ddl-lock or break-ddl-lock command to manually handle the abnormal DDL locks in some abnormal scenarios.
 Warning:
 Do not use unlock-ddl-lock or break-ddl-lock unless you are totally aware of the possible impacts brought by the command and you can accept them.</description>
    </item>
    
    <item>
      <title>INSERT | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/insert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/insert/</guid>
      <description>INSERT This statement inserts new rows into a table.
Synopsis InsertIntoStmt:
PriorityOpt:
IgnoreOptional:
IntoOpt:
TableName:
InsertValues:
Examples mysql&amp;gt; CREATE TABLE t1 (a int); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; CREATE TABLE t2 LIKE t1; Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 VALUES (1); Query OK, 1 row affected (0.02 sec) mysql&amp;gt; INSERT INTO t1 (a) VALUES (1); Query OK, 1 row affected (0.01 sec) mysql&amp;gt; INSERT INTO t2 SELECT * FROM t1; Query OK, 2 rows affected (0.</description>
    </item>
    
    <item>
      <title>Identify Slow Queries</title>
      <link>https://pingcap.com/docs/dev/how-to/maintain/identify-slow-queries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/maintain/identify-slow-queries/</guid>
      <description>Identify Slow Queries The slow query log is a record of SQL statements that took a long time to perform.
The slow log format is updated in TiDB v2.1.8 and later. For the slow query log information in versions earlier than v2.1.8, see this file.
A problematic SQL statement can increase the pressure on the entire cluster, resulting in a longer response time. To solve this problem, you can use the slow query log to identify the problematic statements and thus improve the performance.</description>
    </item>
    
    <item>
      <title>Import Example Database</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/import-example-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/import-example-database/</guid>
      <description>Import Example Database Examples used in the TiDB manual use System Data from Capital Bikeshare, released under the Capital Bikeshare Data License Agreement.
Download all data files The system data is available for download in .zip files organized per year. Downloading and extracting all files requires approximately 3GB of disk space. To download all files for years 2010-2017 using a bash script:
mkdir -p bikeshare-data &amp;amp;&amp;amp; cd bikeshare-data curl -L --remote-name-all https://s3.</description>
    </item>
    
    <item>
      <title>Information Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/information-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/information-functions/</guid>
      <description> Information Functions In TiDB, the usage of information functions is similar to MySQL. For more information, see Information Functions.
Information function descriptions    Name Description     CONNECTION_ID() Return the connection ID (thread ID) for the connection   CURRENT_USER(), CURRENT_USER Return the authenticated user name and host name   DATABASE() Return the default (current) database name   FOUND_ROWS() For a SELECT with a LIMIT clause, the number of the rows that are returned if there is no LIMIT clause   LAST_INSERT_ID() Return the value of the AUTOINCREMENT column for the last INSERT   SCHEMA() Synonym for DATABASE()   SESSION_USER() Synonym for USER()   SYSTEM_USER() Synonym for USER()   USER() Return the user name and host name provided by the client   VERSION() Return a string that indicates the MySQL server version   TIDB_VERSION() Return a string that indicates the TiDB server version    </description>
    </item>
    
    <item>
      <title>Information Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/information-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/information-functions/</guid>
      <description> Information Functions In TiDB, the usage of information functions is similar to MySQL. For more information, see Information Functions.
Information function descriptions    Name Description     CONNECTION_ID() Return the connection ID (thread ID) for the connection   CURRENT_USER(), CURRENT_USER Return the authenticated user name and host name   DATABASE() Return the default (current) database name   FOUND_ROWS() For a SELECT with a LIMIT clause, the number of the rows that are returned if there is no LIMIT clause   LAST_INSERT_ID() Return the value of the AUTOINCREMENT column for the last INSERT   SCHEMA() Synonym for DATABASE()   SESSION_USER() Synonym for USER()   SYSTEM_USER() Synonym for USER()   USER() Return the user name and host name provided by the client   VERSION() Return a string that indicates the MySQL server version   TIDB_VERSION() Return a string that indicates the TiDB server version    </description>
    </item>
    
    <item>
      <title>Information Schema</title>
      <link>https://pingcap.com/docs/dev/reference/system-databases/information-schema/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/system-databases/information-schema/</guid>
      <description>Information Schema As part of MySQL compatibility, TiDB supports a number of INFORMATION_SCHEMA tables. Many of these tables also have a corresponding SHOW command. The benefit of querying INFORMATION_SCHEMA is that it is possible to join between tables.
Fully Supported Information Schema Tables CHARACTER_SETS table The CHARACTER_SETS table provides information about character sets. The default character set in TiDB is utf8mb4. Additional character sets in this table are included for compatibility with MySQL:</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Ansible</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-using-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-using-ansible/</guid>
      <description>Install and Deploy TiKV Using Ansible This guide describes how to install and deploy TiKV using Ansible. Ansible is an IT automation tool that can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.
TiDB-Ansible is a TiDB cluster deployment tool developed by PingCAP, based on Ansible playbook. TiDB-Ansible enables you to quickly deploy a new TiKV cluster which includes PD, TiKV, and the cluster monitoring modules.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Ansible</title>
      <link>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-using-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-using-ansible/</guid>
      <description>Install and Deploy TiKV Using Ansible This guide describes how to install and deploy TiKV using Ansible. Ansible is an IT automation tool that can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.
TiDB-Ansible is a TiDB cluster deployment tool developed by PingCAP, based on Ansible playbook. TiDB-Ansible enables you to quickly deploy a new TiKV cluster which includes PD, TiKV, and the cluster monitoring modules.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Binary Files</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-using-binary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-using-binary/</guid>
      <description>Install and Deploy TiKV Using Binary Files This guide describes how to deploy a TiKV cluster using binary files.
 To quickly understand and try TiKV, see Deploy the TiKV cluster on a single machine. To try TiKV out and explore the features, see Deploy the TiKV cluster on multiple nodes for testing.  Deploy the TiKV cluster on a single machine This section describes how to deploy TiKV on a single machine installed with the Linux system.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Binary Files</title>
      <link>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-using-binary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-using-binary/</guid>
      <description>Install and Deploy TiKV Using Binary Files This guide describes how to deploy a TiKV cluster using binary files.
 To quickly understand and try TiKV, see Deploy the TiKV cluster on a single machine. To try TiKV out and explore the features, see Deploy the TiKV cluster on multiple nodes for testing.  Deploy the TiKV cluster on a single machine This section describes how to deploy TiKV on a single machine installed with the Linux system.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Docker</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-using-docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-using-docker/</guid>
      <description>Install and Deploy TiKV Using Docker This guide describes how to deploy a multi-node TiKV cluster using Docker.
Prerequisites Make sure that Docker is installed on each machine.
For more details about prerequisites, see Hardware and Software Requirements.
Deploy the TiKV cluster on multiple nodes Assume that you have 6 machines with the following details:
   Name Host IP Services Data Path     Node1 192.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Docker</title>
      <link>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-using-docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-using-docker/</guid>
      <description>Install and Deploy TiKV Using Docker This guide describes how to deploy a multi-node TiKV cluster using Docker.
Prerequisites Make sure that Docker is installed on each machine.
For more details about prerequisites, see Hardware and Software Requirements.
Deploy the TiKV cluster on multiple nodes Assume that you have 6 machines with the following details:
   Name Host IP Services Data Path     Node1 192.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Docker Compose</title>
      <link>https://pingcap.com/docs/tikv/deploy-tikv-docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/deploy-tikv-docker-compose/</guid>
      <description>Install and Deploy TiKV Using Docker Compose This guide describes how to quickly deploy a TiKV testing cluster using Docker Compose on a single machine.
 Note:
Currently, this installation method only supports the Linux system.
 Prerequisites Make sure you have installed the following items on your machine:
 Docker (17.06.0 or later) and Docker Compose
sudo yum install docker docker-compose Helm
curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash Git
sudo yum install git  Install and deploy  Download tidb-docker-compose.</description>
    </item>
    
    <item>
      <title>Install and Deploy TiKV Using Docker Compose</title>
      <link>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tikv/deploy-tikv-docker-compose/</guid>
      <description>Install and Deploy TiKV Using Docker Compose This guide describes how to quickly deploy a TiKV testing cluster using Docker Compose on a single machine.
 Note:
Currently, this installation method only supports the Linux system.
 Prerequisites Make sure you have installed the following items on your machine:
 Docker (17.06.0 or later) and Docker Compose
sudo yum install docker docker-compose Helm
curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash Git
sudo yum install git  Install and deploy  Download tidb-docker-compose.</description>
    </item>
    
    <item>
      <title>Install from DBdeployer</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-dbdeployer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-dbdeployer/</guid>
      <description>Install from DBdeployer DBdeployer is designed to allow multiple versions of TiDB deployed concurrently. It is recommended for advanced users who are testing out new builds of TiDB, or testing compatibility across releases.
Similar to Homebrew, the DBdeployer installation method installs the tidb-server without the tikv-server or pd-server. This is useful for development environments, since you can test your application&amp;rsquo;s compatibility with TiDB without needing to deploy a full TiDB platform.</description>
    </item>
    
    <item>
      <title>Install from Homebrew</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-homebrew/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-homebrew/</guid>
      <description>Install from Homebrew TiDB on Homebrew supports a minimal installation mode of the tidb-server without the tikv-server or pd-server. This is useful for development environments, since you can test your application&amp;rsquo;s compatibility with TiDB without needing to deploy a full TiDB platform.
This installation method is supported on macOS, Linux and Windows (via WSL).
 Note:
Internally this installation uses goleveldb as the storage engine. It is much slower than TiKV, and any benchmarks will be unreliable.</description>
    </item>
    
    <item>
      <title>Introduction to Statistics</title>
      <link>https://pingcap.com/docs/dev/reference/performance/statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/performance/statistics/</guid>
      <description>Introduction to Statistics Based on the statistics, the TiDB optimizer chooses the most efficient query execution plan. The statistics collect table-level and column-level information.
 The statistics of a table include the total number of rows and the number of updated rows. The statistics of a column include the number of different values, the number of NULL, the histogram, and the Count-Min Sketch of the column.  Collect statistics Manual collection You can run the ANALYZE statement to collect statistics.</description>
    </item>
    
    <item>
      <title>Introduction to Statistics</title>
      <link>https://pingcap.com/docs/v2.1/sql/statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/statistics/</guid>
      <description>Introduction to Statistics Based on the statistics, the TiDB optimizer chooses the most efficient query execution plan. The statistics collect table-level and column-level information.
 The statistics of a table include the total number of rows and the number of updated rows. The statistics of a column include the number of different values, the number of NULL, the histogram, and the Count-Min Sketch of the column.  Collect statistics Manual collection You can run the ANALYZE statement to collect statistics.</description>
    </item>
    
    <item>
      <title>JSON Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/json-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/json-functions/</guid>
      <description>JSON Functions TiDB supports most of the JSON functions that shipped with the GA release of MySQL 5.7. Additional JSON functions were added to MySQL 5.7 after its release, and not all are available in TiDB (see unsupported functions).
Functions that create JSON values    Function Name and Syntactic Sugar Description     JSON_ARRAY([val[, val] &amp;hellip;]) Evaluates a (possibly empty) list of values and returns a JSON array containing those values   JSON_OBJECT(key, val[, key, val] &amp;hellip;) Evaluates a (possibly empty) list of key-value pairs and returns a JSON object containing those pairs   JSON_QUOTE(string) Returns a string as a JSON value with quotes    Functions that search JSON values    Function Name and Syntactic Sugar Description     JSON_CONTAINS(target, candidate[, path]) Indicates by returning 1 or 0 whether a given candidate JSON document is contained within a target JSON document   JSON_CONTAINS_PATH(json_doc, one_or_all, path[, path] &amp;hellip;) Returns 0 or 1 to indicate whether a JSON document contains data at a given path or paths   JSON_EXTRACT(json_doc, path[, path] &amp;hellip;) Returns data from a JSON document, selected from the parts of the document matched by the path arguments   -&amp;gt; Returns the value from a JSON column after the evaluating path; the syntactic sugar of JSON_EXTRACT(doc, path_literal)   -&amp;gt;&amp;gt; Returns the value from a JSON column after the evaluating path and unquoting the result; the syntactic sugar of JSON_UNQUOTE(JSON_EXTRACT(doc, path_literal))   JSON_KEYS(json_doc[, path]) Returns the keys from the top-level value of a JSON object as a JSON array, or, if a path argument is given, the top-level keys from the selected path    Functions that modify JSON values    Function Name and Syntactic Sugar Description     JSON_INSERT(json_doc, path, val[, path, val] &amp;hellip;) Inserts data into a JSON document and returns the result   JSON_MERGE(json_doc, json_doc[, json_doc] &amp;hellip;) A deprecated alias for JSON_MERGE_PRESERVE   JSON_MERGE_PRESERVE(json_doc, json_doc[, json_doc] &amp;hellip;) Merges two or more JSON documents and returns the merged result   JSON_REMOVE(json_doc, path[, path] &amp;hellip;) Removes data from a JSON document and returns the result   JSON_REPLACE(json_doc, path, val[, path, val] &amp;hellip;) Replaces existing values in a JSON document and returns the result   JSON_SET(json_doc, path, val[, path, val] &amp;hellip;) Inserts or updates data in a JSON document and returns the result   JSON_UNQUOTE(json_val) Unquotes a JSON value and returns the result as a string    Functions that return JSON value attributes    Function Name and Syntactic Sugar Description     JSON_DEPTH(json_doc) Returns the maximum depth of a JSON document   JSON_LENGTH(json_doc[, path]) Returns the length of a JSON document, or, if a path argument is given, the length of the value within the path   JSON_TYPE(json_val) Returns a string indicating the type of a JSON value    Unsupported functions The following JSON functions are unsupported in TiDB.</description>
    </item>
    
    <item>
      <title>JSON Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/json-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/json-functions/</guid>
      <description>JSON Functions TiDB supports most of the JSON functions that shipped with the GA release of MySQL 5.7. Additional JSON functions were added to MySQL 5.7 after its release, and not all are available in TiDB (see unsupported functions).
Functions that create JSON values    Function Name and Syntactic Sugar Description     JSON_ARRAY([val[, val] &amp;hellip;]) Evaluates a (possibly empty) list of values and returns a JSON array containing those values   JSON_OBJECT(key, val[, key, val] &amp;hellip;) Evaluates a (possibly empty) list of key-value pairs and returns a JSON object containing those pairs    Functions that search JSON values    Function Name and Syntactic Sugar Description     JSON_CONTAINS(target, candidate[, path]) Indicates by returning 1 or 0 whether a given candidate JSON document is contained within a target JSON document   JSON_CONTAINS_PATH(json_doc, one_or_all, path[, path] &amp;hellip;) Returns 0 or 1 to indicate whether a JSON document contains data at a given path or paths   JSON_EXTRACT(json_doc, path[, path] &amp;hellip;) Returns data from a JSON document, selected from the parts of the document matched by the path arguments   -&amp;gt; Returns the value from a JSON column after the evaluating path; the syntactic sugar of JSON_EXTRACT(doc, path_literal)   -&amp;gt;&amp;gt; Returns the value from a JSON column after the evaluating path and unquoting the result; the syntactic sugar of JSON_UNQUOTE(JSON_EXTRACT(doc, path_literal))   JSON_KEYS(json_doc[, path]) Returns the keys from the top-level value of a JSON object as a JSON array, or, if a path argument is given, the top-level keys from the selected path    Functions that modify JSON values    Function Name and Syntactic Sugar Description     JSON_INSERT(json_doc, path, val[, path, val] &amp;hellip;) Inserts data into a JSON document and returns the result   JSON_MERGE(json_doc, json_doc[, json_doc] &amp;hellip;) Merges two or more JSON documents and returns the merged result   JSON_REMOVE(json_doc, path[, path] &amp;hellip;) Removes data from a JSON document and returns the result   JSON_REPLACE(json_doc, path, val[, path, val] &amp;hellip;) Replaces existing values in a JSON document and returns the result   JSON_SET(json_doc, path, val[, path, val] &amp;hellip;) Inserts or updates data in a JSON document and returns the result   JSON_UNQUOTE(json_val) Unquotes a JSON value and returns the result as a string    Functions that return JSON value attributes    Function Name and Syntactic Sugar Description     JSON_DEPTH(json_doc) Returns the maximum depth of a JSON document   JSON_LENGTH(json_doc[, path]) Returns the length of a JSON document, or, if a path argument is given, the length of the value within the path   JSON_TYPE(json_val) Returns a string indicating the type of a JSON value    Unsupported functions The following JSON functions are unsupported in TiDB.</description>
    </item>
    
    <item>
      <title>KILL [TIDB] | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/kill/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/kill/</guid>
      <description>KILL [TIDB] The statement KILL TIDB is used to terminate connections in TiDB.
By design, this statement is not compatible with MySQL by default. This helps prevent against a case of a connection being terminated on the wrong TiDB server, since it is common to place multiple TiDB servers behind a load balancer.
Synopsis KillStmt:
Examples mysql&amp;gt; SHOW PROCESSLIST; +------+------+-----------+------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +------+------+-----------+------+---------+------+-------+------------------+ | 1 | root | 127.</description>
    </item>
    
    <item>
      <title>Key Features</title>
      <link>https://pingcap.com/docs/key-features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/key-features/</guid>
      <description>Key Features Horizontal Scalability TiDB expands both SQL processing and storage by simply adding new nodes. This makes infrastructure capacity planning both easier and more cost-effective than traditional relational databases which only scale vertically.
MySQL Compatible Syntax TiDB acts like it is a MySQL 5.7 server to your applications. You can continue to use all of the existing MySQL client libraries, and in many cases, you will not need to change a single line of code in your application.</description>
    </item>
    
    <item>
      <title>Key Metrics</title>
      <link>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/overview/</guid>
      <description>Key Metrics If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see TiDB Monitoring Framework Overview.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
For routine operations, you can get an overview of the component (PD, TiDB, TiKV) status and the entire cluster from the Overview dashboard, where the key metrics are displayed.</description>
    </item>
    
    <item>
      <title>Key Metrics</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/dashboard-overview-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/dashboard-overview-info/</guid>
      <description>Key Metrics If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see TiDB Monitoring Framework Overview.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
For routine operations, you can get an overview of the component (PD, TiDB, TiKV) status and the entire cluster from the Overview dashboard, where the key metrics are displayed.</description>
    </item>
    
    <item>
      <title>Key Monitoring Metrics of PD</title>
      <link>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/pd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/pd/</guid>
      <description>Key Monitoring Metrics of PD If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see Overview of the Monitoring Framework.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
You can get an overview of the component PD status from the PD dashboard, where the key metrics are displayed.</description>
    </item>
    
    <item>
      <title>Key Monitoring Metrics of PD</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/dashboard-pd-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/dashboard-pd-info/</guid>
      <description>Key Monitoring Metrics of PD If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see Overview of the Monitoring Framework.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
You can get an overview of the component PD status from the PD dashboard, where the key metrics are displayed.</description>
    </item>
    
    <item>
      <title>Key Monitoring Metrics of TiKV</title>
      <link>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/tikv/</guid>
      <description>Key Monitoring Metrics of TiKV If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see Overview of the Monitoring Framework.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
You can get an overview of the component TiKV status from the TiKV dashboard, where the key metrics are displayed.</description>
    </item>
    
    <item>
      <title>Key Monitoring Metrics of TiKV</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/dashboard-tikv-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/dashboard-tikv-info/</guid>
      <description>Key Monitoring Metrics of TiKV If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see Overview of the Monitoring Framework.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
You can get an overview of the component TiKV status from the TiKV dashboard, where the key metrics are displayed.</description>
    </item>
    
    <item>
      <title>Keywords and Reserved Words</title>
      <link>https://pingcap.com/docs/dev/reference/sql/language-structure/keywords-and-reserved-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/language-structure/keywords-and-reserved-words/</guid>
      <description>Keywords and Reserved Words Keywords are words that have significance in SQL. Certain keywords, such as SELECT, UPDATE, or DELETE, are reserved and require special treatment for use as identifiers such as table and column names. For example, as table names, the reserved words must be quoted with backquotes:
mysql&amp;gt; CREATE TABLE select (a INT); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a INT)&amp;#34; (total length 27) mysql&amp;gt; CREATE TABLE `select` (a INT); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Keywords and Reserved Words</title>
      <link>https://pingcap.com/docs/v2.1/sql/keywords-and-reserved-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/keywords-and-reserved-words/</guid>
      <description>Keywords and Reserved Words Keywords are words that have significance in SQL. Certain keywords, such as SELECT, UPDATE, or DELETE, are reserved and require special treatment for use as identifiers such as table and column names. For example, as table names, the reserved words must be quoted with backquotes:
mysql&amp;gt; CREATE TABLE select (a INT); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a INT)&amp;#34; (total length 27) mysql&amp;gt; CREATE TABLE `select` (a INT); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>LOAD DATA | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/load-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/load-data/</guid>
      <description>LOAD DATA The LOAD DATA statement batch loads data into a TiDB table.
Synopsis LoadDataStmt:
Examples mysql&amp;gt; CREATE TABLE trips ( -&amp;gt; trip_id bigint NOT NULL PRIMARY KEY auto_increment, -&amp;gt; duration integer not null, -&amp;gt; start_date datetime, -&amp;gt; end_date datetime, -&amp;gt; start_station_number integer, -&amp;gt; start_station varchar(255), -&amp;gt; end_station_number integer, -&amp;gt; end_station varchar(255), -&amp;gt; bike_number varchar(255), -&amp;gt; member_type varchar(255) -&amp;gt; ); Query OK, 0 rows affected (0.14 sec) mysql&amp;gt; LOAD DATA LOCAL INFILE &amp;#39;/mnt/evo970/data-sets/bikeshare-data/2017Q4-capitalbikeshare-tripdata.</description>
    </item>
    
    <item>
      <title>Literal Values</title>
      <link>https://pingcap.com/docs/dev/reference/sql/language-structure/literal-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/language-structure/literal-values/</guid>
      <description>Literal Values This document describes String literals, Numeric literals, NULL values, Hexadecimal literals, Date and time literals, Boolean literals, and Bit-value literals.
String literals A string is a sequence of bytes or characters, enclosed within either single quote &#39; or double quote &amp;quot; characters. For example:
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; Quoted strings placed next to each other are concatenated to a single string. The following lines are equivalent:
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; If the ANSI_QUOTES SQL MODE is enabled, string literals can be quoted only within single quotation marks because a string quoted within double quotation marks is interpreted as an identifier.</description>
    </item>
    
    <item>
      <title>Literal Values</title>
      <link>https://pingcap.com/docs/v2.1/sql/literal-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/literal-values/</guid>
      <description>Literal Values This document describes String literals, Numeric literals, NULL values, Hexadecimal literals, Date and time literals, Boolean literals, and Bit-value literals.
String literals A string is a sequence of bytes or characters, enclosed within either single quote &#39; or double quote &amp;quot; characters. For example:
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; Quoted strings placed next to each other are concatenated to a single string. The following lines are equivalent:
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; If the ANSI_QUOTES SQL MODE is enabled, string literals can be quoted only within single quotation marks because a string quoted within double quotation marks is interpreted as an identifier.</description>
    </item>
    
    <item>
      <title>Loader Instructions</title>
      <link>https://pingcap.com/docs/dev/reference/tools/loader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/loader/</guid>
      <description>Loader Instructions What is Loader? Loader is a data import tool to load data to TiDB.
It can be downloaded as part of the Enterprise Tools package.
Why did we develop Loader? Since tools like mysqldump will take us days to migrate massive amounts of data, we used the mydumper/myloader suite to multi-thread export and import data. During the process, we found that mydumper works well. However, as myloader lacks functions of error retry and savepoint, it is inconvenient for us to use.</description>
    </item>
    
    <item>
      <title>Loader Instructions</title>
      <link>https://pingcap.com/docs/v2.1/tools/loader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/loader/</guid>
      <description>Loader Instructions What is Loader? Loader is a data import tool to load data to TiDB.
Download the Binary.
Why did we develop Loader? Since tools like mysqldump will take us days to migrate massive amounts of data, we used the mydumper/myloader suite to multi-thread export and import data. During the process, we found that mydumper works well. However, as myloader lacks functions of error retry and savepoint, it is inconvenient for us to use.</description>
    </item>
    
    <item>
      <title>Local Deployment from Binary Tarball</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-binary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-binary/</guid>
      <description>Local Deployment from Binary Tarball This guide provides installation instructions for all TiDB components on a single developer machine. It is intended for evaluation purposes, and does not match the recommended usage for production systems.
See also testing environment and production enviroment deployment.
The following local TCP ports will be used:
   Component Port Protocol Description     TiDB 4000 TCP the communication port for the application and DBA tools   TiDB 10080 TCP the communication port to report TiDB status   TiKV 20160 TCP the TiKV communication port   PD 2379 TCP the communication port between TiDB and PD   PD 2380 TCP the inter-node communication port within the PD cluster    Prepare This guide is for deployment on Linux only.</description>
    </item>
    
    <item>
      <title>MODIFY COLUMN | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/modify-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/modify-column/</guid>
      <description>MODIFY COLUMN The ALTER TABLE.. MODIFY COLUMN statement modifies a column on an existing table. The modification can include changing the data type and attributes. To rename at the same time, use the CHANGE COLUMN statement instead.
Synopsis AlterTableStmt:
AlterTableSpec:
ColumnKeywordOpt:
ColumnDef:
ColumnPosition:
Examples mysql&amp;gt; CREATE TABLE t1 (id int not null primary key auto_increment, col1 INT); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (col1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.</description>
    </item>
    
    <item>
      <title>Manage the Data Synchronization Task</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/manage-tasks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/manage-tasks/</guid>
      <description>Manage the Data Synchronization Task This document describes how to manage and maintain the data synchronization task using the dmctl component. For the Data Migration cluster deployed using DM-Ansible, the dmctl binary file is in dm-ansible/dmctl.
dmctl basic usage This section shows the basic usage of dmctl commands.
dmctl help $ ./dmctl --help Usage of dmctl: # Prints the version information.  -V prints version and exit # Encrypts the database password according to the encryption method provided by DM; used in DM configuration files.</description>
    </item>
    
    <item>
      <title>Manage the Data Synchronization Task</title>
      <link>https://pingcap.com/docs/v2.1/tools/data-migration-manage-task/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/data-migration-manage-task/</guid>
      <description>Manage the Data Synchronization Task This document describes how to manage and maintain the data synchronization task using the dmctl component. For the Data Migration cluster deployed using DM-Ansible, the dmctl binary file is in dm-ansible/dmctl.
dmctl basic usage This section shows the basic usage of dmctl commands.
dmctl help $ ./dmctl --help Usage of dmctl: -V prints version and exit # Prints the version information.  -encrypt string # Encrypts the database password according to the encryption method provided by DM; used in DM configuration files.</description>
    </item>
    
    <item>
      <title>Merge and Replicate Data from Sharded Tables</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/features/shard-merge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/features/shard-merge/</guid>
      <description>Merge and Replicate Data from Sharded Tables This document introduces the sharding support feature provided by Data Migration (DM). This feature allows you to merge and replicate the data of tables with the same table schema in the upstream MySQL or MariaDB instances into one same table in the downstream TiDB. It supports not only replicating the upstream DML statements, but also coordinating to replicate the table schema change using DDL statements in multiple upstream sharded tables.</description>
    </item>
    
    <item>
      <title>Migrate Data from MySQL to TiDB</title>
      <link>https://pingcap.com/docs/dev/how-to/migrate/from-mysql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/migrate/from-mysql/</guid>
      <description>Migrate Data from MySQL to TiDB Use the mydumper/loader tool to export and import all the data You can use mydumper to export data from MySQL and loader to import the data into TiDB.
 Note:
Although TiDB also supports the official mysqldump tool from MySQL for data migration, it is not recommended to use it. Its performance is much lower than mydumper / loader and it takes much time to migrate large amounts of data.</description>
    </item>
    
    <item>
      <title>Migrate Data from MySQL to TiDB</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/migration/</guid>
      <description>Migrate Data from MySQL to TiDB Use the mydumper/loader tool to export and import all the data You can use mydumper to export data from MySQL and loader to import the data into TiDB.
 Note:
Although TiDB also supports the official mysqldump tool from MySQL for data migration, it is not recommended to use it. Its performance is much lower than mydumper / loader and it takes much time to migrate large amounts of data.</description>
    </item>
    
    <item>
      <title>Migrate Incrementally Using Syncer</title>
      <link>https://pingcap.com/docs/dev/how-to/migrate/incrementally-from-mysql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/migrate/incrementally-from-mysql/</guid>
      <description>Migrate Incrementally Using Syncer The previous guide introduces how to import a full database from MySQL to TiDB using mydumper/loader. This methodology is not recommended for large databases with frequent updates, since it can lead to a larger downtime window during migration. It is instead recommended to use syncer.
Syncer can be downloaded as part of Enterprise Tools.
Assuming the data from t1 and t2 is already imported to TiDB using mydumper/loader.</description>
    </item>
    
    <item>
      <title>Migrate from Amazon Aurora MySQL to TiDB</title>
      <link>https://pingcap.com/docs/dev/how-to/migrate/from-aurora/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/migrate/from-aurora/</guid>
      <description>Migrate from Amazon Aurora MySQL to TiDB This document describes how to migrate from Amazon Aurora MySQL to TiDB by using TiDB Data Migration (DM).
Step 1: Enable binlog in the Aurora cluster Assuming that you want to migrate data from two Aurora clusters to TiDB, the information of the Aurora clusters is listed in the following table. The Aurora-1 cluster contains a seperate reader endpoint.
   Cluster Endpoint Port Role     Aurora-1 pingcap-1.</description>
    </item>
    
    <item>
      <title>Migration Overview</title>
      <link>https://pingcap.com/docs/dev/how-to/migrate/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/migrate/overview/</guid>
      <description>Migration Overview This document describes scenarios for migrating data into TiDB from either MySQL or another data source via CSV format.
Tools overview Migrations will often make use of the following tools. The following is a brief overview of their usage:
 mydumper exports data from MySQL. It is recommended over using mysqldump. loader imports data in mydumper format into TiDB. syncer acts like a MySQL replication slave and pushes data from MySQL into TiDB.</description>
    </item>
    
    <item>
      <title>Migration Overview</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/migration-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/migration-overview/</guid>
      <description>Migration Overview Overview This document describes how to migrate data from MySQL to TiDB in detail.
See the following for the assumed MySQL and TiDB server information:
   Name Address Port User Password     MySQL 127.0.0.1 3306 root *   TiDB 127.0.0.1 4000 root *    Scenarios  To import all the history data. This needs the following tools:
 Checker: to check if the schema is compatible with TiDB.</description>
    </item>
    
    <item>
      <title>Miscellaneous Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/miscellaneous-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/miscellaneous-functions/</guid>
      <description> Miscellaneous Functions    Name Description     ANY_VALUE() Suppress ONLY_FULL_GROUP_BY value rejection   SLEEP() Sleep for a number of seconds   UUID() Return a Universal Unique Identifier (UUID)   VALUES() Defines the values to be used during an INSERT   INET_ATON() Return the numeric value of an IP address   INET_NTOA() Return the IP address from a numeric value   INET6_ATON() Return the numeric value of an IPv6 address   INET6_NTOA() Return the IPv6 address from a numeric value   IS_IPV4() Whether argument is an IPv4 address   IS_IPV4_COMPAT() Whether argument is an IPv4-compatible address   IS_IPV4_MAPPED() Whether argument is an IPv4-mapped address   IS_IPV6() Whether argument is an IPv6 address   GET_LOCK() Get a named lock   RELEASE_LOCK() Releases the named lock    </description>
    </item>
    
    <item>
      <title>Miscellaneous Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/miscellaneous-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/miscellaneous-functions/</guid>
      <description> Miscellaneous Functions    Name Description     ANY_VALUE() Suppress ONLY_FULL_GROUP_BY value rejection   SLEEP() Sleep for a number of seconds   UUID() Return a Universal Unique Identifier (UUID)   VALUES() Defines the values to be used during an INSERT   INET_ATON() Return the numeric value of an IP address   INET_NTOA() Return the IP address from a numeric value   INET6_ATON() Return the numeric value of an IPv6 address   INET6_NTOA() Return the IPv6 address from a numeric value   IS_IPV4() Whether argument is an IPv4 address   IS_IPV4_COMPAT() Whether argument is an IPv4-compatible address   IS_IPV4_MAPPED() Whether argument is an IPv4-mapped address   IS_IPV6() Whether argument is an IPv6 address   GET_LOCK() Get a named lock   RELEASE_LOCK() Releases the named lock    </description>
    </item>
    
    <item>
      <title>Monitor a TiDB Cluster</title>
      <link>https://pingcap.com/docs/dev/how-to/monitor/monitor-a-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/monitor/monitor-a-cluster/</guid>
      <description>Monitor a TiDB Cluster You can use the following two types of interfaces to monitor the TiDB cluster state:
 The state interface: this interface uses the HTTP interface to get the component information. The metrics interface: this interface uses Prometheus to record the detailed information of the various operations in components and view these metrics using Grafana.  Use the state interface The state interface monitors the basic information of a specific component in the TiDB cluster.</description>
    </item>
    
    <item>
      <title>Monitor a TiDB Cluster</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/monitor/</guid>
      <description>Monitor a TiDB Cluster Currently there are two types of interfaces to monitor the state of the TiDB cluster:
 Using the HTTP interface to get the internal information of a component, which is called the component state interface. Using Prometheus to record the detailed information of the various operations in the components, which is called the Metrics interface.  The component state interface You can use this type of interface to monitor the basic information of the component.</description>
    </item>
    
    <item>
      <title>Numeric Functions and Operators</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/numeric-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/numeric-functions-and-operators/</guid>
      <description> Numeric Functions and Operators This document describes the arithmetic operators and mathematical functions.
Arithmetic operators    Name Description     + Addition operator   - Minus operator   * Multiplication operator   / Division operator   DIV Integer division   %, MOD Modulo operator   - Change the sign of the argument    Mathematical functions    Name Description     POW() Return the argument raised to the specified power   POWER() Return the argument raised to the specified power   EXP() Raise to the power of   SQRT() Return the square root of the argument   LN() Return the natural logarithm of the argument   LOG() Return the natural logarithm of the first argument   LOG2() Return the base-2 logarithm of the argument   LOG10() Return the base-10 logarithm of the argument   PI() Return the value of pi   TAN() Return the tangent of the argument   COT() Return the cotangent   SIN() Return the sine of the argument   COS() Return the cosine   ATAN() Return the arc tangent   ATAN2(), ATAN() Return the arc tangent of the two arguments   ASIN() Return the arc sine   ACOS() Return the arc cosine   RADIANS() Return argument converted to radians   DEGREES() Convert radians to degrees   MOD() Return the remainder   ABS() Return the absolute value   CEIL() Return the smallest integer value not less than the argument   CEILING() Return the smallest integer value not less than the argument   FLOOR() Return the largest integer value not greater than the argument   ROUND() Round the argument   RAND() Return a random floating-point value   SIGN() Return the sign of the argument   CONV() Convert numbers between different number bases   TRUNCATE() Truncate to specified number of decimal places   CRC32() Compute a cyclic redundancy check value    </description>
    </item>
    
    <item>
      <title>Numeric Functions and Operators</title>
      <link>https://pingcap.com/docs/v2.1/sql/numeric-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/numeric-functions-and-operators/</guid>
      <description> Numeric Functions and Operators This document describes the arithmetic operators and mathematical functions.
Arithmetic operators    Name Description     + Addition operator   - Minus operator   * Multiplication operator   / Division operator   DIV Integer division   %, MOD Modulo operator   - Change the sign of the argument    Mathematical functions    Name Description     POW() Return the argument raised to the specified power   POWER() Return the argument raised to the specified power   EXP() Raise to the power of   SQRT() Return the square root of the argument   LN() Return the natural logarithm of the argument   LOG() Return the natural logarithm of the first argument   LOG2() Return the base-2 logarithm of the argument   LOG10() Return the base-10 logarithm of the argument   PI() Return the value of pi   TAN() Return the tangent of the argument   COT() Return the cotangent   SIN() Return the sine of the argument   COS() Return the cosine   ATAN() Return the arc tangent   ATAN2(), ATAN() Return the arc tangent of the two arguments   ASIN() Return the arc sine   ACOS() Return the arc cosine   RADIANS() Return argument converted to radians   DEGREES() Convert radians to degrees   MOD() Return the remainder   ABS() Return the absolute value   CEIL() Return the smallest integer value not less than the argument   CEILING() Return the smallest integer value not less than the argument   FLOOR() Return the largest integer value not greater than the argument   ROUND() Round the argument   RAND() Return a random floating-point value   SIGN() Return the sign of the argument   CONV() Convert numbers between different number bases   TRUNCATE() Truncate to specified number of decimal places   CRC32() Compute a cyclic redundancy check value    </description>
    </item>
    
    <item>
      <title>Operators</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/operators/</guid>
      <description>Operators This document describes the operators precedence, comparison functions and operators, logical operators, and assignment operators.
 Operator precedence Comparison functions and operators Logical operators Assignment operators     Name Description     AND, &amp;amp;&amp;amp; Logical AND   = Assign a value (as part of a SET statement, or as part of the SET clause in an UPDATE statement)   := Assign a value   BETWEEN &amp;hellip; AND &amp;hellip; Check whether a value is within a range of values   BINARY Cast a string to a binary string   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   CASE Case operator   DIV Integer division   / Division operator   = Equal operator   &amp;lt;=&amp;gt; NULL-safe equal to operator   &amp;gt; Greater than operator   &amp;gt;= Greater than or equal operator   IS Test a value against a boolean   IS NOT Test a value against a boolean   IS NOT NULL NOT NULL value test   IS NULL NULL value test   -&amp;gt; Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT()   -&amp;gt;&amp;gt; Return value from JSON column after evaluating path and unquoting the result; equivalent to JSON_UNQUOTE(JSON_EXTRACT())   &amp;lt;&amp;lt; Left shift   &amp;lt; Less than operator   &amp;lt;= Less than or equal operator   LIKE Simple pattern matching   - Minus operator   %, MOD Modulo operator   NOT, !</description>
    </item>
    
    <item>
      <title>Operators</title>
      <link>https://pingcap.com/docs/v2.1/sql/operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/operators/</guid>
      <description>Operators This document describes the operators precedence, comparison functions and operators, logical operators, and assignment operators.
 Operator precedence Comparison functions and operators Logical operators Assignment operators     Name Description     AND, &amp;amp;&amp;amp; Logical AND   = Assign a value (as part of a SET statement, or as part of the SET clause in an UPDATE statement)   := Assign a value   BETWEEN &amp;hellip; AND &amp;hellip; Check whether a value is within a range of values   BINARY Cast a string to a binary string   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   CASE Case operator   DIV Integer division   / Division operator   = Equal operator   &amp;lt;=&amp;gt; NULL-safe equal to operator   &amp;gt; Greater than operator   &amp;gt;= Greater than or equal operator   IS Test a value against a boolean   IS NOT Test a value against a boolean   IS NOT NULL NOT NULL value test   IS NULL NULL value test   -&amp;gt; Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT()   -&amp;gt;&amp;gt; Return value from JSON column after evaluating path and unquoting the result; equivalent to JSON_UNQUOTE(JSON_EXTRACT())   &amp;lt;&amp;lt; Left shift   &amp;lt; Less than operator   &amp;lt;= Less than or equal operator   LIKE Simple pattern matching   - Minus operator   %, MOD Modulo operator   NOT, !</description>
    </item>
    
    <item>
      <title>Optimizer Hints</title>
      <link>https://pingcap.com/docs/dev/reference/performance/optimizer-hints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/performance/optimizer-hints/</guid>
      <description>Optimizer Hints TiDB supports optimizer hints, based on the comment-like syntax introduced in MySQL 5.7. i.e. /*+ TIDB_XX(t1, t2) */. Use of optimizer hints is recommended in cases where the TiDB optimizer selects a less optimal query plan.
 Note:
MySQL command-line clients earlier than 5.7.7 strip optimizer hints by default. If you want to use the Hint syntax in these earlier versions, add the --comments option when starting the client.</description>
    </item>
    
    <item>
      <title>Overview of TiKV</title>
      <link>https://pingcap.com/docs/tikv/tikv-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/tikv-overview/</guid>
      <description>Overview of TiKV TiKV (The pronunciation is: /&amp;lsquo;takevi:/ tai-K-V, etymology: titanium) is a distributed Key-Value database which is based on the design of Google Spanner and HBase, but it is much simpler without dependency on any distributed file system.
As the storage layer of TiDB, TiKV can work separately and does not depend on the SQL layer of TiDB. To apply to different scenarios, TiKV provides two types of APIs for developers: the Raw Key-Value API and the Transactional Key-Value API.</description>
    </item>
    
    <item>
      <title>Overview of TiKV</title>
      <link>https://pingcap.com/docs/v2.1/tikv/tikv-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tikv/tikv-overview/</guid>
      <description>Overview of TiKV TiKV (The pronunciation is: /&amp;lsquo;takevi:/ tai-K-V, etymology: titanium) is a distributed Key-Value database which is based on the design of Google Spanner and HBase, but it is much simpler without dependency on any distributed file system.
As the storage layer of TiDB, TiKV can work separately and does not depend on the SQL layer of TiDB. To apply to different scenarios, TiKV provides two types of APIs for developers: the Raw Key-Value API and the Transactional Key-Value API.</description>
    </item>
    
    <item>
      <title>PD Configuration Flags</title>
      <link>https://pingcap.com/docs/dev/reference/configuration/pd-server/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/configuration/pd-server/configuration/</guid>
      <description>PD Configuration Flags PD is configurable using command-line flags and environment variables.
--advertise-client-urls  The advertise URL list for client traffic from outside Default: ${client-urls} If the client cannot connect to PD through the default listening client URLs, you must manually set the advertise client URLs explicitly. For example, the internal IP address of Docker is 172.17.0.1, while the IP address of the host is 192.168.100.113 and the port mapping is set to -p 2379:2379.</description>
    </item>
    
    <item>
      <title>PD Control User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/pd-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/pd-control/</guid>
      <description>PD Control User Guide As a command line tool of PD, PD Control obtains the state information of the cluster and tunes the cluster.
Source code compiling  Go Version 1.9 or later In the root directory of the PD project, use the make command to compile and generate bin/pd-ctl   Note:
Generally, you don&amp;rsquo;t need to compile source code as the PD Control tool already exists in the released Binary or Docker.</description>
    </item>
    
    <item>
      <title>PD Control User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/pd-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/pd-control/</guid>
      <description>PD Control User Guide As a command line tool of PD, PD Control obtains the state information of the cluster and tunes the cluster.
Source code compiling  Go Version 1.9 or later In the root directory of the PD project, use the make command to compile and generate bin/pd-ctl   Note:
Generally, you don&amp;rsquo;t need to compile source code as the PD Control tool already exists in the released Binary or Docker.</description>
    </item>
    
    <item>
      <title>PD Recover User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/pd-recover/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/pd-recover/</guid>
      <description>PD Recover User Guide PD Recover is a disaster recovery tool of PD, used to recover the PD cluster which cannot start or provide services normally.
Source code compiling  Go Version 1.9 or later In the root directory of the PD project, use the make command to compile and generate bin/pd-recover  Usage This section describes how to recover a PD cluster which cannot start or provide services normally.</description>
    </item>
    
    <item>
      <title>PD Recover User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/pd-recover/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/pd-recover/</guid>
      <description>PD Recover User Guide PD Recover is a disaster recovery tool of PD, used to recover the PD cluster which cannot start or provide services normally.
Source code compiling  Go Version 1.9 or later In the root directory of the PD project, use the make command to compile and generate bin/pd-recover  Usage This section describes how to recover a PD cluster which cannot start or provide services normally.</description>
    </item>
    
    <item>
      <title>PREPARE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/prepare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/prepare/</guid>
      <description>PREPARE The PREPARE statement provides an SQL interface to server-side prepared statements.
Synopsis PreparedStmt:
Examples mysql&amp;gt; PREPARE mystmt FROM &amp;#39;SELECT ? as num FROM DUAL&amp;#39;; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; SET @number = 5; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; EXECUTE mystmt USING @number; +------+ | num | +------+ | 5 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; DEALLOCATE PREPARE mystmt; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Pre-GA release notes</title>
      <link>https://pingcap.com/docs/releases/prega/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/prega/</guid>
      <description> Pre-GA Release Notes On August 30, 2017, TiDB Pre-GA is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Use index scan to handle the where clause with the compare expression which has different types on each side Support the Greedy algorithm based Join Reorder  Many enhancements have been introduced to be more compatible with MySQL Support Natural Join Support the JSON type (Experimental), including the query, update and index of the JSON fields Prune the useless data to reduce the consumption of the executor memory Support configuring prioritization in the SQL statements and automatically set the prioritization for some of the statements according to the query type Completed the expression refactor and the speed is increased by about 30%  Placement Driver (PD):  Support manually changing the leader of the PD cluster  TiKV:  Use dedicated Rocksdb instance to store Raft log Use DeleteRange to speed up the deleting of replicas Coprocessor now supports more pushdown operators Improve the performance and stability  TiDB Connector for Spark Beta Release:  Implement the predicates pushdown Implement the aggregation pushdown Implement range pruning Capable of running full set of TPC+H except for one query that needs view support  </description>
    </item>
    
    <item>
      <title>Pre-GA release notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/prega/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/prega/</guid>
      <description> Pre-GA Release Notes On August 30, 2017, TiDB Pre-GA is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Use index scan to handle the where clause with the compare expression which has different types on each side Support the Greedy algorithm based Join Reorder  Many enhancements have been introduced to be more compatible with MySQL Support Natural Join Support the JSON type (Experimental), including the query, update and index of the JSON fields Prune the useless data to reduce the consumption of the executor memory Support configuring prioritization in the SQL statements and automatically set the prioritization for some of the statements according to the query type Completed the expression refactor and the speed is increased by about 30%  Placement Driver (PD):  Support manually changing the leader of the PD cluster  TiKV:  Use dedicated Rocksdb instance to store Raft log Use DeleteRange to speed up the deleting of replicas Coprocessor now supports more pushdown operators Improve the performance and stability  TiDB Connector for Spark Beta Release:  Implement the predicates pushdown Implement the aggregation pushdown Implement range pruning Capable of running full set of TPC+H except for one query that needs view support  </description>
    </item>
    
    <item>
      <title>Precheck the upstream MySQL instance configuration</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/precheck/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/precheck/</guid>
      <description>Precheck the upstream MySQL instance configuration This document introduces the precheck feature provided by DM. This feature is used to detect possible errors in the upstream MySQL instance configuration when the data replication task is started.
Command check-task allows you to precheck whether the upstream MySQL instance configuration satisfies the DM requirements.
Checking items Upstream and downstream database users must have the corresponding read and write privileges. DM checks the following privileges and configuration automatically while the data replication task is started:</description>
    </item>
    
    <item>
      <title>Precision Math</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/precision-math/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/precision-math/</guid>
      <description>Precision Math The precision math support in TiDB is consistent with MySQL. For more information, see Precision Math in MySQL.
Numeric types The scope of precision math for exact-value operations includes the exact-value data types (integer and DECIMAL types) and exact-value numeric literals. Approximate-value data types and numeric literals are handled as floating-point numbers.
Exact-value numeric literals have an integer part or fractional part, or both. They may be signed.</description>
    </item>
    
    <item>
      <title>Precision Math</title>
      <link>https://pingcap.com/docs/v2.1/sql/precision-math/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/precision-math/</guid>
      <description>Precision Math The precision math support in TiDB is consistent with MySQL. For more information, see Precision Math in MySQL.
Numeric types The scope of precision math for exact-value operations includes the exact-value data types (integer and DECIMAL types) and exact-value numeric literals. Approximate-value data types and numeric literals are handled as floating-point numbers.
Exact-value numeric literals have an integer part or fractional part, or both. They may be signed.</description>
    </item>
    
    <item>
      <title>Prepared SQL Statement Syntax</title>
      <link>https://pingcap.com/docs/v2.1/sql/prepare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/prepare/</guid>
      <description>Prepared SQL Statement Syntax TiDB supports server-side Prepared statements, which can reduce the load of statement parsing and query optimization and improve execution efficiency. You can use Prepared statements in two ways: application programs and SQL statements.
Use application programs Most MySQL Drivers support Prepared statements, such as MySQL Connector/C. You can call the Prepared statement API directly through the Binary protocol.
Use SQL statements You can also implement Prepared statements using PREPARE, EXECUTE and DEALLOCATE PREPARE.</description>
    </item>
    
    <item>
      <title>Privilege Management</title>
      <link>https://pingcap.com/docs/dev/reference/security/privilege-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/security/privilege-system/</guid>
      <description>Privilege Management TiDB supports MySQL 5.7&amp;rsquo;s privilege management system, including the syntax and privilege types. Starting with TiDB 3.0, support for SQL Roles is also available.
This document introduces privilege-related TiDB operations, privileges required for TiDB operations and implementation of the privilege system.
Privilege-related operations Grant privileges The GRANT statement grants privileges to the user accounts.
For example, use the following statement to grant the xxx user the privilege to read the test database.</description>
    </item>
    
    <item>
      <title>Privilege Management</title>
      <link>https://pingcap.com/docs/v2.1/sql/privilege/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/privilege/</guid>
      <description>Privilege Management TiDB&amp;rsquo;s privilege management system is implemented according to the privilege management system in MySQL. It supports most of the syntaxes and privilege types in MySQL. If you find any inconsistency with MySQL, feel free to open an issue.
Examples User account operation TiDB user account names consist of a user name and a host name. The account name syntax is &#39;user_name&#39;@&#39;host_name&#39;.
 The user_name is case sensitive. The host_name can be a host name or an IP address.</description>
    </item>
    
    <item>
      <title>Production Deployment from Binary Tarball</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/from-tarball/production-environment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/from-tarball/production-environment/</guid>
      <description>Production Deployment from Binary Tarball This guide provides installation instructions from a binary tarball on Linux. A complete TiDB cluster contains PD, TiKV, and TiDB. To start the database service, follow the order of PD -&amp;gt; TiKV -&amp;gt; TiDB. To stop the database service, follow the order of stopping TiDB -&amp;gt; TiKV -&amp;gt; PD.
See also local deployment and testing environment deployment.
Prepare Before you start, see TiDB architecture and Software and Hardware Recommendations.</description>
    </item>
    
    <item>
      <title>RENAME INDEX | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/rename-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/rename-index/</guid>
      <description>RENAME INDEX The statement ALTER TABLE .. RENAME INDEX renames an existing index to a new name. This operation is instant in TiDB, and requires only a meta data change.
Synopsis AlterTableStmt:
KeyOrIndex:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL, INDEX col1 (c1)); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; SHOW CREATE TABLE t1\G *************************** 1. row *************************** Table: t1 Create Table: CREATE TABLE `t1` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c1` int(11) NOT NULL, PRIMARY KEY (`id`), KEY `col1` (`c1`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin 1 row in set (0.</description>
    </item>
    
    <item>
      <title>RENAME TABLE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/rename-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/rename-table/</guid>
      <description>RENAME TABLE This statement renames an existing table to a new name.
Synopsis RenameTableStmt:
TableToTable:
Examples mysql&amp;gt; CREATE TABLE t1 (a int); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; SHOW TABLES; +----------------+ | Tables_in_test | +----------------+ | t1 | +----------------+ 1 row in set (0.00 sec) mysql&amp;gt; RENAME TABLE t1 TO t2; Query OK, 0 rows affected (0.08 sec) mysql&amp;gt; SHOW TABLES; +----------------+ | Tables_in_test | +----------------+ | t2 | +----------------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>REPLACE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/replace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/replace/</guid>
      <description>REPLACE The REPLACE statement is semantically a combined DELETE+INSERT statement. It can be used to simplify application code.
Synopsis ReplaceIntoStmt:
PriorityOpt:
IntoOpt:
TableName:
InsertValues:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1), (2), (3); Query OK, 3 rows affected (0.02 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql&amp;gt; SELECT * FROM t1; +----+----+ | id | c1 | +----+----+ | 1 | 1 | | 2 | 2 | | 3 | 3 | +----+----+ 3 rows in set (0.</description>
    </item>
    
    <item>
      <title>REVOKE &lt;privileges&gt; | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/revoke-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/revoke-privileges/</guid>
      <description>REVOKE  This statement removes privileges from an existing user.
Synopsis GrantStmt:
PrivElemList:
PrivElem:
PrivType:
ObjectType:
PrivLevel:
UserSpecList:
Examples mysql&amp;gt; CREATE USER newuser IDENTIFIED BY &amp;#39;mypassword&amp;#39;; Query OK, 1 row affected (0.02 sec) mysql&amp;gt; GRANT ALL ON test.* TO &amp;#39;newuser&amp;#39;; Query OK, 0 rows affected (0.03 sec) mysql&amp;gt; SHOW GRANTS FOR &amp;#39;newuser&amp;#39;; +-------------------------------------------------+ | Grants for newuser@% | +-------------------------------------------------+ | GRANT USAGE ON *.* TO &amp;#39;newuser&amp;#39;@&amp;#39;%&amp;#39; | | GRANT ALL PRIVILEGES ON test.</description>
    </item>
    
    <item>
      <title>ROLLBACK | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/rollback/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/rollback/</guid>
      <description>ROLLBACK This statement reverts all changes in the current transaction inside of TIDB. It is the opposite of a COMMIT statement.
Synopsis Statement:
Examples mysql&amp;gt; CREATE TABLE t1 (a int NOT NULL PRIMARY KEY); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; BEGIN; Query OK, 0 rows affected (0.00 sec) mysql&amp;gt; INSERT INTO t1 VALUES (1); Query OK, 1 row affected (0.00 sec) mysql&amp;gt; ROLLBACK; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Read Historical Data</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/read-historical-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/read-historical-data/</guid>
      <description>Read Historical Data This document describes how TiDB reads data from the history versions, how TiDB manages the data versions, as well as an example to show how to use the feature.
Feature description TiDB implements a feature to read history data using the standard SQL interface directly without special clients or drivers. By using this feature:
 Even when data is updated or removed, its history versions can be read using the SQL interface.</description>
    </item>
    
    <item>
      <title>Reading Data from History Versions</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/history-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/history-read/</guid>
      <description>Reading Data From History Versions This document describes how TiDB reads data from the history versions, how TiDB manages the data versions, as well as an example to show how to use the feature.
Feature description TiDB implements a feature to read history data using the standard SQL interface directly without special clients or drivers. By using this feature:
 Even when data is updated or removed, its history versions can be read using the SQL interface.</description>
    </item>
    
    <item>
      <title>Release Notes</title>
      <link>https://pingcap.com/docs/releases/rn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rn/</guid>
      <description>TiDB Release Notes 3.0  3.0.0-rc.1 3.0.0-beta.1 3.0.0-beta  2.1  2.1.10 2.1.9 2.1.8 2.1.7 2.1.6 2.1.5 2.1.4 2.1.3 2.1.2 2.1.1 2.1 GA 2.1 RC5 2.1 RC4 2.1 RC3 2.1 RC2 2.1 RC1 2.1 Beta  2.0  2.0.11 2.0.10 2.0.9 2.0.8 2.0.7 2.0.6 2.0.5 2.0.4 2.0.3 2.0.2 2.0.1 2.0 2.0 RC5 2.0 RC4 2.0 RC3 2.0 RC1 1.1 Beta 1.1 Alpha  1.0  1.0.8 1.0.7 1.0.6 1.0.5 1.</description>
    </item>
    
    <item>
      <title>Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/rn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/rn/</guid>
      <description> TiDB Release Notes  2.0.11 2.1.2 2.0.10 2.1.1 2.1 GA 2.0.9 2.1 RC5 2.1 RC4 2.0.8 2.1 RC3 2.1 RC2 2.0.7 2.1 RC1 2.0.6 2.0.5 2.1 Beta 2.0.4 2.0.3 2.0.2 2.0.1 2.0 2.0 RC5 2.0 RC4 2.0 RC3 2.0 RC1 1.1 Beta 1.0.8 1.0.7 1.1 Alpha 1.0.6 1.0.5 1.0.4 1.0.3 1.0.2 1.0.1 1.0 Pre-GA RC4 RC3 RC2 RC1  </description>
    </item>
    
    <item>
      <title>Reparo User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/reparo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/reparo/</guid>
      <description>Reparo User Guide Reparo is a TiDB-Binlog tool, used to recover the incremental data. To back up the incremental data, you can use Drainer of TiDB-Binlog to output the binlog data in the protobuf format to files. To restore the incremental data, you can use Reparo to parse the binlog data in the files and apply the binlog in TiDB/MySQL.
Download Reparo via tidb-binlog-cluster-latest-linux-amd64.tar.gz
Reparo usage Description of command line parameters Usage of Reparo: -L string The level of the output information of logs Value: &amp;#34;debug&amp;#34;/&amp;#34;info&amp;#34;/&amp;#34;warn&amp;#34;/&amp;#34;error&amp;#34;/&amp;#34;fatal&amp;#34; (&amp;#34;info&amp;#34; by default) -V Prints the version.</description>
    </item>
    
    <item>
      <title>Reparo User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/reparo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/reparo/</guid>
      <description>Reparo User Guide Reparo is a TiDB-Binlog tool, used to recover the incremental data. To back up the incremental data, you can use Drainer of TiDB-Binlog to output the binlog data in the protobuf format to files. To restore the incremental data, you can use Reparo to parse the binlog data in the files and apply the binlog in TiDB/MySQL.
Download Reparo via reparo-latest-linux-amd64.tar.gz
Reparo usage Description of command line parameters Usage of Reparo: -L string The level of the output information of logs Value: &amp;#34;debug&amp;#34;/&amp;#34;info&amp;#34;/&amp;#34;warn&amp;#34;/&amp;#34;error&amp;#34;/&amp;#34;fatal&amp;#34; (&amp;#34;info&amp;#34; by default) -V Prints the version.</description>
    </item>
    
    <item>
      <title>Report an Issue</title>
      <link>https://pingcap.com/docs/report-issue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/report-issue/</guid>
      <description>Report an Issue We strive to make TiDB compatible with MySQL 5.7. If you discover a difference in behavior that is not documented, a bug, or strange performance characteristics please create a new issue in GitHub.
You may use GitHub issues for Bug Reports, Feature Requests, General Questions and Performance Questions. Please make sure that you fill out the issue template completely so we can respond appropriately.</description>
    </item>
    
    <item>
      <title>SELECT | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/select/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/select/</guid>
      <description>SELECT The SELECT statement is used to read data from TiDB.
Synopsis SelectStmt:
FromDual:
WhereClauseOptional:
SelectStmtOpts:
SelectStmtFieldList:
TableRefsClause:
WhereClauseOptional:
SelectStmtGroup:
HavingClause:
OrderByOptional:
SelectStmtLimit:
SelectLockOpt:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.03 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql&amp;gt; SELECT * FROM t1; +----+----+ | id | c1 | +----+----+ | 1 | 1 | | 2 | 2 | | 3 | 3 | | 4 | 4 | | 5 | 5 | +----+----+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>SET PASSWORD | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/set-password/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/set-password/</guid>
      <description>SET PASSWORD This statement changes the user password for a user account in the TiDB system database.
Synopsis SetStmt:
Examples mysql&amp;gt; SET PASSWORD=&amp;#39;test&amp;#39;; -- change my password Query OK, 0 rows affected (0.01 sec) mysql&amp;gt; CREATE USER &amp;#39;newuser&amp;#39; IDENTIFIED BY &amp;#39;test&amp;#39;; Query OK, 1 row affected (0.00 sec) mysql&amp;gt; SHOW CREATE USER newuser; +----------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | CREATE USER for newuser@% | +----------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | CREATE USER &amp;#39;newuser&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED WITH &amp;#39;mysql_native_password&amp;#39; AS &amp;#39;*94BDCEBE19083CE2A1F959FD02F964C7AF4CFC29&amp;#39; REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK | +----------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>SET TRANSACTION | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/set-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/set-transaction/</guid>
      <description>SET TRANSACTION The SET TRANSACTION statement can be used to change the current isolation level on a GLOBAL or SESSION basis. This syntax is an alternative to SET transaction_isolation=&#39;new-value&#39; and is included for compatibility with both MySQL, and the SQL standards.
Synopsis SetStmt:
TransactionChar:
IsolationLevel:
Examples mysql&amp;gt; SHOW SESSION VARIABLES like &amp;#39;transaction_isolation&amp;#39;; +-----------------------+-----------------+ | Variable_name | Value | +-----------------------+-----------------+ | transaction_isolation | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>SET [GLOBAL|SESSION] &lt;variable&gt; | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/set-variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/set-variable/</guid>
      <description>SET [GLOBAL|SESSION]  The statement SET [GLOBAL|SESSION] modifies one of TiDB&amp;rsquo;s built in variables, of either SESSION or GLOBAL scope. Note that similar to MySQL, changes to GLOBAL variables will not apply to either existing connections, or the local connection. Only new sessions will reflect the changes to the value.
Synopsis SetStmt:
Examples mysql&amp;gt; SHOW GLOBAL VARIABLES LIKE &amp;#39;sql_mode&amp;#39;; +---------------+-------------------------------------------------------------------------------------------------------------------------------------------+ | Variable_name | Value | +---------------+-------------------------------------------------------------------------------------------------------------------------------------------+ | sql_mode | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION | +---------------+-------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>SET [NAMES|CHARACTER SET] |  TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/set-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/set-names/</guid>
      <description>SET [NAMES|CHARACTER SET] The statements SET NAMES, SET CHARACTER SET and SET CHARSET modify the variables character_set_client, character_set_results and character_set_connection for the current connection.
Synopsis SetStmt:
Examples mysql&amp;gt; SHOW VARIABLES LIKE &amp;#39;character_set%&amp;#39;; +--------------------------+--------------------------------------------------------+ | Variable_name | Value | +--------------------------+--------------------------------------------------------+ | character_sets_dir | /usr/local/mysql-5.6.25-osx10.8-x86_64/share/charsets/ | | character_set_connection | utf8mb4 | | character_set_system | utf8 | | character_set_results | utf8mb4 | | character_set_client | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_server | utf8mb4 | +--------------------------+--------------------------------------------------------+ 8 rows in set (0.</description>
    </item>
    
    <item>
      <title>SHOW CHARACTER SET | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-character-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-character-set/</guid>
      <description>SHOW CHARACTER SET This statement provides a static list of available character sets in TiDB. The output does not reflect any attributes of the current connection or user.
Synopsis ShowStmt:
ShowTargetFilterable:
CharsetKw:
Examples mysql&amp;gt; SHOW CHARACTER SET; +---------+---------------+-------------------+--------+ | Charset | Description | Default collation | Maxlen | +---------+---------------+-------------------+--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------+---------------+-------------------+--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>SHOW COLLATION | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-collation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-collation/</guid>
      <description>SHOW COLLATION This statement provides a static list of collations, and is included to provide compatibility with MySQL client libraries.
 Note: TiDB currently only supports binary collations.
 Synopsis ShowStmt:
ShowTargetFilterable:
Examples mysql&amp;gt; SHOW COLLATION; +--------------------------+----------+------+---------+----------+---------+ | Collation | Charset | Id | Default | Compiled | Sortlen | +--------------------------+----------+------+---------+----------+---------+ | big5_chinese_ci | big5 | 1 | Yes | Yes | 1 | | latin2_czech_cs | latin2 | 2 | | Yes | 1 | | dec8_swedish_ci | dec8 | 3 | Yes | Yes | 1 | | cp850_general_ci | cp850 | 4 | Yes | Yes | 1 | | latin1_german1_ci | latin1 | 5 | | Yes | 1 | | hp8_english_ci | hp8 | 6 | Yes | Yes | 1 | | koi8r_general_ci | koi8r | 7 | Yes | Yes | 1 | | latin1_swedish_ci | latin1 | 8 | Yes | Yes | 1 | | latin2_general_ci | latin2 | 9 | Yes | Yes | 1 | | swe7_swedish_ci | swe7 | 10 | Yes | Yes | 1 | | ascii_general_ci | ascii | 11 | Yes | Yes | 1 | | ujis_japanese_ci | ujis | 12 | Yes | Yes | 1 | | sjis_japanese_ci | sjis | 13 | Yes | Yes | 1 | | cp1251_bulgarian_ci | cp1251 | 14 | | Yes | 1 | | latin1_danish_ci | latin1 | 15 | | Yes | 1 | | hebrew_general_ci | hebrew | 16 | Yes | Yes | 1 | | tis620_thai_ci | tis620 | 18 | Yes | Yes | 1 | | euckr_korean_ci | euckr | 19 | Yes | Yes | 1 | | latin7_estonian_cs | latin7 | 20 | | Yes | 1 | | latin2_hungarian_ci | latin2 | 21 | | Yes | 1 | | koi8u_general_ci | koi8u | 22 | Yes | Yes | 1 | | cp1251_ukrainian_ci | cp1251 | 23 | | Yes | 1 | | gb2312_chinese_ci | gb2312 | 24 | Yes | Yes | 1 | | greek_general_ci | greek | 25 | Yes | Yes | 1 | | cp1250_general_ci | cp1250 | 26 | Yes | Yes | 1 | | latin2_croatian_ci | latin2 | 27 | | Yes | 1 | | gbk_chinese_ci | gbk | 28 | Yes | Yes | 1 | | cp1257_lithuanian_ci | cp1257 | 29 | | Yes | 1 | | latin5_turkish_ci | latin5 | 30 | Yes | Yes | 1 | | latin1_german2_ci | latin1 | 31 | | Yes | 1 | | armscii8_general_ci | armscii8 | 32 | Yes | Yes | 1 | | utf8_general_ci | utf8 | 33 | Yes | Yes | 1 | | cp1250_czech_cs | cp1250 | 34 | | Yes | 1 | | ucs2_general_ci | ucs2 | 35 | Yes | Yes | 1 | | cp866_general_ci | cp866 | 36 | Yes | Yes | 1 | | keybcs2_general_ci | keybcs2 | 37 | Yes | Yes | 1 | | macce_general_ci | macce | 38 | Yes | Yes | 1 | | macroman_general_ci | macroman | 39 | Yes | Yes | 1 | | cp852_general_ci | cp852 | 40 | Yes | Yes | 1 | | latin7_general_ci | latin7 | 41 | Yes | Yes | 1 | | latin7_general_cs | latin7 | 42 | | Yes | 1 | | macce_bin | macce | 43 | | Yes | 1 | | cp1250_croatian_ci | cp1250 | 44 | | Yes | 1 | | utf8mb4_general_ci | utf8mb4 | 45 | Yes | Yes | 1 | | utf8mb4_bin | utf8mb4 | 46 | | Yes | 1 | | latin1_bin | latin1 | 47 | | Yes | 1 | | latin1_general_ci | latin1 | 48 | | Yes | 1 | | latin1_general_cs | latin1 | 49 | | Yes | 1 | | cp1251_bin | cp1251 | 50 | | Yes | 1 | | cp1251_general_ci | cp1251 | 51 | Yes | Yes | 1 | | cp1251_general_cs | cp1251 | 52 | | Yes | 1 | | macroman_bin | macroman | 53 | | Yes | 1 | | utf16_general_ci | utf16 | 54 | Yes | Yes | 1 | | utf16_bin | utf16 | 55 | | Yes | 1 | | utf16le_general_ci | utf16le | 56 | Yes | Yes | 1 | | cp1256_general_ci | cp1256 | 57 | Yes | Yes | 1 | | cp1257_bin | cp1257 | 58 | | Yes | 1 | | cp1257_general_ci | cp1257 | 59 | Yes | Yes | 1 | | utf32_general_ci | utf32 | 60 | Yes | Yes | 1 | | utf32_bin | utf32 | 61 | | Yes | 1 | | utf16le_bin | utf16le | 62 | | Yes | 1 | | binary | binary | 63 | Yes | Yes | 1 | | armscii8_bin | armscii8 | 64 | | Yes | 1 | | ascii_bin | ascii | 65 | | Yes | 1 | | cp1250_bin | cp1250 | 66 | | Yes | 1 | | cp1256_bin | cp1256 | 67 | | Yes | 1 | | cp866_bin | cp866 | 68 | | Yes | 1 | | dec8_bin | dec8 | 69 | | Yes | 1 | | greek_bin | greek | 70 | | Yes | 1 | | hebrew_bin | hebrew | 71 | | Yes | 1 | | hp8_bin | hp8 | 72 | | Yes | 1 | | keybcs2_bin | keybcs2 | 73 | | Yes | 1 | | koi8r_bin | koi8r | 74 | | Yes | 1 | | koi8u_bin | koi8u | 75 | | Yes | 1 | | latin2_bin | latin2 | 77 | | Yes | 1 | | latin5_bin | latin5 | 78 | | Yes | 1 | | latin7_bin | latin7 | 79 | | Yes | 1 | | cp850_bin | cp850 | 80 | | Yes | 1 | | cp852_bin | cp852 | 81 | | Yes | 1 | | swe7_bin | swe7 | 82 | | Yes | 1 | | utf8_bin | utf8 | 83 | | Yes | 1 | | big5_bin | big5 | 84 | | Yes | 1 | | euckr_bin | euckr | 85 | | Yes | 1 | | gb2312_bin | gb2312 | 86 | | Yes | 1 | | gbk_bin | gbk | 87 | | Yes | 1 | | sjis_bin | sjis | 88 | | Yes | 1 | | tis620_bin | tis620 | 89 | | Yes | 1 | | ucs2_bin | ucs2 | 90 | | Yes | 1 | | ujis_bin | ujis | 91 | | Yes | 1 | | geostd8_general_ci | geostd8 | 92 | Yes | Yes | 1 | | geostd8_bin | geostd8 | 93 | | Yes | 1 | | latin1_spanish_ci | latin1 | 94 | | Yes | 1 | | cp932_japanese_ci | cp932 | 95 | Yes | Yes | 1 | | cp932_bin | cp932 | 96 | | Yes | 1 | | eucjpms_japanese_ci | eucjpms | 97 | Yes | Yes | 1 | | eucjpms_bin | eucjpms | 98 | | Yes | 1 | | cp1250_polish_ci | cp1250 | 99 | | Yes | 1 | | utf16_unicode_ci | utf16 | 101 | | Yes | 1 | | utf16_icelandic_ci | utf16 | 102 | | Yes | 1 | | utf16_latvian_ci | utf16 | 103 | | Yes | 1 | | utf16_romanian_ci | utf16 | 104 | | Yes | 1 | | utf16_slovenian_ci | utf16 | 105 | | Yes | 1 | | utf16_polish_ci | utf16 | 106 | | Yes | 1 | | utf16_estonian_ci | utf16 | 107 | | Yes | 1 | | utf16_spanish_ci | utf16 | 108 | | Yes | 1 | | utf16_swedish_ci | utf16 | 109 | | Yes | 1 | | utf16_turkish_ci | utf16 | 110 | | Yes | 1 | | utf16_czech_ci | utf16 | 111 | | Yes | 1 | | utf16_danish_ci | utf16 | 112 | | Yes | 1 | | utf16_lithuanian_ci | utf16 | 113 | | Yes | 1 | | utf16_slovak_ci | utf16 | 114 | | Yes | 1 | | utf16_spanish2_ci | utf16 | 115 | | Yes | 1 | | utf16_roman_ci | utf16 | 116 | | Yes | 1 | | utf16_persian_ci | utf16 | 117 | | Yes | 1 | | utf16_esperanto_ci | utf16 | 118 | | Yes | 1 | | utf16_hungarian_ci | utf16 | 119 | | Yes | 1 | | utf16_sinhala_ci | utf16 | 120 | | Yes | 1 | | utf16_german2_ci | utf16 | 121 | | Yes | 1 | | utf16_croatian_ci | utf16 | 122 | | Yes | 1 | | utf16_unicode_520_ci | utf16 | 123 | | Yes | 1 | | utf16_vietnamese_ci | utf16 | 124 | | Yes | 1 | | ucs2_unicode_ci | ucs2 | 128 | | Yes | 1 | | ucs2_icelandic_ci | ucs2 | 129 | | Yes | 1 | | ucs2_latvian_ci | ucs2 | 130 | | Yes | 1 | | ucs2_romanian_ci | ucs2 | 131 | | Yes | 1 | | ucs2_slovenian_ci | ucs2 | 132 | | Yes | 1 | | ucs2_polish_ci | ucs2 | 133 | | Yes | 1 | | ucs2_estonian_ci | ucs2 | 134 | | Yes | 1 | | ucs2_spanish_ci | ucs2 | 135 | | Yes | 1 | | ucs2_swedish_ci | ucs2 | 136 | | Yes | 1 | | ucs2_turkish_ci | ucs2 | 137 | | Yes | 1 | | ucs2_czech_ci | ucs2 | 138 | | Yes | 1 | | ucs2_danish_ci | ucs2 | 139 | | Yes | 1 | | ucs2_lithuanian_ci | ucs2 | 140 | | Yes | 1 | | ucs2_slovak_ci | ucs2 | 141 | | Yes | 1 | | ucs2_spanish2_ci | ucs2 | 142 | | Yes | 1 | | ucs2_roman_ci | ucs2 | 143 | | Yes | 1 | | ucs2_persian_ci | ucs2 | 144 | | Yes | 1 | | ucs2_esperanto_ci | ucs2 | 145 | | Yes | 1 | | ucs2_hungarian_ci | ucs2 | 146 | | Yes | 1 | | ucs2_sinhala_ci | ucs2 | 147 | | Yes | 1 | | ucs2_german2_ci | ucs2 | 148 | | Yes | 1 | | ucs2_croatian_ci | ucs2 | 149 | | Yes | 1 | | ucs2_unicode_520_ci | ucs2 | 150 | | Yes | 1 | | ucs2_vietnamese_ci | ucs2 | 151 | | Yes | 1 | | ucs2_general_mysql500_ci | ucs2 | 159 | | Yes | 1 | | utf32_unicode_ci | utf32 | 160 | | Yes | 1 | | utf32_icelandic_ci | utf32 | 161 | | Yes | 1 | | utf32_latvian_ci | utf32 | 162 | | Yes | 1 | | utf32_romanian_ci | utf32 | 163 | | Yes | 1 | | utf32_slovenian_ci | utf32 | 164 | | Yes | 1 | | utf32_polish_ci | utf32 | 165 | | Yes | 1 | | utf32_estonian_ci | utf32 | 166 | | Yes | 1 | | utf32_spanish_ci | utf32 | 167 | | Yes | 1 | | utf32_swedish_ci | utf32 | 168 | | Yes | 1 | | utf32_turkish_ci | utf32 | 169 | | Yes | 1 | | utf32_czech_ci | utf32 | 170 | | Yes | 1 | | utf32_danish_ci | utf32 | 171 | | Yes | 1 | | utf32_lithuanian_ci | utf32 | 172 | | Yes | 1 | | utf32_slovak_ci | utf32 | 173 | | Yes | 1 | | utf32_spanish2_ci | utf32 | 174 | | Yes | 1 | | utf32_roman_ci | utf32 | 175 | | Yes | 1 | | utf32_persian_ci | utf32 | 176 | | Yes | 1 | | utf32_esperanto_ci | utf32 | 177 | | Yes | 1 | | utf32_hungarian_ci | utf32 | 178 | | Yes | 1 | | utf32_sinhala_ci | utf32 | 179 | | Yes | 1 | | utf32_german2_ci | utf32 | 180 | | Yes | 1 | | utf32_croatian_ci | utf32 | 181 | | Yes | 1 | | utf32_unicode_520_ci | utf32 | 182 | | Yes | 1 | | utf32_vietnamese_ci | utf32 | 183 | | Yes | 1 | | utf8_unicode_ci | utf8 | 192 | | Yes | 1 | | utf8_icelandic_ci | utf8 | 193 | | Yes | 1 | | utf8_latvian_ci | utf8 | 194 | | Yes | 1 | | utf8_romanian_ci | utf8 | 195 | | Yes | 1 | | utf8_slovenian_ci | utf8 | 196 | | Yes | 1 | | utf8_polish_ci | utf8 | 197 | | Yes | 1 | | utf8_estonian_ci | utf8 | 198 | | Yes | 1 | | utf8_spanish_ci | utf8 | 199 | | Yes | 1 | | utf8_swedish_ci | utf8 | 200 | | Yes | 1 | | utf8_turkish_ci | utf8 | 201 | | Yes | 1 | | utf8_czech_ci | utf8 | 202 | | Yes | 1 | | utf8_danish_ci | utf8 | 203 | | Yes | 1 | | utf8_lithuanian_ci | utf8 | 204 | | Yes | 1 | | utf8_slovak_ci | utf8 | 205 | | Yes | 1 | | utf8_spanish2_ci | utf8 | 206 | | Yes | 1 | | utf8_roman_ci | utf8 | 207 | | Yes | 1 | | utf8_persian_ci | utf8 | 208 | | Yes | 1 | | utf8_esperanto_ci | utf8 | 209 | | Yes | 1 | | utf8_hungarian_ci | utf8 | 210 | | Yes | 1 | | utf8_sinhala_ci | utf8 | 211 | | Yes | 1 | | utf8_german2_ci | utf8 | 212 | | Yes | 1 | | utf8_croatian_ci | utf8 | 213 | | Yes | 1 | | utf8_unicode_520_ci | utf8 | 214 | | Yes | 1 | | utf8_vietnamese_ci | utf8 | 215 | | Yes | 1 | | utf8_general_mysql500_ci | utf8 | 223 | | Yes | 1 | | utf8mb4_unicode_ci | utf8mb4 | 224 | | Yes | 1 | | utf8mb4_icelandic_ci | utf8mb4 | 225 | | Yes | 1 | | utf8mb4_latvian_ci | utf8mb4 | 226 | | Yes | 1 | | utf8mb4_romanian_ci | utf8mb4 | 227 | | Yes | 1 | | utf8mb4_slovenian_ci | utf8mb4 | 228 | | Yes | 1 | | utf8mb4_polish_ci | utf8mb4 | 229 | | Yes | 1 | | utf8mb4_estonian_ci | utf8mb4 | 230 | | Yes | 1 | | utf8mb4_spanish_ci | utf8mb4 | 231 | | Yes | 1 | | utf8mb4_swedish_ci | utf8mb4 | 232 | | Yes | 1 | | utf8mb4_turkish_ci | utf8mb4 | 233 | | Yes | 1 | | utf8mb4_czech_ci | utf8mb4 | 234 | | Yes | 1 | | utf8mb4_danish_ci | utf8mb4 | 235 | | Yes | 1 | | utf8mb4_lithuanian_ci | utf8mb4 | 236 | | Yes | 1 | | utf8mb4_slovak_ci | utf8mb4 | 237 | | Yes | 1 | | utf8mb4_spanish2_ci | utf8mb4 | 238 | | Yes | 1 | | utf8mb4_roman_ci | utf8mb4 | 239 | | Yes | 1 | | utf8mb4_persian_ci | utf8mb4 | 240 | | Yes | 1 | | utf8mb4_esperanto_ci | utf8mb4 | 241 | | Yes | 1 | | utf8mb4_hungarian_ci | utf8mb4 | 242 | | Yes | 1 | | utf8mb4_sinhala_ci | utf8mb4 | 243 | | Yes | 1 | | utf8mb4_german2_ci | utf8mb4 | 244 | | Yes | 1 | | utf8mb4_croatian_ci | utf8mb4 | 245 | | Yes | 1 | | utf8mb4_unicode_520_ci | utf8mb4 | 246 | | Yes | 1 | | utf8mb4_vietnamese_ci | utf8mb4 | 247 | | Yes | 1 | +--------------------------+----------+------+---------+----------+---------+ 219 rows in set (0.</description>
    </item>
    
    <item>
      <title>SHOW CREATE TABLE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-create-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-create-table/</guid>
      <description>SHOW CREATE TABLE This statement shows the exact statement to recreate an existing table using SQL.
Synopsis ShowStmt:
TableName:
Examples mysql&amp;gt; CREATE TABLE t1 (a INT); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; SHOW CREATE TABLE t1; +-------+------------------------------------------------------------------------------------------------------------+ | Table | Create Table | +-------+------------------------------------------------------------------------------------------------------------+ | t1 | CREATE TABLE `t1` ( `a` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin | +-------+------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) MySQL compatibility This statement is understood to be fully compatible with MySQL.</description>
    </item>
    
    <item>
      <title>SHOW CREATE USER | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-create-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-create-user/</guid>
      <description>SHOW CREATE USER This statement shows how to re-create a user using the CREATE USER syntax.
Synopsis ShowStmt:
Username:
Examples mysql&amp;gt; SHOW CREATE USER &amp;#39;root&amp;#39;; +--------------------------------------------------------------------------------------------------------------------------+ | CREATE USER for root@% | +--------------------------------------------------------------------------------------------------------------------------+ | CREATE USER &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED WITH &amp;#39;mysql_native_password&amp;#39; AS &amp;#39;&amp;#39; REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK | +--------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql&amp;gt; SHOW GRANTS FOR &amp;#39;root&amp;#39;; +-------------------------------------------+ | Grants for root@% | +-------------------------------------------+ | GRANT ALL PRIVILEGES ON *.</description>
    </item>
    
    <item>
      <title>SHOW DATABASES | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-databases/</guid>
      <description>SHOW DATABASES This statement shows a list of databases that the current user has privileges to. Databases which the current user does not have access to will appear hidden from the list. The information_schema database always appears first in the list of databases.
SHOW SCHEMAS is an alias of this statement.
Synopsis ShowStmt:
ShowTargetFilterable:
Examples mysql&amp;gt; SHOW DATABASES; +--------------------+ | Database | +--------------------+ | INFORMATION_SCHEMA | | PERFORMANCE_SCHEMA | | mysql | | test | +--------------------+ 4 rows in set (0.</description>
    </item>
    
    <item>
      <title>SHOW ENGINES | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-engines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-engines/</guid>
      <description>SHOW ENGINES This statement is included only for compatibility with MySQL.
Synopsis SHOW ENGINES Examples mysql&amp;gt; SHOW ENGINES; +--------+---------+------------------------------------------------------------+--------------+------+------------+ | Engine | Support | Comment | Transactions | XA | Savepoints | +--------+---------+------------------------------------------------------------+--------------+------+------------+ | InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES | +--------+---------+------------------------------------------------------------+--------------+------+------------+ 1 row in set (0.00 sec) MySQL compatibility  This statement will always only return InnoDB as the supported engine.</description>
    </item>
    
    <item>
      <title>SHOW ERRORS | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-errors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-errors/</guid>
      <description>SHOW ERRORS This statement shows error(s) from previously executed statements. The error buffer is cleared as soon as a statement executes successfully. In which case, SHOW ERRORS will return an empty set.
The behavior of which statements generate errors vs. warnings is highly influenced by the current sql_mode.
Synopsis ShowStmt:
ShowTargetFilterable:
Examples mysql&amp;gt; select invalid; ERROR 1054 (42S22): Unknown column &amp;#39;invalid&amp;#39; in &amp;#39;field list&amp;#39; mysql&amp;gt; create invalid; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your TiDB version for the right syntax to use line 1 column 14 near &amp;#34;invalid&amp;#34; mysql&amp;gt; SHOW ERRORS; +-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+ | Level | Code | Message | +-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+ | Error | 1054 | Unknown column &amp;#39;invalid&amp;#39; in &amp;#39;field list&amp;#39; | | Error | 1064 | You have an error in your SQL syntax; check the manual that corresponds to your TiDB version for the right syntax to use line 1 column 14 near &amp;#34;invalid&amp;#34; | +-------+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+ 2 rows in set (0.</description>
    </item>
    
    <item>
      <title>SHOW GRANTS | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-grants/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-grants/</guid>
      <description>SHOW GRANTS This statement shows a list of privileges associated with a user. As in MySQL, the USAGE privileges denotes the ability to login to TiDB.
Synopsis ShowStmt:
Username:
Examples mysql&amp;gt; SHOW GRANTS; +-------------------------------------------+ | Grants for User | +-------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; | +-------------------------------------------+ 1 row in set (0.00 sec) mysql&amp;gt; SHOW GRANTS FOR &amp;#39;u1&amp;#39;; ERROR 1141 (42000): There is no such grant defined for user &amp;#39;u1&amp;#39; on host &amp;#39;%&amp;#39; mysql&amp;gt; CREATE USER u1; Query OK, 1 row affected (0.</description>
    </item>
    
    <item>
      <title>SHOW INDEX [FROM|IN] | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-index/</guid>
      <description>SHOW INDEX [FROM|IN] This statement is an alias to SHOW INDEXES [FROM|IN]. It is included for compatibility with MySQL.</description>
    </item>
    
    <item>
      <title>SHOW INDEXES [FROM|IN] | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-indexes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-indexes/</guid>
      <description>SHOW INDEXES [FROM|IN] The statement SHOW INDEXES [FROM|IN] lists the indexes on a specified table. The statements SHOW INDEX [FROM|IN], SHOW KEYS [FROM|IN] are aliases of this statement, and included for compatibility with MySQL.
Synopsis ShowStmt:
ShowTargetFilterable:
ShowIndexKwd:
FromOrIn:
TableName:
Examples mysql&amp;gt; CREATE TABLE t1 (id int not null primary key auto_increment, col1 INT, INDEX(col1)); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; SHOW INDEXES FROM t1; +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | t1 | 0 | PRIMARY | 1 | id | A | 0 | NULL | NULL | | BTREE | | | | t1 | 1 | col1 | 1 | col1 | A | 0 | NULL | NULL | YES | BTREE | | | +-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ 2 rows in set (0.</description>
    </item>
    
    <item>
      <title>SHOW KEYS [FROM|IN] | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-keys/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-keys/</guid>
      <description>SHOW KEYS [FROM|IN] This statement is an alias to SHOW INDEXES [FROM|IN]. It is included for compatibility with MySQL.</description>
    </item>
    
    <item>
      <title>SHOW PRIVILEGES | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-privileges/</guid>
      <description>SHOW PRIVILEGES This statement shows a list of assignable privileges in TiDB. It is a static list, and does not reflect the privileges of the current user.
Synopsis ShowStmt:
Examples mysql&amp;gt; show privileges; +-------------------------+---------------------------------------+-------------------------------------------------------+ | Privilege | Context | Comment | +-------------------------+---------------------------------------+-------------------------------------------------------+ | Alter | Tables | To alter the table | | Alter | Tables | To alter the table | | Alter routine | Functions,Procedures | To alter or drop stored functions/procedures | | Create | Databases,Tables,Indexes | To create new databases and tables | | Create routine | Databases | To use CREATE FUNCTION/PROCEDURE | | Create temporary tables | Databases | To use CREATE TEMPORARY TABLE | | Create view | Tables | To create new views | | Create user | Server Admin | To create new users | | Delete | Tables | To delete existing rows | | Drop | Databases,Tables | To drop databases, tables, and views | | Event | Server Admin | To create, alter, drop and execute events | | Execute | Functions,Procedures | To execute stored routines | | File | File access on server | To read and write files on the server | | Grant option | Databases,Tables,Functions,Procedures | To give to other users those privileges you possess | | Index | Tables | To create or drop indexes | | Insert | Tables | To insert data into tables | | Lock tables | Databases | To use LOCK TABLES (together with SELECT privilege) | | Process | Server Admin | To view the plain text of currently executing queries | | Proxy | Server Admin | To make proxy user possible | | References | Databases,Tables | To have references on tables | | Reload | Server Admin | To reload or refresh tables, logs and privileges | | Replication client | Server Admin | To ask where the slave or master servers are | | Replication slave | Server Admin | To read binary log events from the master | | Select | Tables | To retrieve rows from table | | Show databases | Server Admin | To see all databases with SHOW DATABASES | | Show view | Tables | To see views with SHOW CREATE VIEW | | Shutdown | Server Admin | To shut down the server | | Super | Server Admin | To use KILL thread, SET GLOBAL, CHANGE MASTER, etc.</description>
    </item>
    
    <item>
      <title>SHOW SCHEMAS | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-schemas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-schemas/</guid>
      <description>SHOW SCHEMAS This statement is an alias to SHOW DATABASES. It is included for compatibility with MySQL.</description>
    </item>
    
    <item>
      <title>SHOW TABLE STATUS | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-table-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-table-status/</guid>
      <description>SHOW TABLE STATUS This statement shows various statistics about tables in TiDB. If the statistics appear out of date, it is recommended to run ANALYZE TABLE.
Synopsis ShowStmt:
ShowTargetFilterable:
ShowDatabaseNameOpt:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.02 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql&amp;gt; SHOW TABLE STATUS LIKE &amp;#39;t1&amp;#39;\G *************************** 1.</description>
    </item>
    
    <item>
      <title>SHOW WARNINGS | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-warnings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-warnings/</guid>
      <description>SHOW WARNINGS This statement shows a list of warnings that occurred for previously executed statements in the current client connection. As in MySQL, the sql_mode impacts which statements will cause errors vs. warnings considerably.
Synopsis ShowStmt:
ShowTargetFilterable:
Examples mysql&amp;gt; CREATE TABLE t1 (a INT UNSIGNED); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 VALUES (0); Query OK, 1 row affected (0.02 sec) mysql&amp;gt; SELECT 1/a FROM t1; +------+ | 1/a | +------+ | NULL | +------+ 1 row in set, 1 warning (0.</description>
    </item>
    
    <item>
      <title>SHOW [FULL] COLUMNS FROM | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-columns-from/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-columns-from/</guid>
      <description>SHOW [FULL] COLUMNS FROM This statement describes the columns of a table or view in a useful tabular format. The optional keyword FULL displays the privileges the current user has to that column, and the comment from the table definition.
The statements SHOW [FULL] FIELDS FROM, DESC &amp;lt;table&amp;gt;, DESCRIBE &amp;lt;table&amp;gt; and EXPLAIN &amp;lt;table&amp;gt; are aliases of this statement.
Synopsis ShowStmt:
ShowTargetFilterable:
OptFull:
Examples mysql&amp;gt; create view v1 as select 1; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>SHOW [FULL] FIELDS FROM | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-fields-from/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-fields-from/</guid>
      <description>SHOW [FULL] FIELDS FROM This statement is an alias to SHOW [FULL] COLUMNS FROM. It is included for compatibility with MySQL.</description>
    </item>
    
    <item>
      <title>SHOW [FULL] PROCESSLIST | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-processlist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-processlist/</guid>
      <description>SHOW [FULL] PROCESSLIST This statement lists the current sessions connected to the same TiDB server. The Info column contains the query text, which will be truncated unless the optional keyword FULL is specified.
Synopsis ShowStmt:
OptFull:
Examples mysql&amp;gt; SHOW PROCESSLIST; +------+------+-----------+------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +------+------+-----------+------+---------+------+-------+------------------+ | 1 | root | 127.0.0.1 | test | Query | 0 | 2 | SHOW PROCESSLIST | | 2 | root | 127.</description>
    </item>
    
    <item>
      <title>SHOW [FULL] TABLES | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-tables/</guid>
      <description>SHOW [FULL] TABLES This statement shows a list of tables and views in the currently selected database. The optional keyword FULL indicates if a table is of type BASE TABLE or VIEW.
To show tables in a different database, use SHOW TABLES IN DatabaseName.
Synopsis ShowStmt:
ShowTargetFilterable:
ShowDatabaseNameOpt:
Examples mysql&amp;gt; CREATE TABLE t1 (a int); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; CREATE VIEW v1 AS SELECT 1; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>SHOW [GLOBAL|SESSION] STATUS | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-status/</guid>
      <description>SHOW [GLOBAL|SESSION] STATUS This statement is included for compatibility with MySQL. It has no effect on TiDB, which uses Prometheus and Grafana for centralized metrics collection instead of SHOW STATUS.
Synopsis ShowStmt:
ShowTargetFilterable:
GlobalScope:
Examples mysql&amp;gt; show status; +--------------------+--------------------------------------+ | Variable_name | Value | +--------------------+--------------------------------------+ | Ssl_cipher_list | | | server_id | 93e2e07d-6bb4-4a1b-90b7-e035fae154fe | | ddl_schema_version | 141 | | Ssl_verify_mode | 0 | | Ssl_version | | | Ssl_cipher | | +--------------------+--------------------------------------+ 6 rows in set (0.</description>
    </item>
    
    <item>
      <title>SHOW [GLOBAL|SESSION] VARIABLES | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/show-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/show-variables/</guid>
      <description>SHOW [GLOBAL|SESSION] VARIABLES This statement shows a list of variables for the scope of either GLOBAL or SESSION. If no scope is specified, the default scope of SESSION will apply.
Synopsis ShowStmt:
ShowTargetFilterable:
GlobalScope:
Examples mysql&amp;gt; SHOW GLOBAL VARIABLES LIKE &amp;#39;tidb%&amp;#39;; +------------------------------------+--------------+ | Variable_name | Value | +------------------------------------+--------------+ | tidb_ddl_reorg_worker_cnt | 16 | | tidb_check_mb4_value_in_utf8 | 1 | | tidb_opt_agg_push_down | 0 | | tidb_retry_limit | 10 | | tidb_constraint_check_in_place | 0 | | tidb_ddl_reorg_priority | PRIORITY_LOW | | tidb_current_ts | 0 | | tidb_mem_quota_indexlookupjoin | 34359738368 | | tidb_query_log_max_len | 2048 | | tidb_enable_cascades_planner | 0 | | tidb_mem_quota_topn | 34359738368 | | tidb_index_lookup_join_concurrency | 4 | | tidb_auto_analyze_end_time | 23:59 +0000 | | tidb_mem_quota_query | 34359738368 | | tidb_optimizer_selectivity_level | 0 | | tidb_index_serial_scan_concurrency | 1 | | tidb_dml_batch_size | 20000 | | tidb_max_chunk_size | 1024 | | tidb_enable_table_partition | auto | | tidb_mem_quota_indexlookupreader | 34359738368 | | tidb_enable_window_function | 0 | | tidb_opt_write_row_id | 0 | | tidb_ddl_error_count_limit | 512 | | tidb_batch_delete | 0 | | tidb_mem_quota_sort | 34359738368 | | tidb_enable_streaming | 0 | | tidb_opt_insubq_to_join_and_agg | 1 | | tidb_build_stats_concurrency | 4 | | tidb_projection_concurrency | 4 | | tidb_mem_quota_mergejoin | 34359738368 | | tidb_hashagg_final_concurrency | 4 | | tidb_checksum_table_concurrency | 4 | | tidb_batch_insert | 0 | | tidb_slow_query_file | | | tidb_index_join_batch_size | 25000 | | tidb_ddl_reorg_batch_size | 1024 | | tidb_enable_fast_analyze | 0 | | tidb_config | | | tidb_distsql_scan_concurrency | 15 | | tidb_hashagg_partial_concurrency | 4 | | tidb_init_chunk_size | 32 | | tidb_backoff_lock_fast | 100 | | tidb_skip_utf8_check | 0 | | tidb_hash_join_concurrency | 5 | | tidb_index_lookup_concurrency | 4 | | tidb_slow_log_threshold | 300 | | tidb_index_lookup_size | 20000 | | tidb_force_priority | NO_PRIORITY | | tidb_auto_analyze_start_time | 00:00 +0000 | | tidb_mem_quota_nestedloopapply | 34359738368 | | tidb_snapshot | | | tidb_general_log | 0 | | tidb_batch_commit | 0 | | tidb_enable_radix_join | 0 | | tidb_skip_isolation_level_check | 0 | | tidb_auto_analyze_ratio | 0.</description>
    </item>
    
    <item>
      <title>SQL Optimization Process</title>
      <link>https://pingcap.com/docs/dev/reference/performance/sql-optimizer-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/performance/sql-optimizer-overview/</guid>
      <description>SQL Optimization Process In TiDB, the process of SQL optimization consists of two phases: logical optimization and physical optimization. This document describes the logical and physical optimization to help you understand the whole process.
Logical optimization Based on rules, logical optimization applies some optimization rules to the input logical execution plan in order, to make the whole logical execution plan better. The optimization rules include:
 Column pruning Eliminate projection Decorrelate correlated subqueries Eliminate Max/Min Push down predicates Partition pruning Push down TopN and Limit  Physical optimization Based on cost, physical optimization makes the physical execution plan for the logical execution plan generated in the previous phase.</description>
    </item>
    
    <item>
      <title>SQL Optimization Process</title>
      <link>https://pingcap.com/docs/v2.1/sql/sql-optimizer-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/sql-optimizer-overview/</guid>
      <description>SQL Optimization Process In TiDB, the process of SQL optimization consists of two phases: logical optimization and physical optimization. This document describes the logical and physical optimization to help you understand the whole process.
Logical optimization Based on rules, logical optimization applies some optimization rules to the input logical execution plan in order, to make the whole logical execution plan better. The optimization rules include:
 Column pruning Eliminate projection Decorrelate correlated subqueries Eliminate Max/Min Push down predicates Partition pruning Push down TopN and Limit  Physical optimization Based on cost, physical optimization makes the physical execution plan for the logical execution plan generated in the previous phase.</description>
    </item>
    
    <item>
      <title>START TRANSACTION | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/start-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/start-transaction/</guid>
      <description>START TRANSACTION This statement starts a new transaction inside of TiDB. It is similar to the statements BEGIN and SET autocommit=0.
In the absense of a START TRANSACTION statement, every statement will by default autocommit in its own transaction. This behavior ensures MySQL compatibility.
Synopsis BeginTransactionStmt:
Examples mysql&amp;gt; CREATE TABLE t1 (a int NOT NULL PRIMARY KEY); Query OK, 0 rows affected (0.12 sec) mysql&amp;gt; START TRANSACTION; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Scale a TiDB cluster</title>
      <link>https://pingcap.com/docs/dev/how-to/scale/horizontally/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/scale/horizontally/</guid>
      <description>Scale a TiDB cluster Overview The capacity of a TiDB cluster can be increased or reduced without affecting online services.
 Note:
If your TiDB cluster is deployed using Ansible, see Scale the TiDB Cluster Using TiDB-Ansible.
 The following part shows you how to add or delete PD, TiKV or TiDB nodes.
About pd-ctl usage, refer to PD Control User Guide.
PD Assume we have three PD servers with the following details:</description>
    </item>
    
    <item>
      <title>Scale a TiDB cluster</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/horizontal-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/horizontal-scale/</guid>
      <description>Scale a TiDB cluster Overview The capacity of a TiDB cluster can be increased or reduced without affecting online services.
 Note:
If your TiDB cluster is deployed using Ansible, see Scale the TiDB Cluster Using TiDB-Ansible.
 The following part shows you how to add or delete PD, TiKV or TiDB nodes.
About pd-ctl usage, refer to PD Control User Guide.
PD Assume we have three PD servers with the following details:</description>
    </item>
    
    <item>
      <title>Scale the TiDB Cluster Using TiDB-Ansible</title>
      <link>https://pingcap.com/docs/dev/how-to/scale/with-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/scale/with-ansible/</guid>
      <description>Scale the TiDB Cluster Using TiDB-Ansible The capacity of a TiDB cluster can be increased or decreased without affecting the online services.
 Warning:
In decreasing the capacity, if your cluster has a mixed deployment of other services, do not perform the following procedures. The following examples assume that the removed nodes have no mixed deployment of other services.
 Assume that the topology is as follows:
   Name Host IP Services     node1 172.</description>
    </item>
    
    <item>
      <title>Scale the TiDB Cluster Using TiDB-Ansible</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/ansible-deployment-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/ansible-deployment-scale/</guid>
      <description>Scale the TiDB Cluster Using TiDB-Ansible The capacity of a TiDB cluster can be increased or decreased without affecting the online services.
 Warning:
In decreasing the capacity, if your cluster has a mixed deployment of other services, do not perform the following procedures. The following examples assume that the removed nodes have no mixed deployment of other services.
 Assume that the topology is as follows:
   Name Host IP Services     node1 172.</description>
    </item>
    
    <item>
      <title>Schema Object Names</title>
      <link>https://pingcap.com/docs/dev/reference/sql/language-structure/schema-object-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/language-structure/schema-object-names/</guid>
      <description>Schema Object Names Some objects names in TiDB, including database, table, index, column, alias, etc., are known as identifiers.
In TiDB, you can quote or unquote an identifier. If an identifier contains special characters or is a reserved word, you must quote it whenever you refer to it. To quote, use the backtick (`) to wrap the identifier. For example:
mysql&amp;gt; SELECT * FROM `table` WHERE `table`.id = 20; If the ANSI_QUOTES SQL mode is enabled, you can also quote identifiers within double quotation marks(&amp;ldquo;):</description>
    </item>
    
    <item>
      <title>Schema Object Names</title>
      <link>https://pingcap.com/docs/v2.1/sql/schema-object-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/schema-object-names/</guid>
      <description>Schema Object Names Some objects names in TiDB, including database, table, index, column, alias, etc., are known as identifiers.
In TiDB, you can quote or unquote an identifier. If an identifier contains special characters or is a reserved word, you must quote it whenever you refer to it. To quote, use the backtick (`) to wrap the identifier. For example:
mysql&amp;gt; SELECT * FROM `table` WHERE `table`.id = 20; If the ANSI_QUOTES SQL mode is enabled, you can also quote identifiers within double quotation marks(&amp;ldquo;):</description>
    </item>
    
    <item>
      <title>Security Compatibility with MySQL</title>
      <link>https://pingcap.com/docs/dev/reference/security/compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/security/compatibility/</guid>
      <description> Security Compatibility with MySQL TiDB supports similar security functionality to MySQL 5.7, with the following exceptions:
 Only the mysql_native_password authentication scheme is supported External authentication (such as with LDAP) is not currently supported Column level permissions are not supported Using certificates for authentication is not supported #9708 Password expiry, as well as password last-changed tracking and password lifetime are not supported #9709 The permission attributes max_questions, max_updated, max_connections, max_user_connections are not supported Password validation is not currently supported #9741 Transparent Data Encryption (TDE) is not currently supported  </description>
    </item>
    
    <item>
      <title>Skip or Replace Abnormal SQL Statements</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/skip-replace-sqls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/skip-replace-sqls/</guid>
      <description>Skip or Replace Abnormal SQL Statements This document introduces how to handle abnormal SQL statements using Data Migration (DM).
Currently, TiDB is not completely compatible with all MySQL syntax (see the DDL statements supported by TiDB). Therefore, when DM is replicating data from MySQL to TiDB and TiDB does not support the corresponding SQL statement, an error might occur and break the replication process. In this case, there are two ways to resume the replication:</description>
    </item>
    
    <item>
      <title>Slow Query Log</title>
      <link>https://pingcap.com/docs/v2.1/sql/slow-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/slow-query/</guid>
      <description>Slow Query Log The slow query log is a record of SQL statements that took a long time to perform.
A problematic SQL statement can increase the pressure on the entire cluster, resulting in a longer response time. To solve this problem, you can use the slow query log to identify the problematic statements and thus improve the performance.
Obtain the log By grep the keyword SLOW_QUERY in the log file of TiDB, you can obtain the logs of statements whose execution time exceeds slow-threshold.</description>
    </item>
    
    <item>
      <title>Software and Hardware Recommendations</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/hardware-recommendations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/hardware-recommendations/</guid>
      <description>Software and Hardware Recommendations About As an open source distributed NewSQL database with high performance, TiDB can be deployed in the Intel architecture server and major virtualization environments and runs well. TiDB supports most of the major hardware networks and Linux operating systems.
Linux OS version requirements    Linux OS Platform Version     Red Hat Enterprise Linux 7.3 or later   CentOS 7.3 or later   Oracle Enterprise Linux 7.</description>
    </item>
    
    <item>
      <title>Software and Hardware Requirements</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/recommendation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/recommendation/</guid>
      <description>Software and Hardware Requirements About As an open source distributed NewSQL database with high performance, TiDB can be deployed in the Intel architecture server and major virtualization environments and runs well. TiDB supports most of the major hardware networks and Linux operating systems.
Linux OS version requirements    Linux OS Platform Version     Red Hat Enterprise Linux 7.3 or later   CentOS 7.3 or later   Oracle Enterprise Linux 7.</description>
    </item>
    
    <item>
      <title>String Functions</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/string-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/string-functions/</guid>
      <description> String Functions    Name Description     ASCII() Return numeric value of left-most character   CHAR() Return the character for each integer passed   BIN() Return a string containing binary representation of a number   HEX() Return a hexadecimal representation of a decimal or string value   OCT() Return a string containing octal representation of a number   UNHEX() Return a string containing hex representation of a number   TO_BASE64() Return the argument converted to a base-64 string   FROM_BASE64() Decode to a base-64 string and return result   LOWER() Return the argument in lowercase   LCASE() Synonym for LOWER()   UPPER() Convert to uppercase   UCASE() Synonym for UPPER()   LPAD() Return the string argument, left-padded with the specified string   RPAD() Append string the specified number of times   TRIM() Remove leading and trailing spaces   LTRIM() Remove leading spaces   RTRIM() Remove trailing spaces   BIT_LENGTH() Return length of argument in bits   CHAR_LENGTH() Return number of characters in argument   CHARACTER_LENGTH() Synonym for CHAR_LENGTH()   LENGTH() Return the length of a string in bytes   OCTET_LENGTH() Synonym for LENGTH()   INSERT() Insert a substring at the specified position up to the specified number of characters   REPLACE() Replace occurrences of a specified string   SUBSTR() Return the substring as specified   SUBSTRING() Return the substring as specified   SUBSTRING_INDEX() Return a substring from a string before the specified number of occurrences of the delimiter   MID() Return a substring starting from the specified position   LEFT() Return the leftmost number of characters as specified   RIGHT() Return the specified rightmost number of characters   INSTR() Return the index of the first occurrence of substring   LOCATE() Return the position of the first occurrence of substring   POSITION() Synonym for LOCATE()   REPEAT() Repeat a string the specified number of times   CONCAT() Return concatenated string   CONCAT_WS() Return concatenate with separator   REVERSE() Reverse the characters in a string   SPACE() Return a string of the specified number of spaces   FIELD() Return the index (position) of the first argument in the subsequent arguments   ELT() Return string at index number   EXPORT_SET() Return a string such that for every bit set in the value bits, you get an on string and for every unset bit, you get an off string   MAKE_SET() Return a set of comma-separated strings that have the corresponding bit in bits set   FIND_IN_SET() Return the index position of the first argument within the second argument   FORMAT() Return a number formatted to specified number of decimal places   ORD() Return character code for leftmost character of the argument   QUOTE() Escape the argument for use in an SQL statement    String comparison functions    Name Description     LIKE Simple pattern matching   NOT LIKE Negation of simple pattern matching   STRCMP() Compare two strings    Regular expressions    Name Description     REGEXP Pattern matching using regular expressions   RLIKE Synonym for REGEXP   NOT REGEXP Negation of REGEXP    </description>
    </item>
    
    <item>
      <title>String Functions</title>
      <link>https://pingcap.com/docs/v2.1/sql/string-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/string-functions/</guid>
      <description> String Functions    Name Description     ASCII() Return numeric value of left-most character   CHAR() Return the character for each integer passed   BIN() Return a string containing binary representation of a number   HEX() Return a hexadecimal representation of a decimal or string value   OCT() Return a string containing octal representation of a number   UNHEX() Return a string containing hex representation of a number   TO_BASE64() Return the argument converted to a base-64 string   FROM_BASE64() Decode to a base-64 string and return result   LOWER() Return the argument in lowercase   LCASE() Synonym for LOWER()   UPPER() Convert to uppercase   UCASE() Synonym for UPPER()   LPAD() Return the string argument, left-padded with the specified string   RPAD() Append string the specified number of times   TRIM() Remove leading and trailing spaces   LTRIM() Remove leading spaces   RTRIM() Remove trailing spaces   BIT_LENGTH() Return length of argument in bits   CHAR_LENGTH() Return number of characters in argument   CHARACTER_LENGTH() Synonym for CHAR_LENGTH()   LENGTH() Return the length of a string in bytes   OCTET_LENGTH() Synonym for LENGTH()   INSERT() Insert a substring at the specified position up to the specified number of characters   REPLACE() Replace occurrences of a specified string   SUBSTR() Return the substring as specified   SUBSTRING() Return the substring as specified   SUBSTRING_INDEX() Return a substring from a string before the specified number of occurrences of the delimiter   MID() Return a substring starting from the specified position   LEFT() Return the leftmost number of characters as specified   RIGHT() Return the specified rightmost number of characters   INSTR() Return the index of the first occurrence of substring   LOCATE() Return the position of the first occurrence of substring   POSITION() Synonym for LOCATE()   REPEAT() Repeat a string the specified number of times   CONCAT() Return concatenated string   CONCAT_WS() Return concatenate with separator   REVERSE() Reverse the characters in a string   SPACE() Return a string of the specified number of spaces   FIELD() Return the index (position) of the first argument in the subsequent arguments   ELT() Return string at index number   EXPORT_SET() Return a string such that for every bit set in the value bits, you get an on string and for every unset bit, you get an off string   MAKE_SET() Return a set of comma-separated strings that have the corresponding bit in bits set   FIND_IN_SET() Return the index position of the first argument within the second argument   FORMAT() Return a number formatted to specified number of decimal places   ORD() Return character code for leftmost character of the argument   QUOTE() Escape the argument for use in an SQL statement    String comparison functions    Name Description     LIKE Simple pattern matching   NOT LIKE Negation of simple pattern matching   STRCMP() Compare two strings    Regular expressions    Name Description     REGEXP Pattern matching using regular expressions   RLIKE Synonym for REGEXP   NOT REGEXP Negation of REGEXP    </description>
    </item>
    
    <item>
      <title>Support Resources</title>
      <link>https://pingcap.com/docs/support-resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/support-resources/</guid>
      <description>Support Resources You can reach out to the community members via any one of the following ways:
 Slack Channel: https://pingcap.com/tidbslack Google Groups: https://groups.google.com/forum/#!forum/tidb-user Stack Overflow: https://stackoverflow.com/questions/tagged/tidb Twitter: https://twitter.com/PingCAP Facebook: https://www.facebook.com/pingcap2015 Reddit: https://www.reddit.com/r/TiDB GitHub: https://github.com/pingcap/tidb/issues  Please contact us for more information on Enterprise support contracts.</description>
    </item>
    
    <item>
      <title>Syncer User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/syncer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/syncer/</guid>
      <description>Syncer User Guide About Syncer Syncer is a tool used to import data incrementally. It is a part of the TiDB enterprise toolset.
It can be downloaded as part of the Enterprise Tools package.
Syncer architecture Where to deploy Syncer You can deploy Syncer to any of the machines that can connect to MySQL or the TiDB cluster. But it is recommended to deploy Syncer to the TiDB cluster.</description>
    </item>
    
    <item>
      <title>Syncer User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/syncer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/syncer/</guid>
      <description>Syncer User Guide About Syncer Syncer is a tool used to import data incrementally. It is a part of the TiDB enterprise toolset. To obtain Syncer, see Download the TiDB enterprise toolset.
Syncer architecture Download the TiDB enterprise toolset (Linux) # Download the tool package. wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.sha256 # Check the file integrity. If the result is OK, the file is correct. sha256sum -c tidb-enterprise-tools-latest-linux-amd64.sha256 # Extract the package.</description>
    </item>
    
    <item>
      <title>Synchronize Data Using Data Migration</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/deploy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/deploy/</guid>
      <description>Synchronize Data Using Data Migration This guide shows how to synchronize data using the Data Migration (DM) tool.
Step 1: Deploy the DM cluster It is recommended to deploy the DM cluster using DM-Ansible. For detailed deployment, see Deploy Data Migration Using DM-Ansible.
 Note:
 For database passwords in all the DM configuration files, use the passwords encrypted by dmctl. If a database password is empty, it is unnecessary to encrypt it.</description>
    </item>
    
    <item>
      <title>Synchronize Data Using Data Migration</title>
      <link>https://pingcap.com/docs/v2.1/tools/data-migration-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/data-migration-practice/</guid>
      <description>Synchronize Data Using Data Migration This guide shows how to synchronize data using the Data Migration (DM) tool.
Step 1: Deploy the DM cluster It is recommended to deploy the DM cluster using DM-Ansible. For detailed deployment, see Deploy Data Migration Using DM-Ansible.
 Note:
 For database related passwords in all the DM configuration files, use the passwords encrypted by dmctl. If a database password is empty, it is unnecessary to encrypt it.</description>
    </item>
    
    <item>
      <title>Sysbench Test Result of TiDB 3.0 Beta on NVMe SSD</title>
      <link>https://pingcap.com/docs/benchmark/sysbench-v4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/sysbench-v4/</guid>
      <description>Sysbench Test Result of TiDB 3.0 Beta on NVMe SSD In this test, Sysbench 1.0.14 is used. It is recommended to use Sysbench 1.0 or later, which can be downloaded here.
Test purpose This test aims to test the performance of TiDB 3.0 Beta on NVMe SSD.
Test version, time, and place TiDB version: 3.0 Beta
Time: February, 2019
Place: Beijing
Test environment  Hardware requirements
 The TiDB cluster is deployed according to the TiDB Deployment Guide.</description>
    </item>
    
    <item>
      <title>TRACE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/trace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/trace/</guid>
      <description>TRACE The TRACE statement provides detailed information about query execution. It is intended to be viewed through a Graphical interface exposed by the TiDB server&amp;rsquo;s status port.
Synopsis TraceStmt:
TraceableStmt:
Examples mysql&amp;gt; trace format=&amp;#39;row&amp;#39; select * from mysql.user; +---------------------------+-----------------+------------+ | operation | startTS | duration | +---------------------------+-----------------+------------+ | session.getTxnFuture | 10:33:34.647148 | 3.847s | | session.Execute | 10:33:34.647146 | 536.233s | | session.ParseSQL | 10:33:34.647182 | 19.868s | | executor.</description>
    </item>
    
    <item>
      <title>TRUNCATE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/truncate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/truncate/</guid>
      <description>TRUNCATE The TRUNCATE statement removes all data from the table in a non-transactional way. TRUNCATE can be thought of as semantically the same as DROP TABLE + CREATE TABLE with the previous definition.
Both TRUNCATE TABLE tableName and TRUNCATE tableName are valid syntax.
Synopsis TruncateTableStmt:
OptTable:
TableName:
Examples mysql&amp;gt; CREATE TABLE t1 (a INT NOT NULL PRIMARY KEY); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 VALUES (1),(2),(3),(4),(5); Query OK, 5 rows affected (0.</description>
    </item>
    
    <item>
      <title>Table Selector</title>
      <link>https://pingcap.com/docs/dev/reference/tools/data-migration/table-selector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/data-migration/table-selector/</guid>
      <description>Table Selector Table selector provides a match rule based on wildcard characters for schema/table. To match a specified table, configure schema-pattern/table-pattern.
Wildcard character Table selector uses the following two wildcard characters in schema-pattern/table-pattern:
 The asterisk character (*, also called &amp;ldquo;star&amp;rdquo;)
 * matches zero or more characters. For example, doc* matches doc and document but not dodo. * can only be placed at the end of the word. For example, doc* is supported, while do*c is not supported.</description>
    </item>
    
    <item>
      <title>Technical Writing Project Ideas</title>
      <link>https://pingcap.com/docs/technical-writing-project-ideas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/technical-writing-project-ideas/</guid>
      <description>Technical Writing Project Ideas As a small technical writing team, we are dedicated to delivering high quality technical information that is easy to use, easy to understand and easy to find. We are working on it, and your help and support would definitely help!
Interesting fact: we call ourselves Content Strategist because user documentation is only one part of our work scope. If you want to know more, let&amp;rsquo;s get in touch at gsod-tidb@pingcap.</description>
    </item>
    
    <item>
      <title>Testing Deployment from Binary Tarball</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/from-tarball/testing-environment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/from-tarball/testing-environment/</guid>
      <description>Testing Deployment from Binary Tarball This guide provides installation instructions for all TiDB components across multiple nodes for testing purposes. It does not match the recommended usage for production systems.
See also local deployment and production environment deployment.
Prepare Before you start, see TiDB architecture and Software and Hardware Recommendations. Make sure the following requirements are satisfied:
Operating system For the operating system, it is recommended to use RHEL/CentOS 7.</description>
    </item>
    
    <item>
      <title>The System Variables</title>
      <link>https://pingcap.com/docs/dev/reference/configuration/tidb-server/mysql-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/configuration/tidb-server/mysql-variables/</guid>
      <description>The System Variables The system variables in MySQL are the system parameters that modify the operation of the database runtime. These variables have two types of scope, Global Scope and Session Scope. TiDB supports all the system variables in MySQL 5.7. Most of the variables are only supported for compatibility and do not affect the runtime behaviors.
Set the system variables You can use the SET statement to change the value of the system variables.</description>
    </item>
    
    <item>
      <title>The System Variables</title>
      <link>https://pingcap.com/docs/v2.1/sql/variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/variable/</guid>
      <description>The System Variables The system variables in MySQL are the system parameters that modify the operation of the database runtime. These variables have two types of scope, Global Scope and Session Scope. TiDB supports all the system variables in MySQL 5.7. Most of the variables are only supported for compatibility and do not affect the runtime behaviors.
Set the system variables You can use the SET statement to change the value of the system variables.</description>
    </item>
    
    <item>
      <title>The TiDB Command Options</title>
      <link>https://pingcap.com/docs/v2.1/sql/server-command-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/server-command-option/</guid>
      <description>The TiDB Command Options This document describes the startup options and TiDB server configuration files.
TiDB startup options When you start TiDB processes, you can specify some program options.
TiDB supports a lot of startup options. Run the following command to get a brief introduction:
./tidb-server --help Run the following command to get the version:
./tidb-server -V The complete descriptions of startup options are as follows.
-L  Log level Default: &amp;ldquo;info&amp;rdquo; Optional values: debug, info, warn, error or fatal  -P  TiDB service monitor port Default: &amp;ldquo;4000&amp;rdquo; TiDB uses this port to accept requests from the MySQL client  --binlog-socket  TiDB uses the unix socket file to accept the internal connection, such as the PUMP service.</description>
    </item>
    
    <item>
      <title>The TiDB Server</title>
      <link>https://pingcap.com/docs/v2.1/sql/tidb-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/tidb-server/</guid>
      <description>The TiDB Server TiDB refers to the TiDB database management system. This document describes the basic management functions of the TiDB cluster.
TiDB cluster startup configuration You can set the service parameters using the command line or the configuration file, or both. The priority of the command line parameters is higher than the configuration file. If the same parameter is set in both ways, TiDB uses the value set using command line parameters.</description>
    </item>
    
    <item>
      <title>The TiDB System Database</title>
      <link>https://pingcap.com/docs/v2.1/sql/system-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/system-database/</guid>
      <description>The TiDB System Database The TiDB System Database is similar to MySQL, which contains tables that store information required by the server when it runs.
Grant system tables These system tables contain grant information about user accounts and their privileges:
 user: user accounts, global privileges, and other non-privilege columns db: database-level privileges tables_priv: table-level privileges columns_priv: column-level privileges  Server-side help system tables Currently, the help_topic is NULL.</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/docs/releases/ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/ga/</guid>
      <description>TiDB 1.0 Release Notes On October 16, 2017, TiDB 1.0 is now released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Analyze pushdown Function signature pushdown  Optimize the internal data format to reduce the interim data size Enhance the MySQL compatibility Support the NO_SQL_CACHE syntax and limit the cache usage in the storage engine Refactor the Hash Aggregator operator to reduce the memory usage Support the Stream Aggregator operator  PD:  Support read flow based balancing Support setting the Store weight and weight based balancing  TiKV:  Coprocessor now supports more pushdown functions Support pushing down the sampling operation Support manually triggering data compact to collect space quickly Improve the performance and stability Add a Debug API for debugging TiSpark Beta Release: Support configuration framework Support ThriftSever/JDBC and Spark SQL  Acknowledgement Special thanks to the following enterprises and teams!</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/ga/</guid>
      <description>TiDB 1.0 Release Notes On October 16, 2017, TiDB 1.0 is now released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Analyze pushdown Function signature pushdown  Optimize the internal data format to reduce the interim data size Enhance the MySQL compatibility Support the NO_SQL_CACHE syntax and limit the cache usage in the storage engine Refactor the Hash Aggregator operator to reduce the memory usage Support the Stream Aggregator operator  PD:  Support read flow based balancing Support setting the Store weight and weight based balancing  TiKV:  Coprocessor now supports more pushdown functions Support pushing down the sampling operation Support manually triggering data compact to collect space quickly Improve the performance and stability Add a Debug API for debugging TiSpark Beta Release: Support configuration framework Support ThriftSever/JDBC and Spark SQL  Acknowledgement Special thanks to the following enterprises and teams!</description>
    </item>
    
    <item>
      <title>TiDB 1.0.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/101/</guid>
      <description>TiDB 1.0.1 Release Notes On November 1, 2017, TiDB 1.0.1 is released with the following updates:
TiDB:  Support canceling DDL Job. Optimize the IN expression. Correct the result type of the Show statement. Support log slow query into a separate log file. Fix bugs.  TiKV:  Support flow control with write bytes. Reduce Raft allocation. Increase coprocessor stack size to 10MB. Remove the useless log from the coprocessor.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.1 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/101/</guid>
      <description>TiDB 1.0.1 Release Notes On November 1, 2017, TiDB 1.0.1 is released with the following updates:
TiDB:  Support canceling DDL Job. Optimize the IN expression. Correct the result type of the Show statement. Support log slow query into a separate log file. Fix bugs.  TiKV:  Support flow control with write bytes. Reduce Raft allocation. Increase coprocessor stack size to 10MB. Remove the useless log from the coprocessor.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/102/</guid>
      <description> TiDB 1.0.2 Release Notes On November 13, 2017, TiDB 1.0.2 is released with the following updates:
TiDB:  Optimize the cost estimation of index point query Support the Alter Table Add Column (ColumnDef ColumnPosition) syntax Optimize the queries whose where conditions are contradictory Optimize the Add Index operation to rectify the progress and reduce repetitive operations Optimize the Index Look Join operator to accelerate the query speed for small data size Fix the issue with prefix index judgment  Placement Driver (PD):  Improve the stability of scheduling under exceptional situations  TiKV:  Support splitting table to ensure one region does not contain data from multiple tables Limit the length of a key to be no more than 4 KB More accurate read traffic statistics Implement deep protection on the coprocessor stack Fix the LIKE behavior and the do_div_mod bug  </description>
    </item>
    
    <item>
      <title>TiDB 1.0.2 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/102/</guid>
      <description> TiDB 1.0.2 Release Notes On November 13, 2017, TiDB 1.0.2 is released with the following updates:
TiDB:  Optimize the cost estimation of index point query Support the Alter Table Add Column (ColumnDef ColumnPosition) syntax Optimize the queries whose where conditions are contradictory Optimize the Add Index operation to rectify the progress and reduce repetitive operations Optimize the Index Look Join operator to accelerate the query speed for small data size Fix the issue with prefix index judgment  Placement Driver (PD):  Improve the stability of scheduling under exceptional situations  TiKV:  Support splitting table to ensure one region does not contain data from multiple tables Limit the length of a key to be no more than 4 KB More accurate read traffic statistics Implement deep protection on the coprocessor stack Fix the LIKE behavior and the do_div_mod bug  </description>
    </item>
    
    <item>
      <title>TiDB 1.0.3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/103/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/103/</guid>
      <description>TiDB 1.0.3 Release Notes On November 28, 2017, TiDB 1.0.3 is released with the following updates:
TiDB  Optimize the performance in transaction conflicts scenario Add the TokenLimit option in the config file Output the default database in slow query logs Remove the DDL statement from query duration metrics Optimize the query cost estimation Fix the index prefix issue when creating tables Support pushing down the expressions for the Float type to TiKV Fix the issue that it is slow to add index for tables with discrete integer primary index Reduce the unnecessary statistics updates Fix a potential issue during the transaction retry  PD  Support adding more types of schedulers using API  TiKV  Fix the deadlock issue with the PD client Fix the issue that the wrong leader value is prompted for NotLeader Fix the issue that the chunk size is too large in the coprocessor  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.3 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/103/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/103/</guid>
      <description>TiDB 1.0.3 Release Notes On November 28, 2017, TiDB 1.0.3 is released with the following updates:
TiDB  Optimize the performance in transaction conflicts scenario Add the TokenLimit option in the config file Output the default database in slow query logs Remove the DDL statement from query duration metrics Optimize the query cost estimation Fix the index prefix issue when creating tables Support pushing down the expressions for the Float type to TiKV Fix the issue that it is slow to add index for tables with discrete integer primary index Reduce the unnecessary statistics updates Fix a potential issue during the transaction retry  PD  Support adding more types of schedulers using API  TiKV  Fix the deadlock issue with the PD client Fix the issue that the wrong leader value is prompted for NotLeader Fix the issue that the chunk size is too large in the coprocessor  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/104/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/104/</guid>
      <description>TiDB 1.0.4 Release Notes On December 11, 2017, TiDB 1.0.4 is released with the following updates:
TiDB  Speed up the loading of the statistics when starting the tidb-server Improve the performance of the show variables statement Fix a potential issue when using the Add Index statement to handle the combined indexes Fix a potential issue when using the Rename Table statement to move a table to another database Accelerate the effectiveness for the Alter/Drop User statement  TiKV  Fix a possible performance issue when a snapshot is applied  Fix the performance issue for reverse scan after removing a lot of data Fix the wrong encoded result for the Decimal type under special circumstances  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.4 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/104/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/104/</guid>
      <description>TiDB 1.0.4 Release Notes On December 11, 2017, TiDB 1.0.4 is released with the following updates:
TiDB  Speed up the loading of the statistics when starting the tidb-server Improve the performance of the show variables statement Fix a potential issue when using the Add Index statement to handle the combined indexes Fix a potential issue when using the Rename Table statement to move a table to another database Accelerate the effectiveness for the Alter/Drop User statement  TiKV  Fix a possible performance issue when a snapshot is applied  Fix the performance issue for reverse scan after removing a lot of data Fix the wrong encoded result for the Decimal type under special circumstances  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/105/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/105/</guid>
      <description>TiDB 1.0.5 Release Notes On December 26, 2017, TiDB 1.0.5 is released with the following updates:
TiDB  Add the max value for the current Auto_Increment ID in the Show Create Table statement. Fix a potential goroutine leak. Support outputting slow queries into a separate file. Load the TimeZone variable from TiKV when creating a new session. Support the schema state check so that the Show Create Tableand Analyze statements process the public table/index only.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.5 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/105/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/105/</guid>
      <description>TiDB 1.0.5 Release Notes On December 26, 2017, TiDB 1.0.5 is released with the following updates:
TiDB  Add the max value for the current Auto_Increment ID in the Show Create Table statement. Fix a potential goroutine leak. Support outputting slow queries into a separate file. Load the TimeZone variable from TiKV when creating a new session. Support the schema state check so that the Show Create Tableand Analyze statements process the public table/index only.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.6 Release Notes</title>
      <link>https://pingcap.com/docs/releases/106/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/106/</guid>
      <description>TiDB 1.0.6 Release Notes On January 08, 2018, TiDB 1.0.6 is released with the following updates:
TiDB:  Support the Alter Table Auto_Increment syntax Fix the bug in Cost Based computation and the Null Json issue in statistics Support the extension syntax to shard the implicit row ID to avoid write hot spot for a single table Fix a potential DDL issue Consider the timezone setting in the curtime, sysdate and curdate functions Support the SEPARATOR syntax in the GROUP_CONCAT function Fix the wrong return type issue of the GROUP_CONCAT function.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.6 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/106/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/106/</guid>
      <description>TiDB 1.0.6 Release Notes On January 08, 2018, TiDB 1.0.6 is released with the following updates:
TiDB:  Support the Alter Table Auto_Increment syntax Fix the bug in Cost Based computation and the Null Json issue in statistics Support the extension syntax to shard the implicit row ID to avoid write hot spot for a single table Fix a potential DDL issue Consider the timezone setting in the curtime, sysdate and curdate functions Support the SEPARATOR syntax in the GROUP_CONCAT function Fix the wrong return type issue of the GROUP_CONCAT function.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.7 Release Notes</title>
      <link>https://pingcap.com/docs/releases/107/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/107/</guid>
      <description>TiDB 1.0.7 Release Notes On January 22, 2018, TiDB 1.0.7 is released with the following updates:
TiDB:  Optimize the FIELD_LIST command Fix data race of the information schema Avoid adding read-only statements to history Add the session variable to control the log query Fix the resource leak issue in statistics Fix the goroutine leak issue Add schema info API for the http status server Fix an issue about IndexJoin Update the behavior when RunWorker is false in DDL Improve the stability of test results in statistics Support PACK_KEYS syntax for the CREATE TABLE statement Add row_id column for the null pushdown schema to optimize performance  PD:  Fix possible scheduling loss issue in abnormal conditions Fix the compatibility issue with proto3 Add the log  TiKV:  Support Table Scan Support the remote mode in tikv-ctl Fix the format compatibility issue of tikv-ctl proto Fix the loss of scheduling command from PD Add timeout in Push metric  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.7 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/107/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/107/</guid>
      <description>TiDB 1.0.7 Release Notes On January 22, 2018, TiDB 1.0.7 is released with the following updates:
TiDB:  Optimize the FIELD_LIST command Fix data race of the information schema Avoid adding read-only statements to history Add the session variable to control the log query Fix the resource leak issue in statistics Fix the goroutine leak issue Add schema info API for the http status server Fix an issue about IndexJoin Update the behavior when RunWorker is false in DDL Improve the stability of test results in statistics Support PACK_KEYS syntax for the CREATE TABLE statement Add row_id column for the null pushdown schema to optimize performance  PD:  Fix possible scheduling loss issue in abnormal conditions Fix the compatibility issue with proto3 Add the log  TiKV:  Support Table Scan Support the remote mode in tikv-ctl Fix the format compatibility issue of tikv-ctl proto Fix the loss of scheduling command from PD Add timeout in Push metric  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.8 Release Notes</title>
      <link>https://pingcap.com/docs/releases/108/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/108/</guid>
      <description>TiDB 1.0.8 Release Notes On February 11, 2018, TiDB 1.0.8 is released with the following updates:
TiDB:  Fix issues in the Outer Join result in some scenarios Optimize the performance of the InsertIntoIgnore statement Fix the issue in the ShardRowID option Add limitation (Configurable, the default value is 5000) to the DML statements number within a transaction Fix an issue in the Table/Column aliases returned by the Prepare statement Fix an issue in updating statistics delta Fix a panic error in the Drop Column statement Fix an DML issue when running the Add Column After statement Improve the stability of the GC process by ignoring the regions with GC errors Run GC concurrently to accelerate the GC process Provide syntax support for the CREATE INDEX statement  PD:  Reduce the lock overheat of the region heartbeats Fix the issue that a hot region scheduler selects the wrong Leader  TiKV:  Use DeleteFilesInRanges to clear stale data and improve the TiKV starting speed Using Decimal in Coprocessor sum Sync the metadata of the received Snapshot compulsorily to ensure its safety  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.8 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/108/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/108/</guid>
      <description>TiDB 1.0.8 Release Notes On February 11, 2018, TiDB 1.0.8 is released with the following updates:
TiDB:  Fix issues in the Outer Join result in some scenarios Optimize the performance of the InsertIntoIgnore statement Fix the issue in the ShardRowID option Add limitation (Configurable, the default value is 5000) to the DML statements number within a transaction Fix an issue in the Table/Column aliases returned by the Prepare statement Fix an issue in updating statistics delta Fix a panic error in the Drop Column statement Fix an DML issue when running the Add Column After statement Improve the stability of the GC process by ignoring the regions with GC errors Run GC concurrently to accelerate the GC process Provide syntax support for the CREATE INDEX statement  PD:  Reduce the lock overheat of the region heartbeats Fix the issue that a hot region scheduler selects the wrong Leader  TiKV:  Use DeleteFilesInRanges to clear stale data and improve the TiKV starting speed Using Decimal in Coprocessor sum Sync the metadata of the received Snapshot compulsorily to ensure its safety  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/docs/releases/11alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/11alpha/</guid>
      <description> TiDB 1.1 Alpha Release Notes On January 19, 2018, TiDB 1.1 Alpha is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  SQL parser  Support more syntax  SQL query optimizer  Use more compact structure to reduce statistics info memory usage Speed up loading statistics info when starting tidb-server Provide more accurate query cost evaluation Use Count-Min Sketch to estimate the cost of queries using unique index more accurately Support more complex conditions to make full use of index  SQL executor  Refactor all executor operators using Chunk architecture, improve the execution performance of analytical statements and reduce memory usage Optimize performance of the INSERT IGNORE statement Push down more types and functions to TiKV Support more SQL_MODE Optimize the Load Data performance to increase the speed by 10 times Optimize the Use Database performance Support statistics on the memory usage of physical operators  Server  Support the PROXY protocol   PD:  Add more APIs Support TLS Add more cases for scheduling Simulator Schedule to adapt to different Region sizes Fix some bugs about scheduling  TiKV:  Support Raft learner Optimize Raft Snapshot and reduce the I/O overhead Support TLS Optimize the RocksDB configuration to improve performance Optimize count (*) and query performance of unique index in Coprocessor Add more failpoints and stability test cases Solve the reconnection issue between PD and TiKV Enhance the features of the data recovery tool tikv-ctl Support splitting according to table in Region Support the Delete Range feature Support setting the I/O limit caused by snapshot Improve the flow control mechanism  </description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/11alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/11alpha/</guid>
      <description> TiDB 1.1 Alpha Release Notes On January 19, 2018, TiDB 1.1 Alpha is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  SQL parser  Support more syntax  SQL query optimizer  Use more compact structure to reduce statistics info memory usage Speed up loading statistics info when starting tidb-server Provide more accurate query cost evaluation Use Count-Min Sketch to estimate the cost of queries using unique index more accurately Support more complex conditions to make full use of index  SQL executor  Refactor all executor operators using Chunk architecture, improve the execution performance of analytical statements and reduce memory usage Optimize performance of the INSERT IGNORE statement Push down more types and functions to TiKV Support more SQL_MODE Optimize the Load Data performance to increase the speed by 10 times Optimize the Use Database performance Support statistics on the memory usage of physical operators  Server  Support the PROXY protocol   PD:  Add more APIs Support TLS Add more cases for scheduling Simulator Schedule to adapt to different Region sizes Fix some bugs about scheduling  TiKV:  Support Raft learner Optimize Raft Snapshot and reduce the I/O overhead Support TLS Optimize the RocksDB configuration to improve performance Optimize count (*) and query performance of unique index in Coprocessor Add more failpoints and stability test cases Solve the reconnection issue between PD and TiKV Enhance the features of the data recovery tool tikv-ctl Support splitting according to table in Region Support the Delete Range feature Support setting the I/O limit caused by snapshot Improve the flow control mechanism  </description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs/releases/11beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/11beta/</guid>
      <description>TiDB 1.1 Beta Release Notes On February 24, 2018, TiDB 1.1 Beta is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  Add more monitoring metrics and refine the log Compatible with more MySQL syntax Support displaying the table creating time in information_schema Optimize queries containing the MaxOneRow operator Configure the size of intermediate result sets generated by Join, to further reduce the memory used by Join Add the tidb_config session variable to output the current TiDB configuration Fix the panic issue in the Union and Index Join operators Fix the wrong result issue of the Sort Merge Join operator in some scenarios Fix the issue that the Show Index statement shows indexes that are in the process of adding Fix the failure of the Drop Stats statement Optimize the query performance of the SQL engine to improve the test result of the Sysbench Select/OLTP by 10% Improve the computing speed of subqueries in the optimizer using the new execution engine; compared with TiDB 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/11beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/11beta/</guid>
      <description>TiDB 1.1 Beta Release Notes On February 24, 2018, TiDB 1.1 Beta is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  Add more monitoring metrics and refine the log Compatible with more MySQL syntax Support displaying the table creating time in information_schema Optimize queries containing the MaxOneRow operator Configure the size of intermediate result sets generated by Join, to further reduce the memory used by Join Add the tidb_config session variable to output the current TiDB configuration Fix the panic issue in the Union and Index Join operators Fix the wrong result issue of the Sort Merge Join operator in some scenarios Fix the issue that the Show Index statement shows indexes that are in the process of adding Fix the failure of the Drop Stats statement Optimize the query performance of the SQL engine to improve the test result of the Sysbench Select/OLTP by 10% Improve the computing speed of subqueries in the optimizer using the new execution engine; compared with TiDB 1.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc1/</guid>
      <description> TiDB 2.0 RC1 Release Notes On March 9, 2018, TiDB 2.0 RC1 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Support limiting the memory usage by a single SQL statement, to reduce the risk of OOM Support pushing the Stream Aggregate operator down to TiKV Support validating the configuration file Support obtaining the information of TiDB configuration through HTTP API Compatible with more MySQL syntax in Parser Improve the compatibility with Navicat Improve the optimizer and extract common expressions with multiple OR conditions, to choose better query plan Improve the optimizer and convert subqueries to Join operators in more scenarios, to choose better query plan Resolve Lock in the Batch mode to increase the garbage collection speed Fix the length of Boolean field to improve compatibility Optimize the Add Index operation and give lower priority to all write and read operations, to reduce the impact on online business  PD:  Optimize the logic of code used to check the Region status to improve performance Optimize the output of log information in abnormal conditions to facilitate debugging Fix the monitor statistics that the disk space of TiKV nodes is not enough Fix the wrong reporting issue of the health interface when TLS is enabled Fix the issue that concurrent addition of replicas might exceed the threshold value of configuration, to improve stability  TiKV:  Fix the issue that gRPC call is not cancelled when PD leaders switch Protect important configuration which cannot be changed after initial configuration Add gRPC APIs used to obtain metrics Check whether SSD is used when you start the cluster Optimize the read performance using ReadPool, and improve the performance by 30% in the raw get test Improve metrics and optimize the usage of metrics  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC1 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2rc1/</guid>
      <description> TiDB 2.0 RC1 Release Notes On March 9, 2018, TiDB 2.0 RC1 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Support limiting the memory usage by a single SQL statement, to reduce the risk of OOM Support pushing the Stream Aggregate operator down to TiKV Support validating the configuration file Support obtaining the information of TiDB configuration through HTTP API Compatible with more MySQL syntax in Parser Improve the compatibility with Navicat Improve the optimizer and extract common expressions with multiple OR conditions, to choose better query plan Improve the optimizer and convert subqueries to Join operators in more scenarios, to choose better query plan Resolve Lock in the Batch mode to increase the garbage collection speed Fix the length of Boolean field to improve compatibility Optimize the Add Index operation and give lower priority to all write and read operations, to reduce the impact on online business  PD:  Optimize the logic of code used to check the Region status to improve performance Optimize the output of log information in abnormal conditions to facilitate debugging Fix the monitor statistics that the disk space of TiKV nodes is not enough Fix the wrong reporting issue of the health interface when TLS is enabled Fix the issue that concurrent addition of replicas might exceed the threshold value of configuration, to improve stability  TiKV:  Fix the issue that gRPC call is not cancelled when PD leaders switch Protect important configuration which cannot be changed after initial configuration Add gRPC APIs used to obtain metrics Check whether SSD is used when you start the cluster Optimize the read performance using ReadPool, and improve the performance by 30% in the raw get test Improve metrics and optimize the usage of metrics  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc3/</guid>
      <description> TiDB 2.0 RC3 Release Notes On March 23, 2018, TiDB 2.0 RC3 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Fix the wrong result issue of MAX/MIN in some scenarios Fix the issue that the result of Sort Merge Join does not show in order of Join Key in some scenarios Fix the error of comparison between uint and int in boundary conditions Optimize checks on length and precision of the floating point type, to improve compatibility with MySQL Improve the parsing error log of time type and add more error information Improve memory control and add statistics about IndexLookupExecutor memory Optimize the execution speed of ADD INDEX to greatly increase the speed in some scenarios Use the Stream Aggregation operator when the GROUP BY substatement is empty, to increase the speed Support closing the Join Reorder optimization in the optimizer using STRAIGHT_JOIN Output more detailed status information of DDL jobs in ADMIN SHOW DDL JOBS Support querying the original statements of currently running DDL jobs using ADMIN SHOW DDL JOB QUERIES Support recovering the index data using ADMIN RECOVER INDEX for disaster recovery Attach a lower priority to the ADD INDEX operation to reduce the impact on online business Support aggregation functions with JSON type parameters, such as SUM/AVG Support modifying the lower_case_table_names system variable in the configuration file, to support the OGG data synchronization tool Improve compatibility with the Navicat management tool Support using implicit RowID in CRUD operations  PD:  Support Region Merge, to merge empty Regions or small Regions after deleting data Ignore the nodes that have a lot of pending peers during adding replicas, to improve the speed of restoring replicas or making nodes offline Fix the frequent scheduling issue caused by a large number of empty Regions Optimize the scheduling speed of leader balance in scenarios of unbalanced resources within different labels Add more statistics about abnormal Regions  TiKV:  Support Region Merge Inform PD immediately once the Raft snapshot process is completed, to speed up balancing Add the Raw DeleteRange API Add the GetMetric API Reduce the I/O fluctuation caused by RocksDB sync files Optimize the space reclaiming mechanism after deleting data Improve the data recovery tool tikv-ctl Fix the issue that it is slow to make nodes down caused by snapshot Support streaming in Coprocessor Support Readpool and increase the raw_get/get/batch_get by 30% Support configuring the request timeout of Coprocessor Support streaming aggregation in Coprocessor Carry time information in Region heartbeats Limit the space usage of snapshot files to avoid consuming too much disk space Record and report the Regions that cannot elect a leader for a long time Speed up garbage cleaning when starting the server Update the size information about the corresponding Region according to compaction events Limit the size of scan lock to avoid request timeout Use DeleteRange to speed up Region deletion Support modifying RocksDB parameters online  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC3 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2rc3/</guid>
      <description> TiDB 2.0 RC3 Release Notes On March 23, 2018, TiDB 2.0 RC3 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Fix the wrong result issue of MAX/MIN in some scenarios Fix the issue that the result of Sort Merge Join does not show in order of Join Key in some scenarios Fix the error of comparison between uint and int in boundary conditions Optimize checks on length and precision of the floating point type, to improve compatibility with MySQL Improve the parsing error log of time type and add more error information Improve memory control and add statistics about IndexLookupExecutor memory Optimize the execution speed of ADD INDEX to greatly increase the speed in some scenarios Use the Stream Aggregation operator when the GROUP BY substatement is empty, to increase the speed Support closing the Join Reorder optimization in the optimizer using STRAIGHT_JOIN Output more detailed status information of DDL jobs in ADMIN SHOW DDL JOBS Support querying the original statements of currently running DDL jobs using ADMIN SHOW DDL JOB QUERIES Support recovering the index data using ADMIN RECOVER INDEX for disaster recovery Attach a lower priority to the ADD INDEX operation to reduce the impact on online business Support aggregation functions with JSON type parameters, such as SUM/AVG Support modifying the lower_case_table_names system variable in the configuration file, to support the OGG data synchronization tool Improve compatibility with the Navicat management tool Support using implicit RowID in CRUD operations  PD:  Support Region Merge, to merge empty Regions or small Regions after deleting data Ignore the nodes that have a lot of pending peers during adding replicas, to improve the speed of restoring replicas or making nodes offline Fix the frequent scheduling issue caused by a large number of empty Regions Optimize the scheduling speed of leader balance in scenarios of unbalanced resources within different labels Add more statistics about abnormal Regions  TiKV:  Support Region Merge Inform PD immediately once the Raft snapshot process is completed, to speed up balancing Add the Raw DeleteRange API Add the GetMetric API Reduce the I/O fluctuation caused by RocksDB sync files Optimize the space reclaiming mechanism after deleting data Improve the data recovery tool tikv-ctl Fix the issue that it is slow to make nodes down caused by snapshot Support streaming in Coprocessor Support Readpool and increase the raw_get/get/batch_get by 30% Support configuring the request timeout of Coprocessor Support streaming aggregation in Coprocessor Carry time information in Region heartbeats Limit the space usage of snapshot files to avoid consuming too much disk space Record and report the Regions that cannot elect a leader for a long time Speed up garbage cleaning when starting the server Update the size information about the corresponding Region according to compaction events Limit the size of scan lock to avoid request timeout Use DeleteRange to speed up Region deletion Support modifying RocksDB parameters online  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc4/</guid>
      <description> TiDB 2.0 RC4 Release Notes On March 30, 2018, TiDB 2.0 RC4 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Support SHOW GRANTS FOR CURRENT_USER(); Fix the issue that the Expression in UnionScan is not cloned Support the SET TRANSACTION syntax Fix the potential goroutine leak issue in copIterator Fix the issue that admin check table misjudges the unique index including null Support displaying floating point numbers using scientific notation Fix the type inference issue during binary literal computing Fix the issue in parsing the CREATE VIEW statement Fix the panic issue when one statement contains both ORDER BY and LIMIT 0 Improve the execution performance of DecodeBytes Optimize LIMIT 0 to TableDual, to avoid building useless execution plans  PD:  Support splitting Region manually to handle the hot spot in a single Region Fix the issue that the label property is not displayed when pdctl runs config show all Optimize metrics and code structure  TiKV:  Limit the memory usage during receiving snapshots, to avoid OOM in extreme conditions Support configuring the behavior of Coprocessor when it encounters warnings Support importing the data pattern in TiKV Support splitting Region in the middle Increase the speed of CI test Use crossbeam channel Fix the issue that too many logs are output caused by leader missing when TiKV is isolated  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC4 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2rc4/</guid>
      <description> TiDB 2.0 RC4 Release Notes On March 30, 2018, TiDB 2.0 RC4 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB:  Support SHOW GRANTS FOR CURRENT_USER(); Fix the issue that the Expression in UnionScan is not cloned Support the SET TRANSACTION syntax Fix the potential goroutine leak issue in copIterator Fix the issue that admin check table misjudges the unique index including null Support displaying floating point numbers using scientific notation Fix the type inference issue during binary literal computing Fix the issue in parsing the CREATE VIEW statement Fix the panic issue when one statement contains both ORDER BY and LIMIT 0 Improve the execution performance of DecodeBytes Optimize LIMIT 0 to TableDual, to avoid building useless execution plans  PD:  Support splitting Region manually to handle the hot spot in a single Region Fix the issue that the label property is not displayed when pdctl runs config show all Optimize metrics and code structure  TiKV:  Limit the memory usage during receiving snapshots, to avoid OOM in extreme conditions Support configuring the behavior of Coprocessor when it encounters warnings Support importing the data pattern in TiKV Support splitting Region in the middle Increase the speed of CI test Use crossbeam channel Fix the issue that too many logs are output caused by leader missing when TiKV is isolated  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2rc5/</guid>
      <description> TiDB 2.0 RC5 Release Notes On April 17, 2018, TiDB 2.0 RC5 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB  Fix the issue about applying the Top-N pushdown rule Fix the estimation of the number of rows for the columns that contain NULL values Fix the zero value of the Binary type Fix the BatchGet issue within a transaction Clean up the written data while rolling back the Add Index operation, to reduce consumed space Optimize the insert on duplicate key update statement to improve the performance by 10 times Fix the issue about the type of the results returned by the UNIX_TIMESTAMP function Fix the issue that the NULL value is inserted while adding NOT NULL columns Support showing memory usage of the executing statements in the Show Process List statement Fix the issue that Alter Table Modify Column reports an error in extreme conditions Support setting the table comment using the Alter statement  PD  Add support for Raft Learner Optimize the Balance Region Scheduler to reduce scheduling overhead Adjust the default value of schedule-limit configuration Fix the issue of allocating ID frequently Fix the compatibility issue when adding a new scheduler  TiKV  Support the Region specified by compact in tikv-ctl Support Batch Put, Batch Get, Batch Delete and Batch Scan in the RawKVClient Fix the OOM issue caused by too many snapshots Return more detailed error information in Coprocessor Support dynamically modifying the block-cache-size in TiKV through tikv-ctl Further improve importer Simplify the ImportSST::Upload interface Configure the keepalive property of gRPC Split tikv-importer from TiKV as an independent binary Provide statistics about the number of rows scanned by each scan range in Coprocessor Fix the compilation issue on the macOS system Fix the issue of misusing a RocksDB metric Support the overflow as warning option in Coprocessor  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC5 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2rc5/</guid>
      <description> TiDB 2.0 RC5 Release Notes On April 17, 2018, TiDB 2.0 RC5 is released. This release has great improvement in MySQL compatibility, SQL optimization and stability.
TiDB  Fix the issue about applying the Top-N pushdown rule Fix the estimation of the number of rows for the columns that contain NULL values Fix the zero value of the Binary type Fix the BatchGet issue within a transaction Clean up the written data while rolling back the Add Index operation, to reduce consumed space Optimize the insert on duplicate key update statement to improve the performance by 10 times Fix the issue about the type of the results returned by the UNIX_TIMESTAMP function Fix the issue that the NULL value is inserted while adding NOT NULL columns Support showing memory usage of the executing statements in the Show Process List statement Fix the issue that Alter Table Modify Column reports an error in extreme conditions Support setting the table comment using the Alter statement  PD  Add support for Raft Learner Optimize the Balance Region Scheduler to reduce scheduling overhead Adjust the default value of schedule-limit configuration Fix the issue of allocating ID frequently Fix the compatibility issue when adding a new scheduler  TiKV  Support the Region specified by compact in tikv-ctl Support Batch Put, Batch Get, Batch Delete and Batch Scan in the RawKVClient Fix the OOM issue caused by too many snapshots Return more detailed error information in Coprocessor Support dynamically modifying the block-cache-size in TiKV through tikv-ctl Further improve importer Simplify the ImportSST::Upload interface Configure the keepalive property of gRPC Split tikv-importer from TiKV as an independent binary Provide statistics about the number of rows scanned by each scan range in Coprocessor Fix the compilation issue on the macOS system Fix the issue of misusing a RocksDB metric Support the overflow as warning option in Coprocessor  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.0ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.0ga/</guid>
      <description>TiDB 2.0 Release Notes On April 27, 2018, TiDB 2.0 GA is released! Compared with TiDB 1.0, this release has great improvement in MySQL compatibility, SQL optimizer, executor, and stability.
TiDB  SQL Optimizer  Use more compact data structure to reduce the memory usage of statistics information Speed up loading statistics information when starting a tidb-server process Support updating statistics information dynamically [experimental] Optimize the cost model to provide more accurate query cost evaluation Use Count-Min Sketch to estimate the cost of point queries more accurately Support analyzing more complex conditions to make full use of indexes Support manually specifying the Join order using the STRAIGHT_JOIN syntax Use the Stream Aggregation operator when the GROUP BY clause is empty to improve the performance Support using indexes for the MAX/MIN function Optimize the processing algorithms for correlated subqueries to support decorrelating more types of correlated subqueries and transform them to Left Outer Join Extend IndexLookupJoin to be used in matching the index prefix  SQL Execution Engine  Refactor all operators using the Chunk architecture, improve the execution performance of analytical queries, and reduce memory usage.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2.0ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2.0ga/</guid>
      <description>TiDB 2.0 Release Notes On April 27, 2018, TiDB 2.0 GA is released! Compared with TiDB 1.0, this release has great improvement in MySQL compatibility, SQL optimizer, executor, and stability.
TiDB  SQL Optimizer  Use more compact data structure to reduce the memory usage of statistics information Speed up loading statistics information when starting a tidb-server process Support updating statistics information dynamically [experimental] Optimize the cost model to provide more accurate query cost evaluation Use Count-Min Sketch to estimate the cost of point queries more accurately Support analyzing more complex conditions to make full use of indexes Support manually specifying the Join order using the STRAIGHT_JOIN syntax Use the Stream Aggregation operator when the GROUP BY clause is empty to improve the performance Support using indexes for the MAX/MIN function Optimize the processing algorithms for correlated subqueries to support decorrelating more types of correlated subqueries and transform them to Left Outer Join Extend IndexLookupJoin to be used in matching the index prefix  SQL Execution Engine  Refactor all operators using the Chunk architecture, improve the execution performance of analytical queries, and reduce memory usage.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 Upgrade Guide</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/tidb-v2.0-upgrade-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/tidb-v2.0-upgrade-guide/</guid>
      <description>TiDB 2.0 Upgrade Guide This document describes how to upgrade from TiDB 1.0 or TiDB 2.0 RC version to TiDB 2.0 GA version.
Step 1: Install Ansible and dependencies in the Control Machine TiDB-Ansible release-2.0 depends on Ansible 2.4.2 or later, and is compatible with the latest Ansible 2.5. In addition, TiDB-Ansible release-2.0 depends on the Python module: jinja2&amp;gt;=2.9.6 and jmespath&amp;gt;=0.9.0.
To make it easy to manage dependencies, use pip to install Ansible and its dependencies.</description>
    </item>
    
    <item>
      <title>TiDB 2.0.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/201/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/201/</guid>
      <description> TiDB 2.0.1 Release Notes On May 16, 2018, TiDB 2.0.1 is released. Compared with TiDB 2.0.0 (GA), this release has great improvement in MySQL compatibility and system stability.
TiDB  Update the progress of Add Index to the DDL job information in real time Add the tidb_auto_analyze_ratio session variable to control the threshold value of automatic statistics update Fix an issue that not all residual states are cleaned up when the transaction commit fails Fix a bug about adding indexes in some conditions Fix the correctness related issue when DDL modifies surface operations in some concurrent scenarios Fix a bug that the result of LIMIT is incorrect in some conditions Fix a capitalization issue of the ADMIN CHECK INDEX statement to make its index name case insensitive Fix a compatibility issue of the UNION statement Fix a compatibility issue when inserting data of TIME type Fix a goroutine leak issue caused by copIteratorTaskSender in some conditions Add an option for TiDB to control the behaviour of Binlog failure Refactor the Coprocessor slow log to distinguish between the scenario of tasks with long processing time and long waiting time Log nothing when meeting MySQL protocol handshake error, to avoid too many logs caused by the load balancer Keep Alive mechanism Refine the Out of range value for column error message Fix a bug when there is a subquery in an Update statement Change the behaviour of handling SIGTERM, and do not wait for all queries to terminate anymore  PD  Add the Scatter Range scheduler to balance Regions with the specified key range Optimize the scheduling of Merge Region to prevent the newly split Region from being merged Add Learner related metrics Fix the issue that the scheduler is mistakenly deleted after restart Fix the error that occurs when parsing the configuration file Fix the issue that the etcd leader and the PD leader are not synchronized Fix the issue that Learner still appears after it is closed Fix the issue that Regions fail to load because the packet size is too large  TiKV  Fix the issue that SELECT FOR UPDATE prevents others from reading Optimize the slow query log Reduce the number of thread_yield calls Fix the bug that raftstore is accidentally blocked when generating the snapshot Fix the issue that Learner cannot be successfully elected in special conditions Fix the issue that split might cause dirty read in extreme conditions Correct the default value of the read thread pool configuration Speed up Delete Range  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.1 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/201/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/201/</guid>
      <description> TiDB 2.0.1 Release Notes On May 16, 2018, TiDB 2.0.1 is released. Compared with TiDB 2.0.0 (GA), this release has great improvement in MySQL compatibility and system stability.
TiDB  Update the progress of Add Index to the DDL job information in real time Add the tidb_auto_analyze_ratio session variable to control the threshold value of automatic statistics update Fix an issue that not all residual states are cleaned up when the transaction commit fails Fix a bug about adding indexes in some conditions Fix the correctness related issue when DDL modifies surface operations in some concurrent scenarios Fix a bug that the result of LIMIT is incorrect in some conditions Fix a capitalization issue of the ADMIN CHECK INDEX statement to make its index name case insensitive Fix a compatibility issue of the UNION statement Fix a compatibility issue when inserting data of TIME type Fix a goroutine leak issue caused by copIteratorTaskSender in some conditions Add an option for TiDB to control the behaviour of Binlog failure Refactor the Coprocessor slow log to distinguish between the scenario of tasks with long processing time and long waiting time Log nothing when meeting MySQL protocol handshake error, to avoid too many logs caused by the load balancer Keep Alive mechanism Refine the Out of range value for column error message Fix a bug when there is a subquery in an Update statement Change the behaviour of handling SIGTERM, and do not wait for all queries to terminate anymore  PD  Add the Scatter Range scheduler to balance Regions with the specified key range Optimize the scheduling of Merge Region to prevent the newly split Region from being merged Add Learner related metrics Fix the issue that the scheduler is mistakenly deleted after restart Fix the error that occurs when parsing the configuration file Fix the issue that the etcd leader and the PD leader are not synchronized Fix the issue that Learner still appears after it is closed Fix the issue that Regions fail to load because the packet size is too large  TiKV  Fix the issue that SELECT FOR UPDATE prevents others from reading Optimize the slow query log Reduce the number of thread_yield calls Fix the bug that raftstore is accidentally blocked when generating the snapshot Fix the issue that Learner cannot be successfully elected in special conditions Fix the issue that split might cause dirty read in extreme conditions Correct the default value of the read thread pool configuration Speed up Delete Range  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.10 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.0.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.0.10/</guid>
      <description>TiDB 2.0.10 Release Notes On December 18, 2018, TiDB 2.0.10 is released. The corresponding TiDB-Ansible 2.0.10 is also released. Compared with TiDB 2.0.9, this release has great improvement in system compatibility and stability.
TiDB  Fix the possible issue caused by canceling a DDL job #8513 Fix the issue that the ORDER BY and UNION clauses cannot quote the column including a table name #8514 Fix the issue that the UNCOMPRESS function does not judge the incorrect input length #8607 Fix the issue encountered by ANSI_QUOTES SQL_MODE when upgrading TiDB #8575 Fix the issue that select returns the wrong result in some cases #8570 Fix the possible issue that TiDB cannot exit when it receives the exit signal #8501 Fix the issue that IndexLookUpJoin returns the wrong result in some cases #8508 Avoid pushing down the filter containing GetVar or SetVar #8454 Fix the issue that the result length of the UNION clauses is incorrect in some cases #8491 Fix the issue of PREPARE FROM @var_name #8488 Fix the panic issue when dumping statistics information in some cases #8464 Fix the statistics estimation issue of point queries in some cases #8493 Fix the panic issue when the returned default enum value is a string #8476 Fix the issue that too much memory is consumed in the scenario of wide tables #8467 Fix the issue encountered when Parser incorrectly formats the mod opcode #8431</description>
    </item>
    
    <item>
      <title>TiDB 2.0.10 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2.0.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2.0.10/</guid>
      <description>TiDB 2.0.10 Release Notes On December 18, 2018, TiDB 2.0.10 is released. The corresponding TiDB-Ansible 2.0.10 is also released. Compared with TiDB 2.0.9, this release has great improvement in system compatibility and stability.
TiDB  Fix the possible issue caused by canceling a DDL job #8513 Fix the issue that the ORDER BY and UNION clauses cannot quote the column including a table name #8514 Fix the issue that the UNCOMPRESS function does not judge the incorrect input length #8607 Fix the issue encountered by ANSI_QUOTES SQL_MODE when upgrading TiDB #8575 Fix the issue that select returns the wrong result in some cases #8570 Fix the possible issue that TiDB cannot exit when it receives the exit signal #8501 Fix the issue that IndexLookUpJoin returns the wrong result in some cases #8508 Avoid pushing down the filter containing GetVar or SetVar #8454 Fix the issue that the result length of the UNION clauses is incorrect in some cases #8491 Fix the issue of PREPARE FROM @var_name #8488 Fix the panic issue when dumping statistics information in some cases #8464 Fix the statistics estimation issue of point queries in some cases #8493 Fix the panic issue when the returned default enum value is a string #8476 Fix the issue that too much memory is consumed in the scenario of wide tables #8467 Fix the issue encountered when Parser incorrectly formats the mod opcode #8431</description>
    </item>
    
    <item>
      <title>TiDB 2.0.11 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.0.11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.0.11/</guid>
      <description> TiDB 2.0.11 Release Notes On January 03, 2019, TiDB 2.0.11 is released. The corresponding TiDB-Ansible 2.0.11 is also released. Compared with TiDB 2.0.10, this release has great improvement in system compatibility and stability.
TiDB  Fix the issue that the error is not handled properly when PD is in an abnormal condition #8764 Fix the issue that the Rename operation on a table in TiDB is not compatible with that in MySQL #8809 Fix the issue that the error message is wrongly reported when the ADMIN CHECK TABLE operation is performed in the process of executing the ADD INDEX statement #8750 Fix the issue that the prefix index range is incorrect in some cases #8877 Fix the panic issue of the UPDATE statement when columns are added in some cases #8904  TiKV  Fix two issues about Region merge #4003, #4004  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.11 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2.0.11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2.0.11/</guid>
      <description> TiDB 2.0.11 Release Notes On January 03, 2019, TiDB 2.0.11 is released. The corresponding TiDB-Ansible 2.0.11 is also released. Compared with TiDB 2.0.10, this release has great improvement in system compatibility and stability.
TiDB  Fix the issue that the error is not handled properly when PD is in an abnormal condition #8764 Fix the issue that the Rename operation on a table in TiDB is not compatible with that in MySQL #8809 Fix the issue that the error message is wrongly reported when the ADMIN CHECK TABLE operation is performed in the process of executing the ADD INDEX statement #8750 Fix the issue that the prefix index range is incorrect in some cases #8877 Fix the panic issue of the UPDATE statement when columns are added in some cases #8904  TiKV  Fix two issues about Region merge #4003, #4004  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/202/</guid>
      <description> TiDB 2.0.2 Release Notes On May 21, 2018, TiDB 2.0.2 is released. Compared with TiDB 2.0.1, this release has great improvement in system stability.
TiDB  Fix the issue of pushing down the Decimal division expression Support using the USE INDEX syntax in the Delete statement Forbid using the shard_row_id_bits feature in columns with Auto-Increment Add the timeout mechanism for writing Binlog  PD  Make the balance leader scheduler filter the disconnected nodes Modify the timeout of the transfer leader operator to 10s Fix the issue that the label scheduler does not schedule when the cluster Regions are in an unhealthy state Fix the improper scheduling issue of evict leader scheduler  TiKV  Fix the issue that the Raft log is not printed Support configuring more gRPC related parameters Support configuring the timeout range of leader election Fix the issue that the obsolete learner is not deleted Fix the issue that the snapshot intermediate file is mistakenly deleted  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.2 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/202/</guid>
      <description> TiDB 2.0.2 Release Notes On May 21, 2018, TiDB 2.0.2 is released. Compared with TiDB 2.0.1, this release has great improvement in system stability.
TiDB  Fix the issue of pushing down the Decimal division expression Support using the USE INDEX syntax in the Delete statement Forbid using the shard_row_id_bits feature in columns with Auto-Increment Add the timeout mechanism for writing Binlog  PD  Make the balance leader scheduler filter the disconnected nodes Modify the timeout of the transfer leader operator to 10s Fix the issue that the label scheduler does not schedule when the cluster Regions are in an unhealthy state Fix the improper scheduling issue of evict leader scheduler  TiKV  Fix the issue that the Raft log is not printed Support configuring more gRPC related parameters Support configuring the timeout range of leader election Fix the issue that the obsolete learner is not deleted Fix the issue that the snapshot intermediate file is mistakenly deleted  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/203/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/203/</guid>
      <description> TiDB 2.0.3 Release Notes On June 1, 2018, TiDB 2.0.3 is released. Compared with TiDB 2.0.2, this release has great improvement in system compatibility and stability.
TiDB  Support modifying the log level online Support the COM_CHANGE_USER command Support using the TIME type parameters under the binary protocol Optimize the cost estimation of query conditions with the BETWEEN expression Do not display the FOREIGN KEY information in the result of SHOW CREATE TABLE Optimize the cost estimation for queries with the LIMIT clause Fix the issue about the YEAR type as the unique index Fix the issue about ON DUPLICATE KEY UPDATE in conditions without the unique index Fix the compatibility issue of the CEIL function Fix the accuracy issue of the DIV calculation in the DECIMAL type Fix the false alarm of ADMIN CHECK TABLE Fix the panic issue of MAX/MIN under specific expression parameters Fix the issue that the result of JOIN is null in special conditions Fix the IN expression issue when building and querying Range Fix a Range calculation issue when using Prepare to query and Plan Cache is enabled Fix the issue that the Schema information is frequently loaded in abnormal conditions  PD  Fix the panic issue when collecting hot-cache metrics in specific conditions Fix the issue about scheduling of the obsolete Regions  TiKV  Fix the bug that the learner flag mistakenly reports to PD Report an error instead of getting a result if divisor/dividend is 0 in do_div_mod  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.3 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/203/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/203/</guid>
      <description> TiDB 2.0.3 Release Notes On June 1, 2018, TiDB 2.0.3 is released. Compared with TiDB 2.0.2, this release has great improvement in system compatibility and stability.
TiDB  Support modifying the log level online Support the COM_CHANGE_USER command Support using the TIME type parameters under the binary protocol Optimize the cost estimation of query conditions with the BETWEEN expression Do not display the FOREIGN KEY information in the result of SHOW CREATE TABLE Optimize the cost estimation for queries with the LIMIT clause Fix the issue about the YEAR type as the unique index Fix the issue about ON DUPLICATE KEY UPDATE in conditions without the unique index Fix the compatibility issue of the CEIL function Fix the accuracy issue of the DIV calculation in the DECIMAL type Fix the false alarm of ADMIN CHECK TABLE Fix the panic issue of MAX/MIN under specific expression parameters Fix the issue that the result of JOIN is null in special conditions Fix the IN expression issue when building and querying Range Fix a Range calculation issue when using Prepare to query and Plan Cache is enabled Fix the issue that the Schema information is frequently loaded in abnormal conditions  PD  Fix the panic issue when collecting hot-cache metrics in specific conditions Fix the issue about scheduling of the obsolete Regions  TiKV  Fix the bug that the learner flag mistakenly reports to PD Report an error instead of getting a result if divisor/dividend is 0 in do_div_mod  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/204/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/204/</guid>
      <description> TiDB 2.0.4 Release Notes On June 15, 2018, TiDB 2.0.4 is released. Compared with TiDB 2.0.3, this release has great improvement in system compatibility and stability.
TiDB  Support the ALTER TABLE t DROP COLUMN a CASCADE syntax Support configuring the value of tidb_snapshot to TSO Refine the display of statement types in monitoring items Optimize the accuracy of query cost estimation Configure the backoff max delay parameter of gRPC Support configuring the memory threshold of a single statement in the configuration file Refactor the error of Optimizer Fix the side effects of the Cast Decimal data Fix the wrong result issue of the Merge Join operator in specific scenarios Fix the issue of converting the Null object to String Fix the issue of casting the JSON type of data to the JSON type Fix the issue that the result order is not consistent with MySQL in the condition of Union + OrderBy Fix the compliance rules issue when the Union statement checks the Limit/OrderBy clause Fix the compatibility issue of the Union All result Fix a bug in predicate pushdown Fix the compatibility issue of the Union statement with the For Update clause Fix the issue that the concat_ws function mistakenly truncates the result  PD  Improve the behavior of the unset scheduling argument max-pending-peer-count by changing it to no limit for the maximum number of PendingPeers  TiKV  Add the RocksDB PerfContext interface for debugging Remove the import-mode parameter Add the region-properties command for tikv-ctl Fix the issue that reverse-seek is slow when many RocksDB tombstones exist Fix the crash issue caused by do_sub Make GC record the log when GC encounters many versions of data  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.4 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/204/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/204/</guid>
      <description> TiDB 2.0.4 Release Notes On June 15, 2018, TiDB 2.0.4 is released. Compared with TiDB 2.0.3, this release has great improvement in system compatibility and stability.
TiDB  Support the ALTER TABLE t DROP COLUMN a CASCADE syntax Support configuring the value of tidb_snapshot to TSO Refine the display of statement types in monitoring items Optimize the accuracy of query cost estimation Configure the backoff max delay parameter of gRPC Support configuring the memory threshold of a single statement in the configuration file Refactor the error of Optimizer Fix the side effects of the Cast Decimal data Fix the wrong result issue of the Merge Join operator in specific scenarios Fix the issue of converting the Null object to String Fix the issue of casting the JSON type of data to the JSON type Fix the issue that the result order is not consistent with MySQL in the condition of Union + OrderBy Fix the compliance rules issue when the Union statement checks the Limit/OrderBy clause Fix the compatibility issue of the Union All result Fix a bug in predicate pushdown Fix the compatibility issue of the Union statement with the For Update clause Fix the issue that the concat_ws function mistakenly truncates the result  PD  Improve the behavior of the unset scheduling argument max-pending-peer-count by changing it to no limit for the maximum number of PendingPeers  TiKV  Add the RocksDB PerfContext interface for debugging Remove the import-mode parameter Add the region-properties command for tikv-ctl Fix the issue that reverse-seek is slow when many RocksDB tombstones exist Fix the crash issue caused by do_sub Make GC record the log when GC encounters many versions of data  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/205/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/205/</guid>
      <description> TiDB 2.0.5 Release Notes On July 6, 2018, TiDB 2.0.5 is released. Compared with TiDB 2.0.4, this release has great improvement in system compatibility and stability.
TiDB  New Features  Add the tidb_disable_txn_auto_retry system variable which is used to disable the automatic retry of transactions #6877  Improvements  Optimize the cost calculation of Selection to make the result more accurate #6989 Select the query condition that completely matches the unique index or the primary key as the query path directly #6966 Execute necessary cleanup when failing to start the service #6964 Handle \N as NULL in the Load Data statement #6962 Optimize the code structure of CBO #6953 Report the monitoring metrics earlier when starting the service #6931 Optimize the format of slow queries by removing the line breaks in SQL statements and adding user information #6920 Support multiple asterisks in comments #6858  Bug Fixes  Fix the issue that KILL QUERY always requires SUPER privilege #7003 Fix the issue that users might fail to login when the number of users exceeds 1024 #6986 Fix an issue about inserting unsigned float/double data #6940 Fix the compatibility of the COM_FIELD_LIST command to resolve the panic issue in some MariaDB clients #6929 Fix the CREATE TABLE IF NOT EXISTS LIKE behavior #6928 Fix an issue in the process of TopN pushdown #6923 Fix the ID record issue of the currently processing row when an error occurs in executing Add Index #6903   PD  Fix the issue that replicas migration uses up TiKV disks space in some scenarios Fix the crash issue caused by AdjacentRegionScheduler  TiKV  Fix the potential overflow issue in decimal operations Fix the dirty read issue that might occur in the process of merging  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.5 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/205/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/205/</guid>
      <description> TiDB 2.0.5 Release Notes On July 6, 2018, TiDB 2.0.5 is released. Compared with TiDB 2.0.4, this release has great improvement in system compatibility and stability.
TiDB  New Features  Add the tidb_disable_txn_auto_retry system variable which is used to disable the automatic retry of transactions #6877  Improvements  Optimize the cost calculation of Selection to make the result more accurate #6989 Select the query condition that completely matches the unique index or the primary key as the query path directly #6966 Execute necessary cleanup when failing to start the service #6964 Handle \N as NULL in the Load Data statement #6962 Optimize the code structure of CBO #6953 Report the monitoring metrics earlier when starting the service #6931 Optimize the format of slow queries by removing the line breaks in SQL statements and adding user information #6920 Support multiple asterisks in comments #6858  Bug Fixes  Fix the issue that KILL QUERY always requires SUPER privilege #7003 Fix the issue that users might fail to login when the number of users exceeds 1024 #6986 Fix an issue about inserting unsigned float/double data #6940 Fix the compatibility of the COM_FIELD_LIST command to resolve the panic issue in some MariaDB clients #6929 Fix the CREATE TABLE IF NOT EXISTS LIKE behavior #6928 Fix an issue in the process of TopN pushdown #6923 Fix the ID record issue of the currently processing row when an error occurs in executing Add Index #6903   PD  Fix the issue that replicas migration uses up TiKV disks space in some scenarios Fix the crash issue caused by AdjacentRegionScheduler  TiKV  Fix the potential overflow issue in decimal operations Fix the dirty read issue that might occur in the process of merging  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.6 Release Notes</title>
      <link>https://pingcap.com/docs/releases/206/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/206/</guid>
      <description> TiDB 2.0.6 Release Notes On August 6, 2018, TiDB 2.0.6 is released. Compared with TiDB 2.0.5, this release has great improvement in system compatibility and stability.
TiDB  Improvements  Make &amp;ldquo;set system variable&amp;rdquo; log shorter to save disk space #7031 Record slow operations during the execution of ADD INDEX in the log, to make troubleshooting easier #7083 Reduce transaction conflicts when updating statistics #7138 Improve the accuracy of row count estimation when the values pending to be estimated exceeds the statistics range #7185 Choose the table with a smaller estimated row count as the outer table for Index Join to improve its execution efficiency #7277 Add the recover mechanism for panics occurred during the execution of ANALYZE TABLE, to avoid that the tidb-server is unavailable caused by abnormal behavior in the process of collecting statistics #7228 Return NULL and the corresponding warning when the results of RPAD/LPAD exceed the value of the max_allowed_packet system variable, compatible with MySQL #7244 Set the upper limit of placeholders count in the PREPARE statement to 65535, compatible with MySQL #7250  Bug Fixes  Fix the issue that the DROP USER statement is incompatible with MySQL behavior in some cases #7014 Fix the issue that statements like INSERT/LOAD DATA meet OOM aftering opening tidb_batch_insert #7092 Fix the issue that the statistics fail to automatically update when the data of a table keeps updating #7093 Fix the issue that the firewall breaks inactive gPRC connections #7099 Fix the issue that prefix index returns a wrong result in some scenarios #7126 Fix the panic issue caused by outdated statistics in some scenarios #7155 Fix the issue that one piece of index data is missed after the ADD INDEX operation in some scenarios #7156 Fix the wrong result issue when querying NULL values using the unique index in some scenarios #7172 Fix the messy code issue of the DECIMAL multiplication result in some scenarios #7212 Fix the wrong result issue of DECIMAL modulo operation in some scenarios #7245 Fix the issue that the UPDATE/DELETE statement in a transaction returns a wrong result under some special sequence of statements #7219 Fix the panic issue of the UNION ALL/UPDATE statement during the process of building the execution plan in some scenarios #7225 Fix the issue that the range of prefix index is calculated incorrectly in some scenarios #7231 Fix the issue that the LOAD DATA statement fails to write the binlog in some scenarios #7242 Fix the wrong result issue of SHOW CREATE TABLE during the execution process of ADD INDEX in some scenarios #7243 Fix the issue that panic occurs when Index Join does not initialize timestamps in some scenarios #7246 Fix the false alarm issue when ADMIN CHECK TABLE mistakenly uses the timezone in the session #7258 Fix the issue that ADMIN CLEANUP INDEX does not clean up the index in some scenarios #7265 Disable the Read Committed isolation level #7282   TiKV  Improvements  Enlarge scheduler&amp;rsquo;s default slots to reduce false conflicts Reduce continuous records of rollback transactions, to improve the Read performance when conflicts are extremely severe Limit the size and number of RocksDB log files, to reduce unnecessary disk usage in long-running condition  Bug Fixes  Fix the crash issue when converting the data type from string to decimal   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.6 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/206/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/206/</guid>
      <description> TiDB 2.0.6 Release Notes On August 6, 2018, TiDB 2.0.6 is released. Compared with TiDB 2.0.5, this release has great improvement in system compatibility and stability.
TiDB  Improvements  Make &amp;ldquo;set system variable&amp;rdquo; log shorter to save disk space #7031 Record slow operations during the execution of ADD INDEX in the log, to make troubleshooting easier #7083 Reduce transaction conflicts when updating statistics #7138 Improve the accuracy of row count estimation when the values pending to be estimated exceeds the statistics range #7185 Choose the table with a smaller estimated row count as the outer table for Index Join to improve its execution efficiency #7277 Add the recover mechanism for panics occurred during the execution of ANALYZE TABLE, to avoid that the tidb-server is unavailable caused by abnormal behavior in the process of collecting statistics #7228 Return NULL and the corresponding warning when the results of RPAD/LPAD exceed the value of the max_allowed_packet system variable, compatible with MySQL #7244 Set the upper limit of placeholders count in the PREPARE statement to 65535, compatible with MySQL #7250  Bug Fixes  Fix the issue that the DROP USER statement is incompatible with MySQL behavior in some cases #7014 Fix the issue that statements like INSERT/LOAD DATA meet OOM aftering opening tidb_batch_insert #7092 Fix the issue that the statistics fail to automatically update when the data of a table keeps updating #7093 Fix the issue that the firewall breaks inactive gPRC connections #7099 Fix the issue that prefix index returns a wrong result in some scenarios #7126 Fix the panic issue caused by outdated statistics in some scenarios #7155 Fix the issue that one piece of index data is missed after the ADD INDEX operation in some scenarios #7156 Fix the wrong result issue when querying NULL values using the unique index in some scenarios #7172 Fix the messy code issue of the DECIMAL multiplication result in some scenarios #7212 Fix the wrong result issue of DECIMAL modulo operation in some scenarios #7245 Fix the issue that the UPDATE/DELETE statement in a transaction returns a wrong result under some special sequence of statements #7219 Fix the panic issue of the UNION ALL/UPDATE statement during the process of building the execution plan in some scenarios #7225 Fix the issue that the range of prefix index is calculated incorrectly in some scenarios #7231 Fix the issue that the LOAD DATA statement fails to write the binlog in some scenarios #7242 Fix the wrong result issue of SHOW CREATE TABLE during the execution process of ADD INDEX in some scenarios #7243 Fix the issue that panic occurs when Index Join does not initialize timestamps in some scenarios #7246 Fix the false alarm issue when ADMIN CHECK TABLE mistakenly uses the timezone in the session #7258 Fix the issue that ADMIN CLEANUP INDEX does not clean up the index in some scenarios #7265 Disable the Read Committed isolation level #7282   TiKV  Improvements  Enlarge scheduler&amp;rsquo;s default slots to reduce false conflicts Reduce continuous records of rollback transactions, to improve the Read performance when conflicts are extremely severe Limit the size and number of RocksDB log files, to reduce unnecessary disk usage in long-running condition  Bug Fixes  Fix the crash issue when converting the data type from string to decimal   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.7 Release Notes</title>
      <link>https://pingcap.com/docs/releases/207/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/207/</guid>
      <description> TiDB 2.0.7 Release Notes On September 7, 2018, TiDB 2.0.7 is released. Compared with TiDB 2.0.6, this release has great improvement in system compatibility and stability.
TiDB  New Feature  Add the PROCESSLIST table in information_schema #7286  Improvement  Collect more details about SQL statement execution and output the information in the SLOW QUERY log #7364 Drop the partition information in SHOW CREATE TABLE #7388 Improve the execution efficiency of the ANALYZE statement by setting it to the RC isolation level and low priority #7500 Speed up adding a unique index #7562 Add an option of controlling the DDL concurrency #7563  Bug Fixes  Fix the issue that USE INDEX(PRIMARY) cannot be used in a table whose primary key is an integer #7298 Fix the issue that Merge Join and Index Join output incorrect results when the inner row is NULL #7301 Fix the issue that Join outputs an incorrect result when the chunk size is set too small #7315 Fix the panic issue caused by a statement of creating a table involving range column #7379 Fix the issue that admin check table mistakenly reports an error of a time-type column #7457 Fix the issue that the data with a default value current_timestamp cannot be queried using the = condition #7467 Fix the issue that the zero-length parameter inserted by using the ComStmtSendLongData command is mistakenly parsed to NULL #7508 Fix the issue that auto analyze is repeatedly executed in specific scenarios #7556 Fix the issue that the parser cannot parse a single line comment ended with a newline character #7635   TiKV  Improvement  Open the dynamic-level-bytes parameter in an empty cluster by default, to reduce space amplification  Bug Fix  Update approximate size and approximate keys count of a Region after Region merging   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.7 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/207/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/207/</guid>
      <description> TiDB 2.0.7 Release Notes On September 7, 2018, TiDB 2.0.7 is released. Compared with TiDB 2.0.6, this release has great improvement in system compatibility and stability.
TiDB  New Feature  Add the PROCESSLIST table in information_schema #7286  Improvement  Collect more details about SQL statement execution and output the information in the SLOW QUERY log #7364 Drop the partition information in SHOW CREATE TABLE #7388 Improve the execution efficiency of the ANALYZE statement by setting it to the RC isolation level and low priority #7500 Speed up adding a unique index #7562 Add an option of controlling the DDL concurrency #7563  Bug Fixes  Fix the issue that USE INDEX(PRIMARY) cannot be used in a table whose primary key is an integer #7298 Fix the issue that Merge Join and Index Join output incorrect results when the inner row is NULL #7301 Fix the issue that Join outputs an incorrect result when the chunk size is set too small #7315 Fix the panic issue caused by a statement of creating a table involving range column #7379 Fix the issue that admin check table mistakenly reports an error of a time-type column #7457 Fix the issue that the data with a default value current_timestamp cannot be queried using the = condition #7467 Fix the issue that the zero-length parameter inserted by using the ComStmtSendLongData command is mistakenly parsed to NULL #7508 Fix the issue that auto analyze is repeatedly executed in specific scenarios #7556 Fix the issue that the parser cannot parse a single line comment ended with a newline character #7635   TiKV  Improvement  Open the dynamic-level-bytes parameter in an empty cluster by default, to reduce space amplification  Bug Fix  Update approximate size and approximate keys count of a Region after Region merging   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.8 Release Notes</title>
      <link>https://pingcap.com/docs/releases/208/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/208/</guid>
      <description> TiDB 2.0.8 Release Notes On October 16, 2018, TiDB 2.0.8 is released. Compared with TiDB 2.0.7, this release has great improvement in system compatibility and stability.
TiDB  Improvement  Slow down the AUTO-ID increasing speed when the Update statement does not modify the corresponding AUTO-INCREMENT column #7846  Bug fixes  Quickly create a new etcd session to recover the service when the PD leader goes down #7810 Fix the issue that the time zone is not considered when the default value of the DateTime type is calculated #7672 Fix the issue that duplicate key update inserts values incorrectly in some conditions #7685 Fix the issue that the predicate conditions of UnionScan are not pushed down #7726 Fix the issue that the time zone is not correctly handled when you add the TIMESTAMP index #7812 Fix the memory leak issue caused by the statistics module in some conditions #7864 Fix the issue that the results of ANALYZE cannot be obtained in some abnormal conditions #7871 Do not fold the function SYSDATE, to ensure the returned results are correct #7894 Fix the substring_index panic issue in some conditions #7896 Fix the issue that OUTER JOIN is mistakenly converted to INNER JOIN in some conditions #7899   TiKV  Bug fix  Fix the issue that the memory consumed by Raftstore EntryCache keeps increasing when a node goes down #3529   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.8 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/208/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/208/</guid>
      <description> TiDB 2.0.8 Release Notes On October 16, 2018, TiDB 2.0.8 is released. Compared with TiDB 2.0.7, this release has great improvement in system compatibility and stability.
TiDB  Improvement  Slow down the AUTO-ID increasing speed when the Update statement does not modify the corresponding AUTO-INCREMENT column #7846  Bug fixes  Quickly create a new etcd session to recover the service when the PD leader goes down #7810 Fix the issue that the time zone is not considered when the default value of the DateTime type is calculated #7672 Fix the issue that duplicate key update inserts values incorrectly in some conditions #7685 Fix the issue that the predicate conditions of UnionScan are not pushed down #7726 Fix the issue that the time zone is not correctly handled when you add the TIMESTAMP index #7812 Fix the memory leak issue caused by the statistics module in some conditions #7864 Fix the issue that the results of ANALYZE cannot be obtained in some abnormal conditions #7871 Do not fold the function SYSDATE, to ensure the returned results are correct #7894 Fix the substring_index panic issue in some conditions #7896 Fix the issue that OUTER JOIN is mistakenly converted to INNER JOIN in some conditions #7899   TiKV  Bug fix  Fix the issue that the memory consumed by Raftstore EntryCache keeps increasing when a node goes down #3529   </description>
    </item>
    
    <item>
      <title>TiDB 2.0.9 Release Notes</title>
      <link>https://pingcap.com/docs/releases/209/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/209/</guid>
      <description> TiDB 2.0.9 Release Notes On November 19, 2018, TiDB 2.0.9 is released. Compared with TiDB 2.0.8, this release has great improvement in system compatibility and stability.
TiDB  Fix the issue caused by the empty statistics histogram #7927 Fix the panic issue of the UNION ALL statement in some cases #7942 Fix the stack overflow issue caused by wrong DDL Jobs #7959 Add the slow log for the Commit operation #7983 Fix the panic issue caused by the too large Limit value #8004 Support specifying the utf8mb4 character set in the USING clause #8048 Make the TRUNCATE built-in function support parameters of unsigned integer type #8069 Fix the selectivity estimation issue of the primary key for the statistics module in some cases #8150 Add the Session variable to control whether _tidb_rowid is allowed to be written in #8126 Fix the panic issue of PhysicalProjection in some cases #8154 Fix the unstable results of the Union statement in some cases #8168 Fix the issue that NULL is not returned by values in the non-Insert statement #8179 Fix the issue that the statistics module cannot clear the outdated data in some cases #8184 Make the maximum allowed running time for a transaction a configurable option 8209 Fix the wrong comparison algorithm of expression rewriter in some cases #8288 Eliminate the extra columns generated by the UNION ORDER BY statement #8307 Support the admin show next_row_id statement #8274 Fix the escape issue of special characters in the Show Create Table statement #8321 Fix the unexpected errors in the UNION statement in some cases #8318 Fix the issue that canceling a DDL job causes no rollback of a schema in some cases #8312 Change tidb_max_chunk_size to a global variable #8333 Add an upper bound to the Scan command of ticlient, to avoid overbound scan #8309 #8310  PD  Fix the issue that the PD server gets stuck caused by etcd startup failure #1267 Fix the issues related to pd-ctl reading the Region key #1298 #1299 #1308 Fix the issue that the regions/check API returns the wrong result #1311 Fix the issue that PD cannot restart join after a PD join failure #1279  TiKV  Add the end-key limit to the kv_scan interface #3749 Abandon the max-tasks-xxx configuration and add max-tasks-per-worker-xxx #3093 Fix the CompactFiles issue in RocksDB #3789  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.9 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/209/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/209/</guid>
      <description> TiDB 2.0.9 Release Notes On November 19, 2018, TiDB 2.0.9 is released. Compared with TiDB 2.0.8, this release has great improvement in system compatibility and stability.
TiDB  Fix the issue caused by the empty statistics histogram #7927 Fix the panic issue of the UNION ALL statement in some cases #7942 Fix the stack overflow issue caused by wrong DDL Jobs #7959 Add the slow log for the Commit operation #7983 Fix the panic issue caused by the too large Limit value #8004 Support specifying the utf8mb4 character set in the USING clause #8048 Make the TRUNCATE built-in function support parameters of unsigned integer type #8069 Fix the selectivity estimation issue of the primary key for the statistics module in some cases #8150 Add the Session variable to control whether _tidb_rowid is allowed to be written in #8126 Fix the panic issue of PhysicalProjection in some cases #8154 Fix the unstable results of the Union statement in some cases #8168 Fix the issue that NULL is not returned by values in the non-Insert statement #8179 Fix the issue that the statistics module cannot clear the outdated data in some cases #8184 Make the maximum allowed running time for a transaction a configurable option 8209 Fix the wrong comparison algorithm of expression rewriter in some cases #8288 Eliminate the extra columns generated by the UNION ORDER BY statement #8307 Support the admin show next_row_id statement #8274 Fix the escape issue of special characters in the Show Create Table statement #8321 Fix the unexpected errors in the UNION statement in some cases #8318 Fix the issue that canceling a DDL job causes no rollback of a schema in some cases #8312 Change tidb_max_chunk_size to a global variable #8333 Add an upper bound to the Scan command of ticlient, to avoid overbound scan #8309 #8310  PD  Fix the issue that the PD server gets stuck caused by etcd startup failure #1267 Fix the issues related to pd-ctl reading the Region key #1298 #1299 #1308 Fix the issue that the regions/check API returns the wrong result #1311 Fix the issue that PD cannot restart join after a PD join failure #1279  TiKV  Add the end-key limit to the kv_scan interface #3749 Abandon the max-tasks-xxx configuration and add max-tasks-per-worker-xxx #3093 Fix the CompactFiles issue in RocksDB #3789  </description>
    </item>
    
    <item>
      <title>TiDB 2.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs/releases/21beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21beta/</guid>
      <description>TiDB 2.1 Beta Release Notes On June 29, 2018, TiDB 2.1 Beta is released! Compared with TiDB 2.0, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Optimize the selection range of Index Join to improve the execution performance Optimize correlated subquery, push down Filter, and extend the index range, to improve the efficiency of some queries by orders of magnitude Support Index Hint and Join Hint in the UPDATE and DELETE statements Validate Hint TIDM_SMJ when no available index exists Support pushdown of the ABS, CEIL, FLOOR, IS TRUE, and IS FALSE functions Handle the IF and IFNULL functions especially in the constant folding process  SQL Execution Engine  Implement parallel Hash Aggregate operators and improve the computing performance of Hash Aggregate by 350% in some scenarios Implement parallel Project operators and improve the performance by 74% in some scenarios Read the data of the Inner table and Outer table of Hash Join concurrently to improve the execution performance Fix incorrect results of INSERT  ON DUPLICATE KEY UPDATE  in some scenarios Fix incorrect results of the CONCAT_WS, FLOOR, CEIL, and DIV built-in functions  Server  Add the HTTP API to scatter the distribution of table Regions in the TiKV cluster Add the auto_analyze_ratio system variable to control the threshold value of automatic Analyze Add the HTTP API to control whether to open the general log Add the HTTP API to modify the log level online Add the user information in the general log and the slow query log Support the server side cursor  Compatibility  Support more MySQL syntax Make the bit aggregate function support the ALL parameter Support the SHOW PRIVILEGES statement  DML  Decrease the memory usage of the INSERT INTO SELECT statement Fix the performance issue of PlanCache Add the tidb_retry_limit system variable to control the automatic retry times of transactions Add the tidb_disable_txn_auto_retry system variable to control whether the transaction tries automatically Fix the accuracy issue of the written data of the time type Support the queue of locally conflicted transactions to optimize the conflicted transaction performance Fix Affected Rows of the UPDATE statement Optimize the statement performance of insert ignore on duplicate key update  DDL  Optimize the execution speed of the CreateTable statement Optimize the execution speed of ADD INDEX and improve it greatly in some scenarios Fix the issue that the number of added columns by Alter table add column exceeds the limit of the number of table columns Fix the issue that DDL job retries lead to an increasing pressure on TiKV in abnormal conditions Fix the issue that TiDB continuously reloads the schema information in abnormal conditions Do not output the FOREIGN KEY related information in the result of SHOW CREATE TABLE Support the select tidb_is_ddl_owner() statement to facilitate judging whether TiDB is DDL Owner Fix the issue that the index is deleted in the Year type in some scenarios Fix the renaming table issue in the concurrent execution scenario Support the AlterTableForce syntax Support the AlterTableRenameIndex syntax with FromKey and ToKey Add the table name and database name in the output information of admin show ddl jobs   PD  Enable Raft PreVote between PD nodes to avoid leader reelection when network recovers after network isolation Optimize the issue that Balance Scheduler schedules small Regions frequently Optimize the hotspot scheduler to improve its adaptability in traffic statistics information jitters Skip the Regions with a large number of rows when scheduling region merge Enable raft learner by default to lower the risk of unavailable data caused by machine failure during scheduling Remove max-replica from pd-recover Add Filter metrics Fix the issue that Region information is not updated after tikv-ctl unsafe recovery Fix the issue that TiKV disk space is used up caused by replica migration in some scenarios Compatibility notes  Do not support rolling back to v2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/21beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/21beta/</guid>
      <description>TiDB 2.1 Beta Release Notes On June 29, 2018, TiDB 2.1 Beta is released! Compared with TiDB 2.0, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Optimize the selection range of Index Join to improve the execution performance Optimize correlated subquery, push down Filter, and extend the index range, to improve the efficiency of some queries by orders of magnitude Support Index Hint and Join Hint in the UPDATE and DELETE statements Validate Hint TIDM_SMJ when no available index exists Support pushdown of the ABS, CEIL, FLOOR, IS TRUE, and IS FALSE functions Handle the IF and IFNULL functions especially in the constant folding process  SQL Execution Engine  Implement parallel Hash Aggregate operators and improve the computing performance of Hash Aggregate by 350% in some scenarios Implement parallel Project operators and improve the performance by 74% in some scenarios Read the data of the Inner table and Outer table of Hash Join concurrently to improve the execution performance Fix incorrect results of INSERT  ON DUPLICATE KEY UPDATE  in some scenarios Fix incorrect results of the CONCAT_WS, FLOOR, CEIL, and DIV built-in functions  Server  Add the HTTP API to scatter the distribution of table Regions in the TiKV cluster Add the auto_analyze_ratio system variable to control the threshold value of automatic Analyze Add the HTTP API to control whether to open the general log Add the HTTP API to modify the log level online Add the user information in the general log and the slow query log Support the server side cursor  Compatibility  Support more MySQL syntax Make the bit aggregate function support the ALL parameter Support the SHOW PRIVILEGES statement  DML  Decrease the memory usage of the INSERT INTO SELECT statement Fix the performance issue of PlanCache Add the tidb_retry_limit system variable to control the automatic retry times of transactions Add the tidb_disable_txn_auto_retry system variable to control whether the transaction tries automatically Fix the accuracy issue of the written data of the time type Support the queue of locally conflicted transactions to optimize the conflicted transaction performance Fix Affected Rows of the UPDATE statement Optimize the statement performance of insert ignore on duplicate key update  DDL  Optimize the execution speed of the CreateTable statement Optimize the execution speed of ADD INDEX and improve it greatly in some scenarios Fix the issue that the number of added columns by Alter table add column exceeds the limit of the number of table columns Fix the issue that DDL job retries lead to an increasing pressure on TiKV in abnormal conditions Fix the issue that TiDB continuously reloads the schema information in abnormal conditions Do not output the FOREIGN KEY related information in the result of SHOW CREATE TABLE Support the select tidb_is_ddl_owner() statement to facilitate judging whether TiDB is DDL Owner Fix the issue that the index is deleted in the Year type in some scenarios Fix the renaming table issue in the concurrent execution scenario Support the AlterTableForce syntax Support the AlterTableRenameIndex syntax with FromKey and ToKey Add the table name and database name in the output information of admin show ddl jobs   PD  Enable Raft PreVote between PD nodes to avoid leader reelection when network recovers after network isolation Optimize the issue that Balance Scheduler schedules small Regions frequently Optimize the hotspot scheduler to improve its adaptability in traffic statistics information jitters Skip the Regions with a large number of rows when scheduling region merge Enable raft learner by default to lower the risk of unavailable data caused by machine failure during scheduling Remove max-replica from pd-recover Add Filter metrics Fix the issue that Region information is not updated after tikv-ctl unsafe recovery Fix the issue that TiKV disk space is used up caused by replica migration in some scenarios Compatibility notes  Do not support rolling back to v2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 GA Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1ga/</guid>
      <description>TiDB 2.1 GA Release Notes On November 30, 2018, TiDB 2.1 GA is released. See the following updates in this release. Compared with TiDB 2.0, this release has great improvements in stability, performance, compatibility, and usability.
TiDB  SQL Optimizer
 Optimize the selection range of Index Join to improve the execution performance
 Optimize the selection of outer table for Index Join and use the table with smaller estimated value of Row Count the as the outer table</description>
    </item>
    
    <item>
      <title>TiDB 2.1 GA Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2.1ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2.1ga/</guid>
      <description>TiDB 2.1 GA Release Notes On November 30, 2018, TiDB 2.1 GA is released. See the following updates in this release. Compared with TiDB 2.0, this release has great improvements in stability, performance, compatibility, and usability.
TiDB  SQL Optimizer
 Optimize the selection range of Index Join to improve the execution performance
 Optimize the selection of outer table for Index Join and use the table with smaller estimated value of Row Count the as the outer table</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc1/</guid>
      <description>TiDB 2.1 RC1 Release Notes On August 24, 2018, TiDB 2.1 RC1 is released! Compared with TiDB 2.1 Beta, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Fix the issue that a wrong result is returned after the correlated subquery is decorrelated in some cases #6972 Optimize the output result of Explain #7011#7041 Optimize the choosing strategy of the outer table for IndexJoin #7019 Remove the Plan Cache of the non-PREPARE statement #7040 Fix the issue that the INSERT statement is not parsed and executed correctly in some cases #7068 Fix the issue that the IndexJoin result is not correct in some cases #7150 Fix the issue that the NULL value cannot be found using the unique index in some cases #7163 Fix the range computing issue of the prefix index in UTF-8 #7194 Fix the issue that result is not correct caused by eliminating the Project operator in some cases #7257 Fix the issue that USE INDEX(PRIMARY) cannot be used when the primary key is an integer #7316 Fix the issue that the index range cannot be computed using the correlated column in some cases #7357  SQL Execution Engine  Fix the issue that the daylight saving time is not computed correctly in some cases #6823 Refactor the aggregation function framework to improve the execution efficiency of the Stream and Hash aggregation operators #6852 Fix the issue that the Hash aggregation operator cannot exit normally in some cases #6982 Fix the issue that BIT_AND/BIT_OR/BIT_XOR does not handle the non-integer data correctly #6994 Optimize the execution speed of the REPLACE INTO statement and increase the performance nearly 10 times #7027 Optimize the memory usage of time type data and decrease the memory usage of the time type data by fifty percent #7043 Fix the issue that the returned result is mixed with signed and unsigned integers in the UNION statement is not compatible with MySQL #7112 Fix the panic issue caused by the too much memory applied by LPAD/RPAD/TO_BASE64/FROM_BASE64/REPEAT #7171 #7266 #7409 #7431 Fix the incorrect result when MergeJoin/IndexJoin handles the NULL value #7255 Fix the incorrect result of Outer Join in some cases #7288 Improve the error message of Data Truncated to facilitate locating the wrong data and the corresponding field in the table #7401 Fix the incorrect result for decimal in some cases #7001 #7113 #7202 #7208 Optimize the point select performance #6937 Prohibit the isolation level of Read Committed to avoid the underlying problem #7211 Fix the incorrect result of LTRIM/RTRIM/TRIM in some cases #7291 Fix the issue that the MaxOneRow operator cannot guarantee that the returned result does not exceed one row #7375 Divide the Coprocessor requests with too many ranges #7454  Statistics  Optimize the mechanism of statistics dynamic collection #6796 Fix the issue that Auto Analyze does not work when data is updated frequently #7022 Decrease the Write conflicts during the statistics dynamic update process #7124 Optimize the cost estimation when the statistics is incorrect #7175 Optimize the AccessPath cost estimation strategy #7233  Server  Fix the bug in loading privilege information #6976 Fix the issue that the Kill command is too strict with privilege check #6954 Fix the issue of removing some binary numeric types #6922 Shorten the output log #7029 Handle the mismatchClusterID issue #7053 Add the advertise-address configuration item #7078 Add the GrpcKeepAlive option #7100 Add the connection or Token time monitor #7110 Optimize the data decoding performance #7149 Add the PROCESSLIST table in INFORMMATION_SCHEMA #7236 Fix the order issue when multiple rules are hit in verifying the privilege #7211 Change some default values of encoding related system variables to UTF-8 #7198 Make the slow query log show more detailed information #7302 Support registering tidb-server related information in PD and obtaining this information by HTTP API #7082  Compatibility  Support Session variables warning_count and error_count #6945 Add Scope check when reading the system variables #6958 Support the MAX_EXECUTION_TIME syntax #7012 Support more statements of the SET syntax #7020 Add validity check when setting system variables #7117 Add the verification of the number of PlaceHolders in the Prepare statement #7162 Support set character_set_results = null #7353 Support the flush status syntax #7369 Fix the column size of SET and ENUM types in information_schema #7347 Support the NATIONAL CHARACTER syntax of statements for creating a table #7378 Support the CHARACTER SET syntax in the LOAD DATA statement #7391 Fix the column information of the SET and ENUM types #7417 Support the IDENTIFIED WITH syntax in the CREATE USER statement #7402 Fix the precision losing issue during TIMESTAMP computing process #7418 Support the validity verification of more SYSTEM variables #7196 Fix the incorrect result when the CHAR_LENGTH function computes the binary string #7410 Fix the incorrect CONCAT result in a statement involving GROUP BY #7448 Fix the imprecise type length issue when casting the DECIMAL type to the STRING type #7451  DML  Fix the stability issue of the Load Data statement #6927 Fix the memory usage issue when performing some Batch operations #7086 Improve the performance of the Replace Into statement #7027 Fix the inconsistent precision issue when writing CURRENT_TIMESTAMP #7355  DDL  Improve the method of DDL judging whether Schema is synchronized to avoid misjudgement in some cases #7319 Fix the SHOW CREATE TABLE result in adding index process #6993 Allow the default value of text/blob/json to be NULL in non-restrict sql-mode #7230 Fix the ADD INDEX issue in some cases #7142 Increase the speed of adding UNIQUE-KEY index operation largely #7132 Fix the truncating issue of the prefix index in UTF-8 character set #7109 Add the environment variable tidb_ddl_reorg_priority to control the priority of the add-index operation #7116 Fix the display issue of AUTO-INCREMENT in information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC1 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/21rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/21rc1/</guid>
      <description>TiDB 2.1 RC1 Release Notes On August 24, 2018, TiDB 2.1 RC1 is released! Compared with TiDB 2.1 Beta, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Fix the issue that a wrong result is returned after the correlated subquery is decorrelated in some cases #6972 Optimize the output result of Explain #7011#7041 Optimize the choosing strategy of the outer table for IndexJoin #7019 Remove the Plan Cache of the non-PREPARE statement #7040 Fix the issue that the INSERT statement is not parsed and executed correctly in some cases #7068 Fix the issue that the IndexJoin result is not correct in some cases #7150 Fix the issue that the NULL value cannot be found using the unique index in some cases #7163 Fix the range computing issue of the prefix index in UTF-8 #7194 Fix the issue that result is not correct caused by eliminating the Project operator in some cases #7257 Fix the issue that USE INDEX(PRIMARY) cannot be used when the primary key is an integer #7316 Fix the issue that the index range cannot be computed using the correlated column in some cases #7357  SQL Execution Engine  Fix the issue that the daylight saving time is not computed correctly in some cases #6823 Refactor the aggregation function framework to improve the execution efficiency of the Stream and Hash aggregation operators #6852 Fix the issue that the Hash aggregation operator cannot exit normally in some cases #6982 Fix the issue that BIT_AND/BIT_OR/BIT_XOR does not handle the non-integer data correctly #6994 Optimize the execution speed of the REPLACE INTO statement and increase the performance nearly 10 times #7027 Optimize the memory usage of time type data and decrease the memory usage of the time type data by fifty percent #7043 Fix the issue that the returned result is mixed with signed and unsigned integers in the UNION statement is not compatible with MySQL #7112 Fix the panic issue caused by the too much memory applied by LPAD/RPAD/TO_BASE64/FROM_BASE64/REPEAT #7171 #7266 #7409 #7431 Fix the incorrect result when MergeJoin/IndexJoin handles the NULL value #7255 Fix the incorrect result of Outer Join in some cases #7288 Improve the error message of Data Truncated to facilitate locating the wrong data and the corresponding field in the table #7401 Fix the incorrect result for decimal in some cases #7001 #7113 #7202 #7208 Optimize the point select performance #6937 Prohibit the isolation level of Read Committed to avoid the underlying problem #7211 Fix the incorrect result of LTRIM/RTRIM/TRIM in some cases #7291 Fix the issue that the MaxOneRow operator cannot guarantee that the returned result does not exceed one row #7375 Divide the Coprocessor requests with too many ranges #7454  Statistics  Optimize the mechanism of statistics dynamic collection #6796 Fix the issue that Auto Analyze does not work when data is updated frequently #7022 Decrease the Write conflicts during the statistics dynamic update process #7124 Optimize the cost estimation when the statistics is incorrect #7175 Optimize the AccessPath cost estimation strategy #7233  Server  Fix the bug in loading privilege information #6976 Fix the issue that the Kill command is too strict with privilege check #6954 Fix the issue of removing some binary numeric types #6922 Shorten the output log #7029 Handle the mismatchClusterID issue #7053 Add the advertise-address configuration item #7078 Add the GrpcKeepAlive option #7100 Add the connection or Token time monitor #7110 Optimize the data decoding performance #7149 Add the PROCESSLIST table in INFORMMATION_SCHEMA #7236 Fix the order issue when multiple rules are hit in verifying the privilege #7211 Change some default values of encoding related system variables to UTF-8 #7198 Make the slow query log show more detailed information #7302 Support registering tidb-server related information in PD and obtaining this information by HTTP API #7082  Compatibility  Support Session variables warning_count and error_count #6945 Add Scope check when reading the system variables #6958 Support the MAX_EXECUTION_TIME syntax #7012 Support more statements of the SET syntax #7020 Add validity check when setting system variables #7117 Add the verification of the number of PlaceHolders in the Prepare statement #7162 Support set character_set_results = null #7353 Support the flush status syntax #7369 Fix the column size of SET and ENUM types in information_schema #7347 Support the NATIONAL CHARACTER syntax of statements for creating a table #7378 Support the CHARACTER SET syntax in the LOAD DATA statement #7391 Fix the column information of the SET and ENUM types #7417 Support the IDENTIFIED WITH syntax in the CREATE USER statement #7402 Fix the precision losing issue during TIMESTAMP computing process #7418 Support the validity verification of more SYSTEM variables #7196 Fix the incorrect result when the CHAR_LENGTH function computes the binary string #7410 Fix the incorrect CONCAT result in a statement involving GROUP BY #7448 Fix the imprecise type length issue when casting the DECIMAL type to the STRING type #7451  DML  Fix the stability issue of the Load Data statement #6927 Fix the memory usage issue when performing some Batch operations #7086 Improve the performance of the Replace Into statement #7027 Fix the inconsistent precision issue when writing CURRENT_TIMESTAMP #7355  DDL  Improve the method of DDL judging whether Schema is synchronized to avoid misjudgement in some cases #7319 Fix the SHOW CREATE TABLE result in adding index process #6993 Allow the default value of text/blob/json to be NULL in non-restrict sql-mode #7230 Fix the ADD INDEX issue in some cases #7142 Increase the speed of adding UNIQUE-KEY index operation largely #7132 Fix the truncating issue of the prefix index in UTF-8 character set #7109 Add the environment variable tidb_ddl_reorg_priority to control the priority of the add-index operation #7116 Fix the display issue of AUTO-INCREMENT in information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc2/</guid>
      <description>TiDB 2.1 RC2 Release Notes On September 14, 2018, TiDB 2.1 RC2 is released. Compared with TiDB 2.1 RC1, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Put forward a proposal of the next generation Planner #7543 Improve the optimization rules of constant propagation #7276 Enhance the computing logic of Range to enable it to handle multiple IN or EQUAL conditions simultaneously #7577 Fix the issue that the estimation result of TableScan is incorrect when Range is empty #7583 Support the PointGet operator for the UPDATE statement #7586 Fix the panic issue during the process of executing the FirstRow aggregate function in some conditions #7624  SQL Execution Engine  Fix the potential DataRace issue when the HashJoin operator encounters an error #7554 Make the HashJoin operator read the inner table and build the hash table simultaneously #7544 Optimize the performance of Hash aggregate operators #7541 Optimize the performance of Join operators #7493, #7433 Fix the issue that the result of UPDATE JOIN is incorrect when the Join order is changed #7571 Improve the performance of Chunks iterator #7585  Statistics  Fix the issue that the auto Analyze work repeatedly analyzes the statistics #7550 Fix the statistics update error that occurs when there is no statistics change #7530 Use the RC isolation level and low priority when building Analyze requests #7496 Support enabling statistics auto-analyze on certain period of a day #7570 Fix the panic issue when logging the statistics information #7588 Support configuring the number of buckets in the histogram using the ANALYZE TABLE WITH BUCKETS statement #7619 Fix the panic issue when updating an empty histogram #7640 Update information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC2 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/21rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/21rc2/</guid>
      <description>TiDB 2.1 RC2 Release Notes On September 14, 2018, TiDB 2.1 RC2 is released. Compared with TiDB 2.1 RC1, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Put forward a proposal of the next generation Planner #7543 Improve the optimization rules of constant propagation #7276 Enhance the computing logic of Range to enable it to handle multiple IN or EQUAL conditions simultaneously #7577 Fix the issue that the estimation result of TableScan is incorrect when Range is empty #7583 Support the PointGet operator for the UPDATE statement #7586 Fix the panic issue during the process of executing the FirstRow aggregate function in some conditions #7624  SQL Execution Engine  Fix the potential DataRace issue when the HashJoin operator encounters an error #7554 Make the HashJoin operator read the inner table and build the hash table simultaneously #7544 Optimize the performance of Hash aggregate operators #7541 Optimize the performance of Join operators #7493, #7433 Fix the issue that the result of UPDATE JOIN is incorrect when the Join order is changed #7571 Improve the performance of Chunks iterator #7585  Statistics  Fix the issue that the auto Analyze work repeatedly analyzes the statistics #7550 Fix the statistics update error that occurs when there is no statistics change #7530 Use the RC isolation level and low priority when building Analyze requests #7496 Support enabling statistics auto-analyze on certain period of a day #7570 Fix the panic issue when logging the statistics information #7588 Support configuring the number of buckets in the histogram using the ANALYZE TABLE WITH BUCKETS statement #7619 Fix the panic issue when updating an empty histogram #7640 Update information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc3/</guid>
      <description>TiDB 2.1 RC3 Release Notes On September 29, 2018, TiDB 2.1 RC3 is released. Compared with TiDB 2.1 RC2, this release has great improvement in stability, compatibility, SQL optimizer, and execution engine.
TiDB  SQL Optimizer  Fix the incorrect result issue when a statement contains embedded LEFT OUTER JOIN #7689 Enhance the optimization rule of predicate pushdown on the JOIN statement #7645 Fix the optimization rule of predicate pushdown for the UnionScan operator #7695 Fix the issue that the unique key property of the Union operator is not correctly set #7680 Enhance the optimization rule of constant folding #7696 Optimize the data source in which the filter is null after propagation to table dual #7756  SQL Execution Engine  Optimize the performance of read requests in a transaction #7717 Optimize the cost of allocating Chunk memory in some executors #7540 Fix the &amp;ldquo;index out of range&amp;rdquo; panic caused by the columns where point queries get all NULL values #7790  Server  Fix the issue that the memory quota in the configuration file does not take effect #7729 Add the tidb_force_priority system variable to set the execution priority for each statement #7694 Support using the admin show slow statement to obtain the slow query log #7785  Compatibility  Fix the issue that the result of charset/collation is incorrect in information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC3 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/21rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/21rc3/</guid>
      <description>TiDB 2.1 RC3 Release Notes On September 29, 2018, TiDB 2.1 RC3 is released. Compared with TiDB 2.1 RC2, this release has great improvement in stability, compatibility, SQL optimizer, and execution engine.
TiDB  SQL Optimizer  Fix the incorrect result issue when a statement contains embedded LEFT OUTER JOIN #7689 Enhance the optimization rule of predicate pushdown on the JOIN statement #7645 Fix the optimization rule of predicate pushdown for the UnionScan operator #7695 Fix the issue that the unique key property of the Union operator is not correctly set #7680 Enhance the optimization rule of constant folding #7696 Optimize the data source in which the filter is null after propagation to table dual #7756  SQL Execution Engine  Optimize the performance of read requests in a transaction #7717 Optimize the cost of allocating Chunk memory in some executors #7540 Fix the &amp;ldquo;index out of range&amp;rdquo; panic caused by the columns where point queries get all NULL values #7790  Server  Fix the issue that the memory quota in the configuration file does not take effect #7729 Add the tidb_force_priority system variable to set the execution priority for each statement #7694 Support using the admin show slow statement to obtain the slow query log #7785  Compatibility  Fix the issue that the result of charset/collation is incorrect in information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc4/</guid>
      <description>TiDB 2.1 RC4 Release Notes On October 23, 2018, TiDB 2.1 RC4 is released. Compared with TiDB 2.1 RC3, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Fix the issue that column pruning of UnionAll is incorrect in some cases #7941 Fix the issue that the result of the UnionAll operator is incorrect in some cases #8007  SQL Execution Engine  Fix the precision issue of the AVG function #7874 Support using the EXPLAIN ANALYZE statement to check the runtime statistics including the execution time and the number of returned rows of each operator during the query execution process #7925 Fix the panic issue of the PointGet operator when a column of a table appears multiple times in the result set #7943 Fix the panic issue caused by too large values in the Limit subclause #8002 Fix the panic issue during the execution process of the AddDate/SubDate statement in some cases #8009  Statistics  Fix the issue of judging the prefix of the histogram low-bound of the combined index as out of range #7856 Fix the memory leak issue caused by statistics collecting #7873 Fix the panic issue when the histogram is empty #7928 Fix the issue that the histogram bound is out of range when the statistics is being uploaded #7944 Limit the maximum length of values in the statistics sampling process #7982</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC4 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/21rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/21rc4/</guid>
      <description>TiDB 2.1 RC4 Release Notes On October 23, 2018, TiDB 2.1 RC4 is released. Compared with TiDB 2.1 RC3, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Fix the issue that column pruning of UnionAll is incorrect in some cases #7941 Fix the issue that the result of the UnionAll operator is incorrect in some cases #8007  SQL Execution Engine  Fix the precision issue of the AVG function #7874 Support using the EXPLAIN ANALYZE statement to check the runtime statistics including the execution time and the number of returned rows of each operator during the query execution process #7925 Fix the panic issue of the PointGet operator when a column of a table appears multiple times in the result set #7943 Fix the panic issue caused by too large values in the Limit subclause #8002 Fix the panic issue during the execution process of the AddDate/SubDate statement in some cases #8009  Statistics  Fix the issue of judging the prefix of the histogram low-bound of the combined index as out of range #7856 Fix the memory leak issue caused by statistics collecting #7873 Fix the panic issue when the histogram is empty #7928 Fix the issue that the histogram bound is out of range when the statistics is being uploaded #7944 Limit the maximum length of values in the statistics sampling process #7982</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/21rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/21rc5/</guid>
      <description>TiDB 2.1 RC5 Release Notes On November 12, 2018, TiDB 2.1 RC5 is released. Compared with TiDB 2.1 RC4, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Fix the issue that IndexReader reads the wrong handle in some cases #8132 Fix the issue occurred while the IndexScan Prepared statement uses Plan Cache #8055 Fix the issue that the result of the Union statement is unstable #8165  SQL Execution Engine  Improve the performance of TiDB on inserting or updating wide tables #8024 Support the unsigned int flag in the Truncate built-in function #8068 Fix the error occurred while converting JSON data to the decimal type #8109 Fix the error occurred when you Update the float type #8170  Statistics  Fix the incorrect statistics issue during point queries in some cases #8035 Fix the selectivity estimation of statistics for primary key in some cases #8149 Fix the issue that the statistics of deleted tables are not cleared up for a long period of time #8182  Server  Improve the readability of logs and make logs better  #8063 #8053 #8224  Fix the error occurred when obtaining the table data of infoschema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC5 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/21rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/21rc5/</guid>
      <description>TiDB 2.1 RC5 Release Notes On November 12, 2018, TiDB 2.1 RC5 is released. Compared with TiDB 2.1 RC4, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer  Fix the issue that IndexReader reads the wrong handle in some cases #8132 Fix the issue occurred while the IndexScan Prepared statement uses Plan Cache #8055 Fix the issue that the result of the Union statement is unstable #8165  SQL Execution Engine  Improve the performance of TiDB on inserting or updating wide tables #8024 Support the unsigned int flag in the Truncate built-in function #8068 Fix the error occurred while converting JSON data to the decimal type #8109 Fix the error occurred when you Update the float type #8170  Statistics  Fix the incorrect statistics issue during point queries in some cases #8035 Fix the selectivity estimation of statistics for primary key in some cases #8149 Fix the issue that the statistics of deleted tables are not cleared up for a long period of time #8182  Server  Improve the readability of logs and make logs better  #8063 #8053 #8224  Fix the error occurred when obtaining the table data of infoschema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 Upgrade Guide</title>
      <link>https://pingcap.com/docs/dev/how-to/upgrade/to-tidb-2.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/upgrade/to-tidb-2.1/</guid>
      <description>TiDB 2.1 Upgrade Guide This document describes how to upgrade from TiDB 2.0 (TiDB 2.0.1 or later) or TiDB 2.1 RC version to TiDB 2.1 GA version.
 Note:
TiDB 2.1 is not compatible with the Kafka version of TiDB-Binlog. If your current TiDB cluster has already been using the Kafka version of TiDB-Binlog, you need to upgrade it to the cluster version of TiDB-Binlog.
 For details about using Ansible to perform a rolling update to each component, see Perform a rolling update using Ansible.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 Upgrade Guide</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/tidb-v2.1-upgrade-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/tidb-v2.1-upgrade-guide/</guid>
      <description>TiDB 2.1 Upgrade Guide This document describes how to upgrade from TiDB 2.0 (TiDB 2.0.1 or later) or TiDB 2.1 RC version to TiDB 2.1 GA version.
 Note:
TiDB 2.1 is not compatible with the Kafka version of TiDB-Binlog. If your current TiDB cluster has already been using the Kafka version of TiDB-Binlog, you need to upgrade it to the cluster version of TiDB-Binlog.
 For details about using Ansible to perform a rolling update to each component, see Perform a rolling update using Ansible.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.1/</guid>
      <description> TiDB 2.1.1 Release Notes On December 12, 2018, TiDB 2.1.1 is released. Compared with TiDB 2.1.0, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer/Executor  Fix the round error of the negative date #8574 Fix the issue that the uncompress function does not check the data length #8606 Reset bind arguments of the prepare statement after the execute command is executed #8652 Support automatically collecting the statistics information of a partition table #8649 Fix the wrongly configured integer type when pushing down the abs function #8628 Fix the data race on the JSON column #8660  Server  Fix the issue that the transaction obtained TSO is incorrect when PD breaks down #8567 Fix the bootstrap failure caused by the statement that does not conform to ANSI standards #8576 Fix the issue that incorrect parameters are used in transaction retries #8638  DDL  Change the default character set and collation of tables into utf8mb4 #8590 Add the ddl_reorg_batch_size variable to control the speed of adding indexes #8614 Make the character set and collation options content in DDL case-insensitive #8611 Fix the issue of adding indexes for generated columns #8655   PD  Fix the issue that some configuration items cannot be set to 0 in the configuration file #1334 Check the undefined configuration when starting PD #1362 Avoid transferring the leader to a newly created peer, to optimize the possible delay #1339 Fix the issue that RaftCluster cannot stop caused by deadlock #1370  TiKV  Avoid transferring the leader to a newly created peer, to optimize the possible delay #3878  Tools  Lightning  Optimize the analyze mechanism on imported tables to increase the import speed Support storing the checkpoint information to a local file  TiDB-Binlog  Fix the output bug of pb files that a table only with the primary key column cannot generate the pb event   </description>
    </item>
    
    <item>
      <title>TiDB 2.1.1 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2.1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2.1.1/</guid>
      <description> TiDB 2.1.1 Release Notes On December 12, 2018, TiDB 2.1.1 is released. Compared with TiDB 2.1.0, this release has great improvement in stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer/Executor  Fix the round error of the negative date #8574 Fix the issue that the uncompress function does not check the data length #8606 Reset bind arguments of the prepare statement after the execute command is executed #8652 Support automatically collecting the statistics information of a partition table #8649 Fix the wrongly configured integer type when pushing down the abs function #8628 Fix the data race on the JSON column #8660  Server  Fix the issue that the transaction obtained TSO is incorrect when PD breaks down #8567 Fix the bootstrap failure caused by the statement that does not conform to ANSI standards #8576 Fix the issue that incorrect parameters are used in transaction retries #8638  DDL  Change the default character set and collation of tables into utf8mb4 #8590 Add the ddl_reorg_batch_size variable to control the speed of adding indexes #8614 Make the character set and collation options content in DDL case-insensitive #8611 Fix the issue of adding indexes for generated columns #8655   PD  Fix the issue that some configuration items cannot be set to 0 in the configuration file #1334 Check the undefined configuration when starting PD #1362 Avoid transferring the leader to a newly created peer, to optimize the possible delay #1339 Fix the issue that RaftCluster cannot stop caused by deadlock #1370  TiKV  Avoid transferring the leader to a newly created peer, to optimize the possible delay #3878  Tools  Lightning  Optimize the analyze mechanism on imported tables to increase the import speed Support storing the checkpoint information to a local file  TiDB-Binlog  Fix the output bug of pb files that a table only with the primary key column cannot generate the pb event   </description>
    </item>
    
    <item>
      <title>TiDB 2.1.10 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.10/</guid>
      <description> TiDB 2.1.10 Release Notes Release date: May 22, 2019
TiDB version: 2.1.10
TiDB Ansible version: 2.1.10
TiDB  Fix the issue that some abnormalities cause incorrect table schema when using tidb_snapshot to read the history data #10359 Fix the issue that the NOT function causes wrong read results in some cases #10363 Fix the wrong behavior of Generated Column in the Replace or Insert on duplicate update statement #10385 Fix a bug of the BETWEEN function in the DATE/DATETIME comparison #10407 Fix the issue that a single line of a slow log that is too long causes an error report when using the SLOW_QUERY table to query a slow log #10412 Fix the issue that the result of DATETIME plus INTERVAL is not the same with that of MySQL in some cases #10416, #10418 Add the check for the invalid time of February in a leap year #10417 Execute the internal initialization operation limitation only in the DDL owner to avoid a large number of conflict error reports when initializing the cluster #10426 Fix the issue that DESC is incompatible with MySQL when the default value of the output timestamp column is default current_timestamp on update current_timestamp #10337 Fix the issue that an error occurs during the privilege check in the Update statement #10439 Fix the issue that wrong calculation of RANGE causes a wrong result in the CHAR column in some cases #10455 Fix the issue that the data might be overwritten after decreasing SHARD_ROW_ID_BITS #9868 Fix the issue that ORDER BY RAND() does not return random numbers #10064 Prohibit the ALTER statement modifying the precision of decimals #10458 Fix the compatibility issue of the TIME_FORMAT function with MySQL #10474 Check the parameter validity of PERIOD_ADD #10430 Fix the issue that the behavior of the invalid YEAR string in TiDB is incompatible with that in MySQL #10493 Support the ALTER DATABASE syntax #10503 Fix the issue that the SLOW_QUERY memory engine reports an error when no ; exists in the slow query statement #10536 Fix the issue that the Add index operation in partitioned tables cannot be canceled in some cases #10533 Fix the issue that the OOM panic cannot be recovered in some cases #10545 Improve the security of the DDL operation rewriting the table metadata #10547  PD  Fix the issue that the priority of the leader does not take effect #1533  TiKV  Reject transferring the leader in a Region whose configuration has been changed recently to avoid transfer failure #4684 Add the priority label for Coprocessor metrics #4643 Fix the possible dirty read issue during transferring the leader #4724 Fix the issue that CommitMerge causes the restart failure of TiKV in some cases #4615 Fix unknown logs #4730  Tools  TiDB Lightning  Add the retry feature when TiDB Lightning fails to send data to importer #176  TiDB Binlog  Optimize the Pump storage log to facilitate troubleshooting #607   TiDB Ansible  Update the configuration file of TiDB Lightning and add the tidb_lightning_ctl script #d3a4a368  </description>
    </item>
    
    <item>
      <title>TiDB 2.1.2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.2/</guid>
      <description>TiDB 2.1.2 Release Notes On December 22, 2018, TiDB 2.1.2 is released. The corresponding TiDB-Ansible 2.1.2 is also released. Compared with TiDB 2.1.1, this release has great improvement in system compatibility and stability.
TiDB  Make TiDB compatible with TiDB-Binlog of the Kafka version #8747 Improve the exit mechanism of TiDB in a rolling update #8707 Fix the panic issue caused by adding the index for the generated column in some cases #8676 Fix the issue that the optimizer cannot find the optimal query plan when TIDB_SMJ Hint exists in the SQL statement in some cases #8729 Fix the issue that AntiSemiJoin returns an incorrect result in some cases #8730 Improve the valid character check of the utf8 character set #8754 Fix the issue that the field of the time type might return an incorrect result when the write operation is performed before the read operation in a transaction #8746  PD  Fix the Region information update issue about Region merge #1377  TiKV  Support the configuration format in the unit of DAY (d) and fix the configuration compatibility issue #3931 Fix the possible panic issue caused by Approximate Size Split #3942 Fix two issues about Region merge #3822, #3873  Tools  TiDB-Lightning  Make TiDB 2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.2 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/2.1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/2.1.2/</guid>
      <description>TiDB 2.1.2 Release Notes On December 22, 2018, TiDB 2.1.2 is released. The corresponding TiDB-Ansible 2.1.2 is also released. Compared with TiDB 2.1.1, this release has great improvement in system compatibility and stability.
TiDB  Make TiDB compatible with TiDB-Binlog of the Kafka version #8747 Improve the exit mechanism of TiDB in a rolling update #8707 Fix the panic issue caused by adding the index for the generated column in some cases #8676 Fix the issue that the optimizer cannot find the optimal query plan when TIDB_SMJ Hint exists in the SQL statement in some cases #8729 Fix the issue that AntiSemiJoin returns an incorrect result in some cases #8730 Improve the valid character check of the utf8 character set #8754 Fix the issue that the field of the time type might return an incorrect result when the write operation is performed before the read operation in a transaction #8746  PD  Fix the Region information update issue about Region merge #1377  TiKV  Support the configuration format in the unit of DAY (d) and fix the configuration compatibility issue #3931 Fix the possible panic issue caused by Approximate Size Split #3942 Fix two issues about Region merge #3822, #3873  Tools  TiDB-Lightning  Make TiDB 2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.3/</guid>
      <description> TiDB 2.1.3 Release Notes On January 28, 2019, TiDB 2.1.3 is released. The corresponding TiDB-Ansible 2.1.3 is also released. Compared with TiDB 2.1.2, this release has great improvement in system stability, SQL optimizer, statistics information, and execution engine.
TiDB  SQL Optimizer/Executor  Fix the panic issue of Prepared Plan Cache in some cases #8826 Fix the issue that Range computing is wrong when the index is a prefix index #8851 Make CAST(str AS TIME(N)) return null if the string is in the illegal TIME format when SQL_MODE is not strict #8966 Fix the panic issue of Generated Column during the process of UPDATE in some cases #8980 Fix the upper bound overflow issue of the statistics histogram in some cases #8989 Support Range for _tidb_rowid construction queries, to avoid full table scan and reduce cluster stress #9059 Return an error when the CAST(AS TIME) precision is too big #9058 Allow using Sort Merge Join in the Cartesian product #9037 Fix the issue that the statistics worker cannot resume after the panic in some cases #9085 Fix the issue that Sort Merge Join returns the wrong result in some cases #9046 Support returning the JSON type in the CASE clause #8355  Server  Return a warning instead of an error when the non-TiDB hint exists in the comment #8766 Verify the validity of the configured TIMEZONE value #8879 Optimize the QueryDurationHistogram metrics item to display more statement types #8875 Fix the lower bound overflow issue of bigint in some cases #8544 Support the ALLOW_INVALID_DATES SQL mode #9110  DDL  Fix a RENAME TABLE compatibility issue to keep the behavior consistent with that of MySQL #8808 Support making concurrent changes of ADD INDEX take effect immediately #8786 Fix the UPDATE panic issue during the process of ADD COLUMN in some cases #8906 Fix the issue of concurrently creating Table Partition in some cases #8902 Support converting the utf8 character set to utf8mb4 #8951 #9152 Fix the issue of Shard Bits overflow #8976 Support outputting the column character sets in SHOW CREATE TABLE #9053 Fix the issue of the maximum length limit of the varchar type column in utf8mb4 #8818 Support ALTER TABLE TRUNCATE TABLE PARTITION #9093 Resolve the charset when the charset is not provided #9147   PD  Fix the Watch issue related to leader election #1396  TiKV  Support obtaining the monitoring information using the HTTP method #3855 Fix the NULL issue of data_format #4075 Add verifying the range for scan requests #4124  Tools  TiDB-Binlog  Fix the no available pump issue while TiDB is started or restarted #157 Enable outputting the Pump client log #165 Fix the data inconsistency issue caused by the unique key containing the NULL value when the table only has the unique key and does not have the primary key   </description>
    </item>
    
    <item>
      <title>TiDB 2.1.4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.4/</guid>
      <description>TiDB 2.1.4 Release Notes On February 15, 2019, TiDB 2.1.4 is released. The corresponding TiDB-Ansible 2.1.4 is also released. Compared with TiDB 2.1.3, this release has greatly improved the stability, the SQL optimizer, statistics, and the execution engine.
TiDB  SQL Optimizer/Executor  Fix the issue that the VALUES function does not handle the FLOAT type correctly #9223 Fix the wrong result issue when casting Float to String in some cases #9227 Fix the wrong result issue of the FORMAT function in some cases #9235 Fix the panic issue when handling the Join query in some cases #9264 Fix the issue that the VALUES function does not handle the ENUM type correctly #9280 Fix the wrong result issue of DATE_ADD/DATE_SUB in some cases #9284  Server  Optimize the reload privilege success log and change it to the DEBUG level #9274  DDL  Change tidb_ddl_reorg_worker_cnt and tidb_ddl_reorg_batch_size to global variables #9134 Fix the bug caused by adding an index to a generated column in some abnormal conditions #9289   TiKV  Fix the duplicate write issue when closing TiKV #4146 Fix the abnormal result issue of the event listener in some cases #4132  Tools  Lightning  Optimize the memory usage #107, #108 Remove the chunk separation of dump files to avoid an extra parsing of dump files #109 Limit the I/O concurrency of reading dump files, to avoid performance degradation caused by too many cache misses #110 Support importing data in batches for a single table, to improve import stability #110 Enable auto compactions in the import mode in TiKV #4199 Support disabling the TiKV periodic Level-1 compaction parameter, because the Level-1 compaction is automatically executed in the import mode when the TiKV cluster version is 2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.5/</guid>
      <description>TiDB 2.1.5 Release Notes On February 28, 2019, TiDB 2.1.5 is released. The corresponding TiDB-Ansible 2.1.5 is also released. Compared with TiDB 2.1.4, this release has greatly improved the stability, the SQL optimizer, statistics, and the execution engine.
TiDB  SQL Optimizer/Executor  Make SHOW CREATE TABLE do not print the column charset information when the charset information of a column is the same with that of a table, to improve the compatibility of SHOW CREATE TABLE with MySQL #9306 Fix the panic or the wrong result of the Sort operator in some cases by extracting ScalarFunc from Sort to a Projection operator for computing to simplify the computing logic of Sort #9319 Remove the sorting field with constant values in the Sort operator #9335, #9440 Fix the data overflow issue when inserting data into an unsigned integer column #9339 Set cast_as_binary to NULL when the length of the target binary exceeds max_allowed_packet #9349 Optimize the constant folding process of IF and IFNULL #9351 Optimize the index selection of TiDB using skyline pruning to improve the stability of simple queries #9356 Support computing the selectivity of the DNF expression #9405 Fix the wrong SQL query result of !</description>
    </item>
    
    <item>
      <title>TiDB 2.1.6 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.6/</guid>
      <description>TiDB 2.1.6 Release Notes On March 15, 2019, TiDB 2.1.6 is released. The corresponding TiDB-Ansible 2.1.6 is also released. Compared with TiDB 2.1.5, this release has greatly improved the stability, the SQL optimizer, statistics, and the execution engine.
TiDB  SQL Optimizer/Executor
 Optimize planner to select the outer table based on cost when both tables are specified in Hint of TIDB_INLJ #9615 Fix the issue that IndexScan cannot be selected correctly in some cases #9587 Fix incompatibility with MySQL of check in the agg function in subqueries #9551 Make show stats_histograms only output valid columns to avoid panics #9502  Server</description>
    </item>
    
    <item>
      <title>TiDB 2.1.7 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.7/</guid>
      <description>TiDB 2.1.7 Release Notes Release Date: March 28, 2019
TiDB version: 2.1.7
TiDB-Ansible version: 2.1.7
TiDB  Fix the issue of longer startup time when upgrading the program caused by canceling DDL operations #9768 Fix the issue that the check-mb4-value-in-utf8 configuration item is in the wrong position in the config.example.toml file #9852 Improve the compatibility of the str_to_date built-in function with MySQL #9817 Fix the compatibility issue of the last_day built-in function #9750 Add the tidb_table_id column for infoschema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.8 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.8/</guid>
      <description>TiDB 2.1.8 Release Notes Release date: April 12, 2019
TiDB version: 2.1.8
TiDB-Ansible version: 2.1.8
TiDB  Fix the issue that the processing logic of GROUP_CONCAT function is incompatible with MySQL when there is a NULL-valued parameter #9930 Fix the equality check issue of decimal values in the Distinct mode #9931 Fix the collation compatibility issue of the date, datetime, and timestamp types for the SHOW FULL COLUMNS statement  #9938 #10114  Fix the issue that the row count estimation is inaccurate when the filtering condition contains correlated columns #9937 Fix the compatibility issue between the DATE_ADD and DATE_SUB functions  #9963 #9966  Support the %H format for the STR_TO_DATE function to improve compatibility #9964 Fix the issue that the result is wrong when the GROUP_CONCAT function groups by a unique index #9969 Return a warning when the Optimizer Hints contains an unmatched table name #9970 Unify the log format to facilitate collecting logs using tools for analysis Unified Log Format Fix the issue that a lot of NULL values cause inaccurate statistics estimation #9979 Fix the issue that an error is reported when the default value of the TIMESTAMP type is the boundary value #9987 Validate the value of time_zone #10000</description>
    </item>
    
    <item>
      <title>TiDB 2.1.9 Release Notes</title>
      <link>https://pingcap.com/docs/releases/2.1.9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/2.1.9/</guid>
      <description>TiDB 2.1.9 Release Notes Release date: May 6, 2019
TiDB version: 2.1.9
TiDB-Ansible version: 2.1.9
TiDB  Fix compatibility of the MAKETIME function when unsigned type overflows #10089 Fix the stack overflow caused by constant folding in some cases #10189 Fix the privilege check issue for Update when an alias exists in some cases #10157, #10326 Track and control memory usage in DistSQL #10197 Support specifying collation as utf8mb4_0900_ai_ci #10201 Fix the wrong result issue of the MAX function when the primary key is of the Unsigned type #10209 Fix the issue that NULL values can be inserted into NOT NULL columns in the non-strict SQL mode #10254 Fix the wrong result issue of the COUNT function when multiple columns exist in DISTINCT #10270 Fix the panic issue occurred when LOAD DATA parses irregular CSV files #10269 Ignore the overflow error when the outer and inner join key types are inconsistent in Index Lookup Join #10244 Fix the issue that a statement is wrongly judged as point-get in some cases #10299 Fix the wrong result issue when the time type does not convert the time zone in some cases #10345 Fix the issue that TiDB character set cases are inconsistent in some cases #10354 Support controlling the number of rows returned by operator #9166  Selection &amp;amp; Projection #10110 StreamAgg &amp;amp; HashAgg #10133 TableReader &amp;amp; IndexReader &amp;amp; IndexLookup #10169  Improve the slow query log  Add SQL Digest to distinguish similar SQL #10093 Add version information of statistics used by slow query statements #10220 Show memory consumption of a statement in slow query log #10246 Adjust the output format of Coprocessor related information so it can be parsed by pt-query-digest #10300 Fix the # character issue in slow query statements #10275 Add some information columns to the memory table of slow query statements #10317 Add the transaction commit time to slow query log #10310 Fix the issue some time formats cannot be parsed by pt-query-digest #10323   PD  Support the GetOperator service #1514  TiKV  Fix potential quorum changes when transferring leader #4604  Tools  TiDB Binlog  Fix the issue that data replication is interrupted because data in the unsigned int type of primary key column are minus numbers #574 Remove the compression option when the downstream is pb and change the downstream name from pb to file #597 Fix the bug that Reparo introduced in 2.</description>
    </item>
    
    <item>
      <title>TiDB 3.0 Beta Release Notes</title>
      <link>https://pingcap.com/docs/releases/3.0beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/3.0beta/</guid>
      <description>TiDB 3.0 Beta Release Notes On January 19, 2019, TiDB 3.0 Beta is released. The corresponding TiDB-Ansible 3.0 Beta is also released. TiDB 3.0 Beta builds on TiDB 2.1 with an added focus in stability, the SQL optimizer, statistics, and the execution engine.
TiDB  New Features  Support Views Support Window Functions Support Range Partitioning Support Hash Partitioning  SQL Optimizer  Re-support the optimization rule of AggregationElimination #7676 Optimize the NOT EXISTS subquery and convert it to Anti Semi Join #7842 Add the tidb_enable_cascades_planner variable to support the new Cascades optimizer.</description>
    </item>
    
    <item>
      <title>TiDB 3.0 Upgrade Guide</title>
      <link>https://pingcap.com/docs/dev/how-to/upgrade/from-previous-version/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/upgrade/from-previous-version/</guid>
      <description>TiDB 3.0 Upgrade Guide This document is targeted for users who want to upgrade from TiDB 2.0 (above V2.0.1) or TiDB 2.1 RC to TiDB 3.0. TiDB 3.0 is compatible with TiDB Binlog of Kafka Version and TiDB Binlog of Cluster Version.
Upgrade caveat  Rolling back to 2.1.x or earlier versions after upgrading is not supported Before upgrading to 3.0 from 2.0.6 or earlier versions, verify if there are any runing DDL operations, especially time-consuming ones like Add Index.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.0 Beta.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/3.0.0-beta.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/3.0.0-beta.1/</guid>
      <description>TiDB 3.0.0 Beta.1 Release Notes Release Date: March 26, 2019
TiDB version: 3.0.0-beta.1
TiDB-Ansible version: 3.0.0-beta.1
Overview On March 26, 2019, TiDB 3.0.0 Beta.1 is released. The corresponding TiDB-Ansible version is 3.0.0 Beta.1. Compared with TiDB 3.0.0 Beta, this release has greatly improved the stability, usability, features, the SQL optimizer, statistics, and the execution engine.
TiDB  SQL Optimizer  Support calculating the Cartesian product by using Sort Merge Join #9032 Support Skyline Pruning, with some rules to prevent the execution plan from relying too heavily on statistics #9337 Support Window Functions  NTILE #9682 LEAD and LAG #9672 PERCENT_RANK #9671 NTH_VALUE #9596 CUME_DIST #9619 FIRST_VALUE and LAST_VALUE #9560 RANK and DENSE_RANK #9500 RANGE FRAMED #9450 ROW FRAMED #9358 ROW NUMBER #9098  Add a type of statistic that indicates the order correlation between columns and the handle column #9315  SQL Execution Engine  Add built-in functions  JSON_QUOTE #7832 JSON_ARRAY_APPEND #9609 JSON_MERGE_PRESERVE #8931 BENCHMARK #9252 COALESCE #9087 NAME_CONST #9261  Optimize the Chunk size based on the query context, to reduce the execution time of SQL statements and resources consumption of the cluster #6489  Privilege management  Support SET ROLE and CURRENT_ROLE #9581 Support DROP ROLE #9616 Support CREATE ROLE #9461  Server  Add the /debug/zip HTTP interface to get information of the current TiDB instance #9651 Support the show pump status and show drainer status SQL statements to check the Pump or Drainer status 9456 Support modifying the Pump or Drainer status by using SQL statements #9789 Support adding HASH fingerprints to SQL text for easy tracking of slow SQL statements #9662 Add the log_bin system variable (&amp;ldquo;0&amp;rdquo; by default) to control the enabling state of binlog; only support checking the state currently #9343 Support managing the sending binlog strategy by using the configuration file #9864 Support querying the slow log by using the INFORMATION_SCHEMA.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.0-rc.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/3.0.0-rc.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/3.0.0-rc.1/</guid>
      <description>TiDB 3.0.0-rc.1 Release Notes Release Date: May 10, 2019
TiDB version: 3.0.0-rc.1
TiDB-Ansible version: 3.0.0-rc.1
Overview On May 10, 2019, TiDB 3.0.0-rc.1 is released. The corresponding TiDB-Ansible version is 3.0.0-rc.1. Compared with TiDB 3.0.0-beta.1, this release has greatly improved the stability, usability, features, the SQL optimizer, statistics, and the execution engine.
TiDB  SQL Optimizer
 Improve the accuracy of cost estimates by using order correlation between columns; introduce a heuristic parameter tidb_opt_correlation_exp_factor to control the preference for index scans for scenarios when correlation cannot be directly used for estimation.</description>
    </item>
    
    <item>
      <title>TiDB Adopters</title>
      <link>https://pingcap.com/docs/adopters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/adopters/</guid>
      <description>TiDB Adopters This is a list of TiDB adopters in various industries.
   Company Industry Success Story     Mobike Ridesharing English; Chinese   Jinri Toutiao Mobile News Platform Chinese   Yiguo.com E-commerce English; Chinese   Shopee E-commerce English; Chinese   Yuanfudao.com EdTech English; Chinese   Xiaomi Consumer Electronics Chinese   LY.com Travel Chinese   Qunar.com Travel Chinese   Hulu Entertainment    VIPKID EdTech    Lenovo Enterprise Technology    Bank of Beijing Banking Chinese   Industrial and Commercial Bank of China Banking    iQiyi Media and Entertainment English; Chinese   BookMyShow Media and Entertainment English   Yimian Data Big Data Chinese   CAASDATA Big Data Chinese   Phoenix New Media Media Chinese   Mobikok AdTech Chinese   LinkDoc Technology HealthTech Chinese   G7 Networks Logistics Chinese   Hive-Box Logistics Chinese   360 Finance FinTech Chinese   GAEA Gaming English; Chinese   YOOZOO Games Gaming Chinese   Seasun Games Gaming Chinese   NetEase Games Gaming    FUNYOURS JAPAN Gaming Chinese   Zhaopin.</description>
    </item>
    
    <item>
      <title>TiDB Adopters</title>
      <link>https://pingcap.com/docs/v2.1/adopters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/adopters/</guid>
      <description>TiDB Adopters This is a list of TiDB adopters in various industries.
   Company Industry Success Story     Mobike Ridesharing English; Chinese   Jinri Toutiao Mobile News Platform Chinese   Yiguo.com E-commerce English; Chinese   Yuanfudao.com EdTech English; Chinese   Ele.me Food Delivery English; Chinese-1; Chinese-2   Xiaomi Consumer Electronics Chinese   LY.com Travel Chinese   Qunar.com Travel Chinese   Hulu Entertainment    VIPKID EdTech    Lenovo Enterprise Technology    Bank of Beijing Banking Chinese   Industrial and Commercial Bank of China Banking    iQiyi Media and Entertainment English; Chinese   Yimian Data Big Data Chinese   CAASDATA Big Data Chinese   Phoenix New Media Media Chinese   Mobikok AdTech Chinese   LinkDoc Technology HealthTech Chinese   G7 Networks Logistics Chinese   Hive-Box Logistics Chinese   360 Finance FinTech Chinese   GAEA Gaming English; Chinese   YOOZOO Games Gaming Chinese   Seasun Games Gaming Chinese   NetEase Games Gaming    FUNYOURS JAPAN Gaming Chinese   Zhaopin.</description>
    </item>
    
    <item>
      <title>TiDB Architecture</title>
      <link>https://pingcap.com/docs/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/architecture/</guid>
      <description>TiDB Architecture The TiDB platform is comprised of three key components: the TiDB server, the PD server, and the TiKV server. In addition, TiDB also provides the TiSpark component for complex OLAP requirements.
TiDB server The TiDB server is in charge of the following operations:
 Receiving the SQL requests
 Processing the SQL related logics
 Locating the TiKV address for storing and computing data through Placement Driver (PD)</description>
    </item>
    
    <item>
      <title>TiDB Architecture</title>
      <link>https://pingcap.com/docs/v2.1/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/architecture/</guid>
      <description>TiDB Architecture The TiDB platform is comprised of three key components: the TiDB server, the PD server, and the TiKV server. In addition, TiDB also provides the TiSpark component for complex OLAP requirements.
TiDB server The TiDB server is in charge of the following operations:
 Receiving the SQL requests
 Processing the SQL related logics
 Locating the TiKV address for storing and computing data through Placement Driver (PD)</description>
    </item>
    
    <item>
      <title>TiDB Cluster Troubleshooting Guide</title>
      <link>https://pingcap.com/docs/dev/how-to/troubleshoot/cluster-setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/troubleshoot/cluster-setup/</guid>
      <description>TiDB Cluster Troubleshooting Guide You can use this guide to help you diagnose and solve basic problems while using TiDB. If your problem is not resolved, please collect the following information and create an issue:
 The exact error message and the operations while the error occurs The state of all the components The error/fatal/panic information in the log of the component that reports the error The configuration and deployment topology The TiDB component related issue in dmesg  For other information, see Frequently Asked Questions (FAQ).</description>
    </item>
    
    <item>
      <title>TiDB Cluster Troubleshooting Guide</title>
      <link>https://pingcap.com/docs/v2.1/trouble-shooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/trouble-shooting/</guid>
      <description>TiDB Cluster Troubleshooting Guide You can use this guide to help you diagnose and solve basic problems while using TiDB. If your problem is not resolved, please collect the following information and create an issue:
 The exact error message and the operations while the error occurs The state of all the components The error/fatal/panic information in the log of the component that reports the error The configuration and deployment topology The TiDB component related issue in dmesg  For other information, see Frequently Asked Questions (FAQ).</description>
    </item>
    
    <item>
      <title>TiDB Configuration File Description</title>
      <link>https://pingcap.com/docs/dev/reference/configuration/tidb-server/configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/configuration/tidb-server/configuration-file/</guid>
      <description>TiDB Configuration File Description The TiDB configuration file supports more options than command line options. You can find the default configuration file in config/config.toml.example and rename it to config.toml.
This document describes the options that are not involved in command line options. For command line options, see here.
split-table  To create a separate Region for each table Default: true It is recommended to set it to false if you need to create a large number of tables  oom-action  To specify the operation when out-of-memory occurs in TiDB Default: &amp;ldquo;log&amp;rdquo; The valid options are &amp;ldquo;log&amp;rdquo; and &amp;ldquo;cancel&amp;rdquo;; &amp;ldquo;log&amp;rdquo; only prints the log, without actual processing; &amp;ldquo;cancel&amp;rdquo; cancels the operation and outputs the log  enable-streaming  To enable the data fetch mode of streaming in Coprocessor Default: false  lower-case-table-names  To configure the value of the lower_case_table_names system variable Default: 2 For details, you can see the MySQL description of this variable Currently, TiDB only supports setting the value of this option to 2.</description>
    </item>
    
    <item>
      <title>TiDB Configuration File Description</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/tidb-config-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/tidb-config-file/</guid>
      <description>TiDB Configuration File Description The TiDB configuration file supports more options than command line options. You can find the default configuration file in config/config.toml.example and rename it to config.toml.
This document describes the options that are not involved in command line options. For command line options, see here.
split-table  To create a separate Region for each table Default: true It is recommended to set it to false if you need to create a large number of tables  oom-action  To specify the operation when out-of-memory occurs in TiDB Default: &amp;ldquo;log&amp;rdquo; The valid options are &amp;ldquo;log&amp;rdquo; and &amp;ldquo;cancel&amp;rdquo;; &amp;ldquo;log&amp;rdquo; only prints the log, without actual processing; &amp;ldquo;cancel&amp;rdquo; cancels the operation and outputs the log  enable-streaming  To enable the data fetch mode of streaming in Coprocessor Default: false  lower-case-table-names  To configure the value of the lower_case_table_names system variable Default: 2 For details, you can see the MySQL description of this variable Currently, TiDB only supports setting the value of this option to 2.</description>
    </item>
    
    <item>
      <title>TiDB Controller User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-control/</guid>
      <description>TiDB Controller User Guide TiDB Controller is a command line tool of TiDB, usually used to obtain the status information of TiDB for debugging.
Compile from source code  Compilation environment requirement: Go Version 1.7 or later Compilation procedures: Go to the root directory of the TiDB Controller project, use the make command to compile, and generate tidb-ctl. Compilation documentation: you can find the help files in the doc directory; if the help files are lost or you want to update them, use the make doc command to generate the help files.</description>
    </item>
    
    <item>
      <title>TiDB Controller User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/tidb-controller/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/tidb-controller/</guid>
      <description>TiDB Controller User Guide TiDB Controller is a command line tool of TiDB, usually used to obtain the status information of TiDB for debugging.
Compile from source code  Compilation environment requirement: Go Version 1.7 or later Compilation procedures: Go to the root directory of the TiDB Controller project, use the make command to compile, and generate tidb-ctl. Compilation documentation: you can find the help files in the doc directory; if the help files are lost or you want to update them, use the make doc command to generate the help files.</description>
    </item>
    
    <item>
      <title>TiDB DM (Data Migration) Tutorial</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/data-migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/data-migration/</guid>
      <description>TiDB DM (Data Migration) Tutorial TiDB DM (Data Migration) is a platform that supports migrating large, complex, production data sets from MySQL or MariaDB to TiDB.
DM supports creating and importing an initial dump of data, as well as keeping data synchronized during migration by reading and applying binary logs from the source data store. DM can migrate sharded topologies from in-production databases by merging tables from multiple separate upstream MySQL/MariaDB instances/clusters.</description>
    </item>
    
    <item>
      <title>TiDB Data Manipulation Language</title>
      <link>https://pingcap.com/docs/v2.1/sql/dml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/dml/</guid>
      <description>TiDB Data Manipulation Language Data manipulation language (DML) is a family of syntax elements used for selecting, inserting, deleting and updating data in a database.
SELECT SELECT is used to retrieve rows selected from one or more tables.
Syntax SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], .</description>
    </item>
    
    <item>
      <title>TiDB Data Type</title>
      <link>https://pingcap.com/docs/dev/reference/sql/data-types/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/data-types/</guid>
      <description>TiDB Data Type TiDB supports all the data types in MySQL except the Spatial type, including numeric type, string type, date &amp;amp; time type, and JSON type.
The definition of the data type is: T(M[, D]). In this format:
 T indicates the specific data type. M indicates the maximum display width for integer types. For floating-point and fixed-point types, M is the total number of digits that can be stored (the precision).</description>
    </item>
    
    <item>
      <title>TiDB Data Type</title>
      <link>https://pingcap.com/docs/v2.1/sql/datatype/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/datatype/</guid>
      <description>TiDB Data Type TiDB supports all the data types in MySQL except the Spatial type, including numeric type, string type, date &amp;amp; time type, and JSON type.
The definition of the data type is: T(M[, D]). In this format:
 T indicates the specific data type. M indicates the maximum display width for integer types. For floating-point and fixed-point types, M is the total number of digits that can be stored (the precision).</description>
    </item>
    
    <item>
      <title>TiDB Deployment on Kubernetes</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/kubernetes/</guid>
      <description>TiDB Deployment on Kubernetes TiDB Operator manages TiDB clusters on Kubernetes and automates tasks related to operating a TiDB cluster. It makes TiDB a truly cloud-native database.
 GCP   AWS   Local  Google Kubernetes Engine (GKE) The TiDB Operator tutorial for GKE runs directly in the Google Cloud Shell.
  AWS Elastic Kubernetes Service (EKS) Deploy a running TiDB Cluster on EKS using a combination of Terraform and TiDB Operator.</description>
    </item>
    
    <item>
      <title>TiDB Deployment on Kubernetes</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/kubernetes/</guid>
      <description>TiDB Deployment on Kubernetes TiDB Operator manages TiDB clusters on Kubernetes and automates tasks related to operating a TiDB cluster. It makes TiDB a truly cloud-native database.
 Warning:
Currently, TiDB Operator is work in progress [WIP] and is NOT ready for production. Use at your own risk.
  GCP   AWS   Local  Google Kubernetes Engine (GKE) The TiDB Operator tutorial for GKE runs directly in the Google Cloud Shell.</description>
    </item>
    
    <item>
      <title>TiDB Docker Compose Deployment</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/local-cluster/install-from-docker-compose/</guid>
      <description>TiDB Docker Compose Deployment This document describes how to quickly deploy a TiDB testing cluster with a single command using Docker Compose.
With Docker Compose, you can use a YAML file to configure application services in multiple containers. Then, with a single command, you can create and start all the services from your configuration.
Prerequisites Make sure you have installed the following items on your machine:
 Git Docker Compose MySQL Client  Deploy TiDB using Docker Compose  Download tidb-docker-compose.</description>
    </item>
    
    <item>
      <title>TiDB Docker Compose Deployment</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/docker-compose/</guid>
      <description>TiDB Docker Compose Deployment This document describes how to quickly deploy a TiDB testing cluster with a single command using Docker Compose.
With Docker Compose, you can use a YAML file to configure application services in multiple containers. Then, with a single command, you can create and start all the services from your configuration.
Prerequisites Make sure you have installed the following items on your machine:
 Git Docker Compose MySQL Client  Deploy TiDB using Docker Compose  Download tidb-docker-compose.</description>
    </item>
    
    <item>
      <title>TiDB FAQ</title>
      <link>https://pingcap.com/docs/faq/tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/faq/tidb/</guid>
      <description>TiDB FAQ This document lists the Most Frequently Asked Questions about TiDB.
About TiDB TiDB introduction and architecture What is TiDB? TiDB is a distributed SQL database that features in horizontal scalability, high availability and consistent distributed transactions. It also enables you to use MySQL&amp;rsquo;s SQL syntax and protocol to manage and retrieve data.
What is TiDB&amp;rsquo;s architecture? The TiDB cluster has three components: the TiDB server, the PD (Placement Driver) server, and the TiKV server.</description>
    </item>
    
    <item>
      <title>TiDB FAQ</title>
      <link>https://pingcap.com/docs/v2.1/FAQ/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/FAQ/</guid>
      <description>TiDB FAQ This document lists the Most Frequently Asked Questions about TiDB.
About TiDB TiDB introduction and architecture What is TiDB? TiDB is a distributed SQL database that features in horizontal scalability, high availability and consistent distributed transactions. It also enables you to use MySQL&amp;rsquo;s SQL syntax and protocol to manage and retrieve data.
What is TiDB&amp;rsquo;s architecture? The TiDB cluster has three components: the TiDB server, the PD (Placement Driver) server, and the TiKV server.</description>
    </item>
    
    <item>
      <title>TiDB Garbage Collection (GC)</title>
      <link>https://pingcap.com/docs/dev/reference/garbage-collection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/garbage-collection/</guid>
      <description>TiDB Garbage Collection (GC) TiDB uses MVCC to control concurrency. When you update or delete data, the original data is not deleted immediately but is kept for a period during which it can be read. Thus the write operation and the read operation are not mutually exclusive and it is possible to read the history versions of the data.
The data versions whose duration exceeds a specific time and that are not used any more will be cleared, otherwise they will occupy the disk space and affect TiDB&amp;rsquo;s performance.</description>
    </item>
    
    <item>
      <title>TiDB Garbage Collection (GC)</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/gc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/gc/</guid>
      <description>TiDB Garbage Collection (GC) TiDB uses MVCC to control concurrency. When you update or delete data, the original data is not deleted immediately but is kept for a period during which it can be read. Thus the write operation and the read operation are not mutually exclusive and it is possible to read the history versions of the data.
The data versions whose duration exceeds a specific time and that are not used any more will be cleared, otherwise they will occupy the disk space and affect TiDB&amp;rsquo;s performance.</description>
    </item>
    
    <item>
      <title>TiDB Introduction</title>
      <link>https://pingcap.com/docs/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/overview/</guid>
      <description>TiDB Introduction TiDB (&amp;ldquo;Ti&amp;rdquo; stands for Titanium) is an open-source NewSQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads. It is MySQL compatible and features horizontal scalability, strong consistency, and high availability.
TiDB can be deployed on-premise or in-cloud. The following deployment options are officially supported by PingCAP:
 Ansible Deployment: This guide describes how to deploy TiDB using Ansible. It is strongly recommended for production deployment. Ansible Offline Deployment: If your environment has no access to the internet, you can follow this guide to see how to deploy a TiDB cluster offline using Ansible.</description>
    </item>
    
    <item>
      <title>TiDB Introduction</title>
      <link>https://pingcap.com/docs/v2.1/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/overview/</guid>
      <description>TiDB Introduction TiDB (The pronunciation is: /&amp;lsquo;tadibi:/ tai-D-B, etymology: titanium) is an open-source distributed scalable Hybrid Transactional and Analytical Processing (HTAP) database. It features horizontal scalability, strong consistency, and high availability. TiDB is MySQL compatible and serves as a one-stop data warehouse for both OLTP (Online Transactional Processing) and OLAP (Online Analytical Processing) workloads.
 Horizontal scalability
TiDB provides horizontal scalability simply by adding new nodes. Never worry about infrastructure capacity ever again.</description>
    </item>
    
    <item>
      <title>TiDB Memory Control</title>
      <link>https://pingcap.com/docs/dev/how-to/configure/memory-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/configure/memory-control/</guid>
      <description>TiDB Memory Control Currently, TiDB can track the memory quota of a single SQL query and take actions to prevent OOM (out of memory) or troubleshoot OOM when the memory usage exceeds a specific threshold value. In the TiDB configuration file, you can configure the options as below to control TiDB behaviors when the memory quota exceeds the threshold value:
# Valid options: [&amp;#34;log&amp;#34;, &amp;#34;cancel&amp;#34;] oom-action = &amp;#34;log&amp;#34;  If the configuration item above uses &amp;ldquo;log&amp;rdquo;, when the memory quota of a single SQL query exceeds the threshold value which is controlled by the tidb_mem_quota_query variable, TiDB prints an entry of log.</description>
    </item>
    
    <item>
      <title>TiDB Memory Control</title>
      <link>https://pingcap.com/docs/v2.1/sql/tidb-memory-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/tidb-memory-control/</guid>
      <description>TiDB Memory Control Currently, TiDB can track the memory quota of a single SQL query and take actions to prevent OOM (out of memory) or troubleshoot OOM when the memory usage exceeds a specific threshold value. In the TiDB configuration file, you can configure the options as below to control TiDB behaviors when the memory quota exceeds the threshold value:
# Valid options: [&amp;#34;log&amp;#34;, &amp;#34;cancel&amp;#34;] oom-action = &amp;#34;log&amp;#34;  If the configuration item above uses &amp;ldquo;log&amp;rdquo;, when the memory quota of a single SQL query exceeds the threshold value which is controlled by the tidb_mem_quota_query variable, TiDB prints an entry of log.</description>
    </item>
    
    <item>
      <title>TiDB Monitoring Framework Overview</title>
      <link>https://pingcap.com/docs/dev/how-to/monitor/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/monitor/overview/</guid>
      <description>TiDB Monitoring Framework Overview The TiDB monitoring framework adopts two open source projects: Prometheus and Grafana. TiDB uses Prometheus to store the monitoring and performance metrics and Grafana to visualize these metrics.
About Prometheus in TiDB As a time series database, Prometheus has a multi-dimensional data model and flexible query language. As one of the most popular open source projects, many companies and organizations have adopted Prometheus, and the project has a very active community.</description>
    </item>
    
    <item>
      <title>TiDB Monitoring Framework Overview</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/monitor-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/monitor-overview/</guid>
      <description>TiDB Monitoring Framework Overview The TiDB monitoring framework adopts two open source projects: Prometheus and Grafana. TiDB uses Prometheus to store the monitoring and performance metrics and Grafana to visualize these metrics.
About Prometheus in TiDB As a time series database, Prometheus has a multi-dimensional data model and flexible query language. As one of the most popular open source projects, many companies and organizations have adopted Prometheus, and the project has a very active community.</description>
    </item>
    
    <item>
      <title>TiDB Monitoring Metrics</title>
      <link>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/key-monitoring-metrics/tidb/</guid>
      <description>TiDB Monitoring Metrics If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see TiDB Monitoring Framework Overview.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
This document describes some key monitoring metrics displayed on the TiDB dashboard.</description>
    </item>
    
    <item>
      <title>TiDB Monitoring Metrics</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/tidb-dashboard-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/tidb-dashboard-info/</guid>
      <description>TiDB Monitoring Metrics If you use Ansible to deploy the TiDB cluster, the monitoring system is deployed at the same time. For more information, see TiDB Monitoring Framework Overview.
The Grafana dashboard is divided into a series of sub dashboards which include Overview, PD, TiDB, TiKV, Node_exporter, Disk Performance, and so on. A lot of metrics are there to help you diagnose.
This document describes some key monitoring metrics displayed on the TiDB dashboard.</description>
    </item>
    
    <item>
      <title>TiDB Quick Start Guide</title>
      <link>https://pingcap.com/docs/v2.1/QUICKSTART/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/QUICKSTART/</guid>
      <description>TiDB Quick Start Guide As an open source distributed scalable HTAP database, TiDB can be deployed on-premise or in-cloud. The following deployment options are officially supported by PingCAP.
 Ansible Deployment: This guide describes how to deploy TiDB using Ansible. It is strongly recommended for production deployment. Ansible Offline Deployment: If your environment has no access to the internet, you can follow this guide to see how to deploy a TiDB cluster offline using Ansible.</description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc1/</guid>
      <description>TiDB RC1 Release Notes On December 23, 2016, TiDB RC1 is released. See the following updates in this release:
TiKV:  The write speed has been improved. The disk space usage is reduced. Hundreds of TBs of data can be supported. The stability is improved and TiKV can support a cluster with 200 nodes. Supports the Raw KV API and the Golang client.  Placement Driver (PD): + The scheduling strategy framework is optimized and now the strategy is more flexible and reasonable.</description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/rc1/</guid>
      <description>TiDB RC1 Release Notes On December 23, 2016, TiDB RC1 is released. See the following updates in this release:
TiKV:  The write speed has been improved. The disk space usage is reduced. Hundreds of TBs of data can be supported. The stability is improved and TiKV can support a cluster with 200 nodes. Supports the Raw KV API and the Golang client.  Placement Driver (PD): + The scheduling strategy framework is optimized and now the strategy is more flexible and reasonable.</description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc2/</guid>
      <description> TiDB RC2 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on the compatibility with MySQL, SQL query optimizer, system stability and performance in this version. Whats more, a new permission management mechanism is added and users can control data access in the same way as the MySQL privilege management system.
TiDB:  Query optimizer  Collect column/index statistics and use them in the query optimizer Optimize the correlated subquery Optimize the Cost Based Optimizer (CBO) framework Eliminate aggregation using unique key information Refactor expression evaluation framework Convert Distinct to GroupBy Support the topn operation push-down  Support basic privilege management Add lots of MySQL built-in functions Improve the Alter Table statement and support the modification of table name, default value and comment Support the Create Table Like statement Support the Show Warnings statement Support the Rename Table statement Restrict the size of a single transaction to avoid the cluster blocking of large transactions Automatically split data in the process of Load Data Optimize the performance of the AddIndex and Delete statement Support &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode Improve the monitoring system Fix Bugs Solve the problem of memory leak  PD:  Support location aware replica scheduling Conduct fast scheduling based on the number of region pd-ctl support more features  Add or delete PD Obtain Region information with Key Add or delete scheduler and operator Obtain cluster label information   TiKV:  Support Async Apply to improve the entire write performance Use prefix seek to improve the read performance of Write CF Use memory hint prefix to improve the insert performance of Raft CF Optimize the single read transaction performance Support more push-down expressions Improve the monitoring system Fix Bugs  </description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/rc2/</guid>
      <description> TiDB RC2 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on the compatibility with MySQL, SQL query optimizer, system stability and performance in this version. Whats more, a new permission management mechanism is added and users can control data access in the same way as the MySQL privilege management system.
TiDB:  Query optimizer  Collect column/index statistics and use them in the query optimizer Optimize the correlated subquery Optimize the Cost Based Optimizer (CBO) framework Eliminate aggregation using unique key information Refactor expression evaluation framework Convert Distinct to GroupBy Support the topn operation push-down  Support basic privilege management Add lots of MySQL built-in functions Improve the Alter Table statement and support the modification of table name, default value and comment Support the Create Table Like statement Support the Show Warnings statement Support the Rename Table statement Restrict the size of a single transaction to avoid the cluster blocking of large transactions Automatically split data in the process of Load Data Optimize the performance of the AddIndex and Delete statement Support &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode Improve the monitoring system Fix Bugs Solve the problem of memory leak  PD:  Support location aware replica scheduling Conduct fast scheduling based on the number of region pd-ctl support more features  Add or delete PD Obtain Region information with Key Add or delete scheduler and operator Obtain cluster label information   TiKV:  Support Async Apply to improve the entire write performance Use prefix seek to improve the read performance of Write CF Use memory hint prefix to improve the insert performance of Raft CF Optimize the single read transaction performance Support more push-down expressions Improve the monitoring system Fix Bugs  </description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc3/</guid>
      <description>TiDB RC3 Release Notes On June 20, 2017, TiDB RC4 is released!This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  The privilege management is refined to enable users to manage the data access privileges using the same way as in MySQL. DDL is accelerated. The load balancing policy and process are optimized for performance. TiDB-Ansible is open sourced. By using TiDB-Ansilbe, you can deploy, upgrade, start and shutdown a TiDB cluster with one click.</description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/rc3/</guid>
      <description>TiDB RC3 Release Notes On June 20, 2017, TiDB RC4 is released!This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  The privilege management is refined to enable users to manage the data access privileges using the same way as in MySQL. DDL is accelerated. The load balancing policy and process are optimized for performance. TiDB-Ansible is open sourced. By using TiDB-Ansilbe, you can deploy, upgrade, start and shutdown a TiDB cluster with one click.</description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc4/</guid>
      <description>TiDB RC4 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  For performance, the write performance is improved significantly, and the computing task scheduling supports prioritizing to avoid the impact of OLAP on OLTP. The optimizer is revised for a more accurate query cost estimating and for an automatic choice of the Join physical operator based on the cost.</description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/docs/v2.1/releases/rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/releases/rc4/</guid>
      <description>TiDB RC4 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  For performance, the write performance is improved significantly, and the computing task scheduling supports prioritizing to avoid the impact of OLAP on OLTP. The optimizer is revised for a more accurate query cost estimating and for an automatic choice of the Join physical operator based on the cost.</description>
    </item>
    
    <item>
      <title>TiDB Roadmap</title>
      <link>https://pingcap.com/docs/roadmap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/roadmap/</guid>
      <description>TiDB Roadmap This document defines the roadmap for TiDB development.
TiDB: Optimizer Statistics Optimization Multi-Column Statistics Cascades Planner Plan Management SQL Tuning Advisor Robust Access Path Selection: add the heuristic rule and improve the accuracy of index selection in OLTP scenarios Adaptive Query Optimization  Execution Engine Parallel Operators Memory Control Concurrency Control Shuffle Operators Vectorized Expression Evaluation UDF  SQL Features Support Views Support Window Functions Support Common Table Expressions Support Hash Partitioned Tables Support the utf8mb4_0900_ai_ci Collation  Improve DDL Support Table Lock Support Change Column Type Support Multiple DDL Operations in a Single Statement Support Invisible Indexes  Support Plugin System Support White List Plugin Support Audit Log Plugin Support RBAC Plugin Support Diagnostic Plugin  Support Query Tracing Support Hybrid Column/Row-oriented Storage Engine Support New Storage Row Format: improve performance and reduce memory usage Support Non-integer Type of RowID Transaction Reduce Read-write Conflicts Optimize Transaction Scheduling Mechanism Refine Model and Reduce Latency Support Minimal Transaction (like the mini-transaction of InnoDB)   TiKV: Raft Region Merge - Merge small Regions together to reduce overhead Local Read Thread - Process read requests in a local read thread Split Region in Batch - Speed up Region split for large Regions Raft Learner - Support Raft learner to smooth the configuration change process Raft Pre-vote - Support Raft pre-vote to avoid unnecessary leader election on network isolation Joint Consensus - Change multi members safely.</description>
    </item>
    
    <item>
      <title>TiDB Roadmap</title>
      <link>https://pingcap.com/docs/v2.1/ROADMAP/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/ROADMAP/</guid>
      <description>TiDB Roadmap This document defines the roadmap for TiDB development.
TiDB: Optimizer Refactor Ranger Optimize the cost model Cascades model planner Join Reorder  Statistics Update statistics dynamically according to the query feedback Analyze table automatically Improve the accuracy of Row Count estimation  Execution Engine Push down the Projection operator to the Coprocessor Improve the performance of the HashJoin operator Parallel Operators Projection Aggregation Sort  Compact Row Format to reduce memory usage File Sort  View Window Function Common Table Expression Table Partition Range Partition Hash Partition  Cluster Index New storage row format Query Tracing Improve DDL Speed up Add Index operation Parallel DDL Support locking table Support modifying the column type Support modifying the primary key Support multiple DDL operations in a single statement  Support utf8_general_ci collation  TiKV: Raft Region Merge - Merge small Regions together to reduce overhead Local Read Thread - Process read requests in a local read thread Split Region in Batch - Speed up Region split for large Regions Raft Learner - Support Raft learner to smooth the configuration change process Raft Pre-vote - Support Raft pre-vote to avoid unnecessary leader election on network isolation Joint Consensus - Change multi members safely.</description>
    </item>
    
    <item>
      <title>TiDB Specific System Variables</title>
      <link>https://pingcap.com/docs/dev/reference/configuration/tidb-server/tidb-specific-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/configuration/tidb-server/tidb-specific-variables/</guid>
      <description>TiDB Specific System Variables TiDB contains a number of system variables which are specific to its usage, and do not apply to MySQL. These variables start with a tidb_ prefix, and can be tuned to optimize system performance.
System variables Variables can be set with the SET statement, for example:
set @@tidb_distsql_scan_concurrency = 10 If you need to set the global variable, run:
set @@global.tidb_distsql_scan_concurrency = 10 tidb_snapshot  Scope: SESSION Default value: &amp;ldquo;&amp;rdquo; This variable is used to set the time point at which the data is read by the session.</description>
    </item>
    
    <item>
      <title>TiDB Specific System Variables</title>
      <link>https://pingcap.com/docs/v2.1/sql/tidb-specific/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/tidb-specific/</guid>
      <description>TiDB Specific System Variables TiDB contains a number of system variables which are specific to its usage, and do not apply to MySQL. These variables start with a tidb_ prefix, and can be tuned to optimize system performance.
System variables Variables can be set with the SET statement, for example:
set @@tidb_distsql_scan_concurrency = 10 If you need to set the global variable, run:
set @@global.tidb_distsql_scan_concurrency = 10 tidb_snapshot  Scope: SESSION Default value: &amp;ldquo;&amp;rdquo; This variable is used to set the time point at which the data is read by the session.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench Performance Test Report -- v2.0.0 vs. v1.0.0</title>
      <link>https://pingcap.com/docs/benchmark/sysbench-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/sysbench-v2/</guid>
      <description>TiDB Sysbench Performance Test Report &amp;ndash; v2.0.0 vs. v1.0.0 Test purpose This test aims to compare the performances of TiDB 1.0 and TiDB 2.0.
Test version, time, and place TiDB version: v1.0.8 vs. v2.0.0-rc6
Time: April 2018
Place: Beijing, China
Test environment IDC machine
   Type Name     OS linux (CentOS 7.3.1611)   CPU 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.20GHz   RAM 128GB   DISK Optane 500GB SSD * 1    Test plan TiDB version information v1.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench Performance Test Report -- v2.0.0 vs. v1.0.0</title>
      <link>https://pingcap.com/docs/v2.1/benchmark/sysbench-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/benchmark/sysbench-v2/</guid>
      <description>TiDB Sysbench Performance Test Report &amp;ndash; v2.0.0 vs. v1.0.0 Test purpose This test aims to compare the performances of TiDB 1.0 and TiDB 2.0.
Test version, time, and place TiDB version: v1.0.8 vs. v2.0.0-rc6
Time: April 2018
Place: Beijing, China
Test environment IDC machine
   Type Name     OS linux (CentOS 7.3.1611)   CPU 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.20GHz   RAM 128GB   DISK Optane 500GB SSD * 1    Test plan TiDB version information v1.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench Performance Test Report -- v2.1 vs. v2.0</title>
      <link>https://pingcap.com/docs/benchmark/sysbench-v3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/sysbench-v3/</guid>
      <description>TiDB Sysbench Performance Test Report &amp;ndash; v2.1 vs. v2.0 Test purpose This test aims to compare the performance of TiDB 2.1 and TiDB 2.0 for OLTP where the working set fits in memory.
Test version, time, and place TiDB version: v2.1.0-rc.2 vs. v2.0.6
Time: September, 2018
Place: Beijing, China
Test environment IDC machine:
   Type Name     OS Linux (CentOS 7.3.1611)   CPU 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench Performance Test Report -- v2.1 vs. v2.0</title>
      <link>https://pingcap.com/docs/v2.1/benchmark/sysbench-v3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/benchmark/sysbench-v3/</guid>
      <description>TiDB Sysbench Performance Test Report &amp;ndash; v2.1 vs. v2.0 Test purpose This test aims to compare the performance of TiDB 2.1 and TiDB 2.0 for OLTP where the working set fits in memory.
Test version, time, and place TiDB version: v2.1.0-rc.2 vs. v2.0.6
Time: September, 2018
Place: Beijing, China
Test environment IDC machine:
   Type Name     OS Linux (CentOS 7.3.1611)   CPU 40 vCPUs, Intel&amp;reg; Xeon&amp;reg; CPU E5-2630 v4 @ 2.</description>
    </item>
    
    <item>
      <title>TiDB System Tables</title>
      <link>https://pingcap.com/docs/dev/reference/system-databases/mysql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/system-databases/mysql/</guid>
      <description> TiDB System Tables This document introduces TiDB system tables.
Grant system tables These system tables contain grant information about user accounts and their privileges:
 user: user accounts, global privileges, and other non-privilege columns db: database-level privileges tables_priv: table-level privileges columns_priv: column-level privileges  Server-side help system tables Currently, the help_topic is NULL.
Statistics system tables  stats_buckets: the buckets of statistics stats_histograms: the histograms of statistics stats_meta: the meta information of tables, such as the total number of rows and updated rows  GC worker system tables  gc_delete_range: to record the data to be deleted  Miscellaneous system tables  GLOBAL_VARIABLES: global system variable table tidb: to record the version information when TiDB executes bootstrap  </description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G Performance Test Report V2.0</title>
      <link>https://pingcap.com/docs/benchmark/tpch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/tpch/</guid>
      <description>TiDB TPC-H 50G Performance Test Report Test purpose This test aims to compare the performances of TiDB 1.0 and TiDB 2.0 in the OLAP scenario.
 Note:
Different test environments might lead to different test results.
 Test environment Machine information System information:
   Machine IP Operation system Kernel version File system type     172.16.31.2 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.3 Ubuntu 17.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G Performance Test Report V2.0</title>
      <link>https://pingcap.com/docs/v2.1/benchmark/tpch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/benchmark/tpch/</guid>
      <description>TiDB TPC-H 50G Performance Test Report Test purpose This test aims to compare the performances of TiDB 1.0 and TiDB 2.0 in the OLAP scenario.
 Note:
Different test environments might lead to different test results.
 Test environment Machine information System information:
   Machine IP Operation system Kernel version File system type     172.16.31.2 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.3 Ubuntu 17.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G Performance Test Report V2.1</title>
      <link>https://pingcap.com/docs/benchmark/tpch-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/benchmark/tpch-v2/</guid>
      <description>TiDB TPC-H 50G Performance Test Report V2.1 Test purpose This test aims to compare the performances of TiDB 2.0 and TiDB 2.1 in the OLAP scenario.
 Note:
Different test environments might lead to different test results.
 Test environment Machine information System information:
   Machine IP Operation system Kernel version File system type     10.0.1.4 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.5 CentOS 7.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G Performance Test Report V2.1</title>
      <link>https://pingcap.com/docs/v2.1/benchmark/tpch-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/benchmark/tpch-v2/</guid>
      <description>TiDB TPC-H 50G Performance Test Report V2.1 Test purpose This test aims to compare the performances of TiDB 2.0 and TiDB 2.1 in the OLAP scenario.
 Note:
Different test environments might lead to different test results.
 Test environment Machine information System information:
   Machine IP Operation system Kernel version File system type     10.0.1.4 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.5 CentOS 7.</description>
    </item>
    
    <item>
      <title>TiDB Transaction Isolation Levels</title>
      <link>https://pingcap.com/docs/dev/reference/transactions/transaction-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/transactions/transaction-isolation/</guid>
      <description>TiDB Transaction Isolation Levels Transaction isolation is one of the foundations of database transaction processing. Isolation is the I in the acronym ACID (Atomicity, Consistency, Isolation, Durability), which represents the isolation property of database transactions.
The SQL-92 standard defines four levels of transaction isolation: Read Uncommitted, Read Committed, Repeatable Read, and Serializable. See the following table for details:
   Isolation Level Dirty Write Dirty Read Fuzzy Read Phantom     READ UNCOMMITTED Not Possible Possible Possible Possible   READ COMMITTED Not Possible Not possible Possible Possible   REPEATABLE READ Not Possible Not possible Not possible Possible   SERIALIZABLE Not Possible Not possible Not possible Not possible    TiDB implements Snapshot Isolation consistency, which it advertises as REPEATABLE-READ for compatibility with MySQL.</description>
    </item>
    
    <item>
      <title>TiDB Transaction Isolation Levels</title>
      <link>https://pingcap.com/docs/v2.1/sql/transaction-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/transaction-isolation/</guid>
      <description>TiDB Transaction Isolation Levels Transaction isolation is one of the foundations of database transaction processing. Isolation is the I in the acronym ACID (Atomicity, Consistency, Isolation, Durability), which represents the isolation property of database transactions.
The SQL-92 standard defines four levels of transaction isolation: Read Uncommitted, Read Committed, Repeatable Read and Serializable. See the following table for details:
   Isolation Level Dirty Read Nonrepeatable Read Phantom Read Serialization Anomaly     Read Uncommitted Possible Possible Possible Possible   Read Committed Not possible Possible Possible Possible   Repeatable Read Not possible Not possible Not possible in TiDB Possible   Serializable Not possible Not possible Not possible Not possible    TiDB offers the Repeatable Read isolation level.</description>
    </item>
    
    <item>
      <title>TiDB User Account Management</title>
      <link>https://pingcap.com/docs/dev/reference/security/user-account-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/security/user-account-management/</guid>
      <description>TiDB User Account Management This document describes how to manage a TiDB user account.
User names and passwords TiDB stores the user accounts in the table of the mysql.user system database. Each account is identified by a user name and the client host. Each account may have a password.
You can connect to the TiDB server using the MySQL client, and use the specified account and password to login:</description>
    </item>
    
    <item>
      <title>TiDB User Account Management</title>
      <link>https://pingcap.com/docs/v2.1/sql/user-account-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/user-account-management/</guid>
      <description>TiDB User Account Management This document describes how to manage a TiDB user account.
User names and passwords TiDB stores the user accounts in the table of the mysql.user system database. Each account is identified by a user name and the client host. Each account may have a password.
You can connect to the TiDB server using the MySQL client, and use the specified account and password to login:</description>
    </item>
    
    <item>
      <title>TiDB User Guide</title>
      <link>https://pingcap.com/docs/v2.1/sql/user-manual/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/user-manual/</guid>
      <description>TiDB User Guide TiDB supports the SQL-92 standard and is compatible with MySQL. To help you easily get started with TiDB, TiDB user guide mainly inherits the MySQL document structure with some TiDB specific changes.
TiDB server administration  The TiDB Server The TiDB Command Options The TiDB Data Directory The TiDB System Database The TiDB System Variables The Proprietary System Variables and Syntax in TiDB The TiDB Server Logs The TiDB Access Privilege System TiDB User Account Management Use Encrypted Connections  SQL optimization  Understand the Query Execution Plan Introduction to Statistics  Language structure  Literal Values Schema Object Names Keywords and Reserved Words User-Defined Variables Expression Syntax Comment Syntax  Globalization  Character Set Support Character Set Configuration Time Zone  Data types  Numeric Types Date and Time Types String Types JSON Types The ENUM data type The SET Type Data Type Default Values  Functions and operators  Function and Operator Reference Type Conversion in Expression Evaluation Operators Control Flow Functions String Functions Numeric Functions and Operators Date and Time Functions Bit Functions and Operators Cast Functions and Operators Encryption and Compression Functions Information Functions JSON Functions Functions Used with Global Transaction IDs [TBD] Aggregate (GROUP BY) Functions Miscellaneous Functions Precision Math  SQL statement syntax  Data Definition Statements Data Manipulation Statements Transactions</description>
    </item>
    
    <item>
      <title>TiDB-Ansible Common Operations</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/ansible-operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/orchestrated/ansible-operations/</guid>
      <description>TiDB-Ansible Common Operations This guide describes the common operations when you administer a TiDB cluster using TiDB-Ansible.
Start a cluster $ ansible-playbook start.yml This operation starts all the components in the entire TiDB cluster in order, which include PD, TiDB, TiKV, and the monitoring components.
Stop a cluster $ ansible-playbook stop.yml This operation stops all the components in the entire TiDB cluster in order, which include PD, TiDB, TiKV, and the monitoring components.</description>
    </item>
    
    <item>
      <title>TiDB-Ansible Common Operations</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/ansible-operation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/ansible-operation/</guid>
      <description>TiDB-Ansible Common Operations This guide describes the common operations when you administer a TiDB cluster using TiDB-Ansible.
Start a cluster $ ansible-playbook start.yml This operation starts all the components in the entire TiDB cluster in order, which include PD, TiDB, TiKV, and the monitoring components.
Stop a cluster $ ansible-playbook stop.yml This operation stops all the components in the entire TiDB cluster in order, which include PD, TiDB, TiKV, and the monitoring components.</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Cluster Deployment</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/deploy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/deploy/</guid>
      <description>TiDB-Binlog Cluster Deployment This document describes two methods of deploying TiDB-Binlog:
 Deploy TiDB-Binlog using TiDB-Ansible Deploy TiDB-Binlog using a Binary package  It is recommended to deploy TiDB-Binlog using TiDB-Ansible. If you just want to do a simple testing, you can deploy TiDB-Binlog using a Binary package.
Deploy TiDB-Binlog using TiDB-Ansible Step 1: Download TiDB-Ansible  Use the TiDB user account to log in to the central control machine and go to the /home/tidb directory.</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Cluster Operations</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/operation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/operation/</guid>
      <description>TiDB-Binlog Cluster Operations Pump/Drainer state Pump/Drainer state description:
 online: running normally. pausing: in the pausing process. It turns into this state after you use kill or press Ctrl + C to exit from the process. When Pump/Drainer exits all internal threads in safe, it becomes paused. paused: has been stopped. While Pump is in this state, it rejects the request of writing binlog into it and does not provide the binlog for Drainer any more.</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Cluster Upgrade</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/upgrade/</guid>
      <description>TiDB-Binlog Cluster Upgrade The new TiDB versions (v2.0.8-binlog, v2.1.0-rc.5 or later) are not compatible with the Kafka version or Local version of TiDB-Binlog. If TiDB is upgraded to one of the new versions, it is required to use the cluster version of TiDB-Binlog. If the Kafka or local version of TiDB-Binlog is used before upgrading, you need to upgrade your TiDB-Binlog to the cluster version.
The corresponding relationship between TiDB-Binlog versions and TiDB versions is shown in the following table:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Cluster User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/tidb-binlog-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/tidb-binlog-cluster/</guid>
      <description>TiDB-Binlog Cluster User Guide This document introduces the architecture and the deployment of TiDB-Binlog of the cluster version.
TiDB-Binlog is an enterprise tool used to collect the binlog data of TiDB and provide real-time backup and synchronization.
TiDB-Binlog has the following features:
 Data synchronization: synchronize the data in the TiDB cluster to other databases Real-time backup and restoration: back up the data in the TiDB cluster and restore the TiDB cluster when the cluster fails  TiDB-Binlog architecture The TiDB-Binlog architecture is as follows:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Local Deployment</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/tidb-binlog-local/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/tidb-binlog-local/</guid>
      <description>TiDB-Binlog Local Deployment About TiDB-Binlog-local TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases
 Real-time backup and recovery: to back up TiDB cluster data, and recover in case of cluster outages   TiDB-Binlog-local architecture The TiDB-Binlog architecture is as follows:
The TiDB-Binlog cluster mainly consists of two components:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Monitoring</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/monitor/</guid>
      <description>TiDB-Binlog Monitoring After you have deployed TiDB-Binlog using Ansible successfully, you can go to the Grafana Web (default address: http://grafana_ip:3000, default account: admin, password: admin) to check the state of Pump and Drainer.
Monitoring metrics TiDB-Binlog consists of two components: Pump and Drainer. This section shows the monitoring metrics of Pump and Drainer.
Pump monitoring metrics To understand the Pump monitoring metrics, check the following table:
   Pump monitoring metrics Description     Storage Size Records the total disk space (capacity) and the available disk space (available)   Metadata Records the biggest TSO (gc_tso) of the binlog that each Pump node can delete, and the biggest commit TSO (max_commit_tso) of the saved binlog   Write Binlog QPS by Instance Shows QPS of writing binlog requests received by each Pump node   Write Binlog Latency Records the latency time of each Pump node writing binlog   Storage Write Binlog Size Shows the size of the binlog data written by Pump   Storage Write Binlog Latency Records the latency time of the Pump storage module writing binlog   Pump Storage Error By Type Records the number of errors encountered by Pump, counted based on the type of error   Query TiKV The number of times that Pump queries the transaction status through TiKV    Drainer monitoring metrics To understand the Drainer monitoring metrics, check the following table:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Monitoring Metrics and Alert Rules</title>
      <link>https://pingcap.com/docs/v2.1/tools/tidb-binlog-monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/tidb-binlog-monitor/</guid>
      <description>TiDB-Binlog Monitoring Metrics and Alert Rules This document describes TiDB-Binlog monitoring metrics in Grafana and explains the alert rules.
Monitoring metrics TiDB-Binlog consists of two components: Pump and Drainer. This section shows the monitoring metrics of Pump and Drainer.
Pump monitoring metrics To understand the Pump monitoring metrics, check the following table:
   Pump monitoring metrics Description     Storage Size Records the total disk space (capacity) and the available disk space (available)   Metadata Records the biggest TSO (gc_tso) of the binlog that each Pump node can delete, and the biggest commit TSO (max_commit_tso) of the saved binlog   Write Binlog QPS by Instance Shows QPS of writing binlog requests received by each Pump node   Write Binlog Latency Records the latency time of each Pump node writing binlog   Storage Write Binlog Size Shows the size of the binlog data written by Pump   Storage Write Binlog Latency Records the latency time of the Pump storage module writing binlog   Pump Storage Error By Type Records the number of errors encountered by Pump, counted based on the type of error   Query TiKV The number of times that Pump queries the transaction status through TiKV    Drainer monitoring metrics To understand the Drainer monitoring metrics, check the following table:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Overview</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/overview/</guid>
      <description>TiDB-Binlog Cluster Overview This document introduces the architecture and the deployment of the cluster version of TiDB-Binlog.
TiDB-Binlog is tool used to collect binlog data from TiDB and provide real-time backup and synchronization to downstream platforms.
TiDB-Binlog has the following features:
 Data synchronization: synchronize the data in the TiDB cluster to other databases Real-time backup and restoration: back up the data in the TiDB cluster and restore the TiDB cluster when the cluster fails  TiDB-Binlog architecture The TiDB-Binlog architecture is as follows:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog Tutorial</title>
      <link>https://pingcap.com/docs/dev/how-to/get-started/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/get-started/tidb-binlog/</guid>
      <description>TiDB-Binlog Tutorial This tutorial starts with a simple TiDB-Binlog deployment with a single node of each component (Placement Driver, TiKV Server, TiDB Server, Pump, and Drainer), set up to push data into a MariaDB Server instance.
This tutorial is targeted toward users who have some familiarity with the TiDB Architecture, who may have already set up a TiDB cluster (not mandatory), and who wants to gain hands-on experience with TiDB-Binlog.</description>
    </item>
    
    <item>
      <title>TiDB-Binlog user guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/tidb-binlog-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-binlog/tidb-binlog-kafka/</guid>
      <description>TiDB-Binlog User Guide This document describes how to deploy the Kafka version of TiDB-Binlog.
About TiDB-Binlog TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases
 Real-time backup and recovery: to back up TiDB cluster data, and recover in case of cluster outages  TiDB-Binlog architecture The TiDB-Binlog architecture is as follows:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog user guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/tidb-binlog-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/tidb-binlog-kafka/</guid>
      <description>TiDB-Binlog User Guide This document describes how to deploy the Kafka version of TiDB-Binlog.
About TiDB-Binlog TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases
 Real-time backup and recovery: to back up TiDB cluster data, and recover in case of cluster outages  TiDB-Binlog architecture The TiDB-Binlog architecture is as follows:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog user guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/tidb-binlog/</guid>
      <description>TiDB-Binlog User Guide About TiDB-Binlog TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases
 Real-time backup and recovery: to back up TiDB cluster data, and recover in case of cluster outages   TiDB-Binlog architecture The TiDB-Binlog architecture is as follows:
The TiDB-Binlog cluster mainly consists of two components:</description>
    </item>
    
    <item>
      <title>TiDB-Lightning CSV Support</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/csv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/csv/</guid>
      <description>TiDB-Lightning CSV Support TiDB-Lightning supports reading CSV (comma-separated values) data source, as well as other delimited format such as TSV (tab-separated values).
File name A CSV file representing a whole table must be named as db_name.table_name.csv. This will be restored as a table table_name inside the database db_name.
If a table spans multiple CSV files, they should be named like db_name.table_name.003.csv.
The file extension must be *.csv, even if the content is not separated by commas.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Checkpoints</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/checkpoints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/checkpoints/</guid>
      <description>TiDB-Lightning Checkpoints Importing a large database usually takes hours or days, and if such long running processes spuriously crashes, it can be very time-wasting to redo the previously completed tasks. To solve this, Lightning uses checkpoints to store the import progress, so that tidb-lightning continues importing from where it lefts off after restarting.
This document describes how to enable, configure, store, and control checkpoints.
Enable and configure checkpoints [checkpoint] # Whether to enable checkpoints.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Checkpoints</title>
      <link>https://pingcap.com/docs/v2.1/tools/lightning/checkpoints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/lightning/checkpoints/</guid>
      <description>TiDB-Lightning Checkpoints Importing a large database usually takes hours or days, and if such long running processes spuriously crashes, it can be very time-wasting to redo the previously completed tasks. To solve this, Lightning uses checkpoints to store the import progress, so that tidb-lightning continues importing from where it lefts off after restarting.
This document describes how to enable, configure, store, and control checkpoints.
Enable and configure checkpoints [checkpoint] # Whether to enable checkpoints.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Deployment</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/deployment/</guid>
      <description>TiDB-Lightning Deployment This document describes the hardware requirements of TiDB-Lightning on separate deployment and mixed deployment, and how to deploy it using Ansible or manually.
Notes Before starting TiDB-Lightning, note that:
 During the import process, the cluster cannot provide normal services. If tidb-lightning crashes, the cluster is left in &amp;ldquo;import mode&amp;rdquo;. Forgetting to switch back to &amp;ldquo;normal mode&amp;rdquo; can lead to a high amount of uncompacted data on the TiKV cluster, and cause abnormally high CPU usage and stall.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Deployment</title>
      <link>https://pingcap.com/docs/v2.1/tools/lightning/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/lightning/deployment/</guid>
      <description>TiDB-Lightning Deployment This document describes the hardware requirements of TiDB-Lightning on separate deployment and mixed deployment, and how to deploy it using Ansible or manually.
Notes Before starting TiDB-Lightning, note that:
 During the import process, the cluster cannot provide normal services. If tidb-lightning crashes, the cluster is left in &amp;ldquo;import mode&amp;rdquo;. Forgetting to switch back to &amp;ldquo;normal mode&amp;rdquo; can lead to a high amount of uncompacted data on the TiKV cluster, and cause abnormally high CPU usage and stall.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning FAQ</title>
      <link>https://pingcap.com/docs/faq/tidb-lightning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/faq/tidb-lightning/</guid>
      <description>TiDB-Lightning FAQ What is the minimum TiDB/TiKV/PD cluster version supported by Lightning? The minimum version is 2.0.9.
Does Lightning support importing multiple schemas (databases)? Yes.
What is the privilege requirements for the target database? Lightning requires the following privileges:
 SELECT UPDATE ALTER CREATE DROP  If the target database is used to store checkpoints, it additionally requires these privileges:
 INSERT DELETE  Lightning encountered an error when importing one table.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning FAQ</title>
      <link>https://pingcap.com/docs/v2.1/tools/lightning/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/lightning/faq/</guid>
      <description>TiDB-Lightning FAQ What is the minimum TiDB/TiKV/PD cluster version supported by Lightning? The minimum version is 2.0.9.
Does Lightning support importing multiple schemas (databases)? Yes.
What is the privilege requirements for the target database? Lightning requires the following privileges:
 SELECT UPDATE ALTER CREATE DROP  If the target database is used to store checkpoints, it additionally requires these privileges:
 INSERT DELETE  Lightning encountered an error when importing one table.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Monitoring</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/monitor/</guid>
      <description>TiDB-Lightning Monitoring Both tidb-lightning and tikv-importer supports metrics collection via Prometheus. This document introduces the monitor configuration and monitoring metrics of TiDB-Lightning.
Monitor configuration  If TiDB-Lightning is installed using TiDB-Ansible, simply add the servers to the [monitored_servers] section in the inventory.ini. Then the Prometheus server can collect their metrics. If TiDB-Lightning is manually installed, follow the instructions below.  tikv-importer tikv-importer v2.1 uses Pushgateway to deliver metrics. Configure tikv-importer.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Monitoring</title>
      <link>https://pingcap.com/docs/v2.1/tools/lightning/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/lightning/monitor/</guid>
      <description>TiDB-Lightning Monitoring Both tidb-lightning and tikv-importer supports metrics collection via Prometheus. This document introduces the monitor configuration and monitoring metrics of TiDB-Lightning.
Monitor configuration  If TiDB-Lightning is installed using TiDB-Ansible, simply add the servers to the [monitored_servers] section in the inventory.ini. Then the Prometheus server can collect their metrics. If TiDB-Lightning is manually installed, follow the instructions below.  tikv-importer tikv-importer v2.1 uses Pushgateway to deliver metrics. Configure tikv-importer.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Overview</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/overview/</guid>
      <description>TiDB-Lightning Overview TiDB-Lightning is a tool used for fast full import of large amounts of data into a TiDB cluster. Currently, TiDB-Lightning supports reading SQL dump exported via mydumper or CSV data source. You can use it in the following two scenarios:
 Importing large amounts of new data quickly Back up and restore all the data  TiDB-Lightning architecture The TiDB-Lightning tool set consists of two components:
 tidb-lightning (the &amp;ldquo;front end&amp;rdquo;) reads the data source and imports the database structure into the TiDB cluster, and also transforms the data into Key-Value (KV) pairs and sends them to tikv-importer.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Overview</title>
      <link>https://pingcap.com/docs/v2.1/tools/lightning/overview-architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/lightning/overview-architecture/</guid>
      <description>TiDB-Lightning Overview TiDB-Lightning is a tool used for fast full import of large amounts of data into a TiDB cluster. Currently, TiDB-Lightning supports reading SQL dump exported via mydumper. You can use it in the following two scenarios:
 Importing large amounts of new data quickly Back up and restore all the data  TiDB-Lightning architecture The TiDB-Lightning tool set consists of two components:
 tidb-lightning (the &amp;ldquo;front end&amp;rdquo;) reads the SQL dump and imports the database structure into the TiDB cluster, and also transforms the data into Key-Value (KV) pairs and sends them to tikv-importer.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Table Filter</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/table-filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tidb-lightning/table-filter/</guid>
      <description>TiDB-Lightning Table Filter TiDB-Lightning supports setting up black and white lists to ignore certain databases and tables. This can be used to skip cache tables, or manually partition the data source on a shared storage to allow multiple Lightning instances work together without interfering each other.
The filtering rule is similar to MySQL replication-rules-db/replication-rules-table.
Filtering databases [black-white-list] do-dbs = [&amp;#34;pattern1&amp;#34;, &amp;#34;pattern2&amp;#34;, &amp;#34;pattern3&amp;#34;] ignore-dbs = [&amp;#34;pattern4&amp;#34;, &amp;#34;pattern5&amp;#34;]  If the do-dbs array in the [black-white-list] section is not empty,  If the name of a database matches any pattern in the do-dbs array, the database is included.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Table Filter</title>
      <link>https://pingcap.com/docs/v2.1/tools/lightning/filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/lightning/filter/</guid>
      <description>TiDB-Lightning Table Filter TiDB-Lightning supports setting up black and white lists to ignore certain databases and tables. This can be used to skip cache tables, or manually partition the data source on a shared storage to allow multiple Lightning instances work together without interfering each other.
The filtering rule is similar to MySQL replication-rules-db/replication-rules-table.
Filtering databases [black-white-list] do-dbs = [&amp;#34;pattern1&amp;#34;, &amp;#34;pattern2&amp;#34;, &amp;#34;pattern3&amp;#34;] ignore-dbs = [&amp;#34;pattern4&amp;#34;, &amp;#34;pattern5&amp;#34;]  If the do-dbs array in the [black-white-list] section is not empty,  If the name of a database matches any pattern in the do-dbs array, the database is included.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Troubleshooting</title>
      <link>https://pingcap.com/docs/dev/how-to/troubleshoot/tidb-lightning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/troubleshoot/tidb-lightning/</guid>
      <description>TiDB-Lightning Troubleshooting When Lightning encounters an unrecoverable error, it exits with nonzero exit code and leaves the reason in the log file. Errors are typically printed at the end of the log. You can also search for the string [error] to look for non-fatal errors.
This document summarizes some commonly encountered errors in the tidb-lightning log file and their solutions.
Import speed is too slow Normally it takes Lightning 2 minutes per thread to import a 256 MB data file.</description>
    </item>
    
    <item>
      <title>TiDB-Lightning Troubleshooting</title>
      <link>https://pingcap.com/docs/v2.1/tools/lightning/errors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/lightning/errors/</guid>
      <description>TiDB-Lightning Troubleshooting When Lightning encounters an unrecoverable error, it exits with nonzero exit code and leaves the reason in the log file. Errors are typically printed at the end of the log. You can also search for the string [error] to look for non-fatal errors.
This document summarizes some commonly encountered errors in the tidb-lightning log file and their solutions.
Import speed is too slow Normally it takes Lightning 2 minutes per thread to import a 256 MB data file.</description>
    </item>
    
    <item>
      <title>TiKV Configuration Flags</title>
      <link>https://pingcap.com/docs/dev/reference/configuration/tikv-server/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/configuration/tikv-server/configuration/</guid>
      <description>TiKV Configuration Flags TiKV supports some readable unit conversions for command line parameters.
 File size (based on byte): KB, MB, GB, TB, PB (or lowercase) Time (based on ms): ms, s, m, h  -A, --addr  The address that the TiKV server monitors Default: &amp;ldquo;127.0.0.1:20160&amp;rdquo; To deploy a cluster, you must use --addr to specify the IP address of the current host, such as &amp;ldquo;192.168.100.113:20160&amp;rdquo;. If the cluster is run on Docker, specify the IP address of Docker as &amp;ldquo;0.</description>
    </item>
    
    <item>
      <title>TiKV Control User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/tikv-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/tikv-control/</guid>
      <description>TiKV Control User Guide TiKV Control (tikv-ctl) is a command line tool of TiKV, used to manage the cluster.
When you compile TiKV, the tikv-ctl command is also compiled at the same time. If the cluster is deployed using Ansible, the tikv-ctl binary file exists in the corresponding tidb-ansible/resources/bin directory. If the cluster is deployed using the binary, the tikv-ctl file is in the bin directory together with other files such as tidb-server, pd-server, tikv-server, etc.</description>
    </item>
    
    <item>
      <title>TiKV Control User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/tikv-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/tikv-control/</guid>
      <description>TiKV Control User Guide TiKV Control (tikv-ctl) is a command line tool of TiKV, used to manage the cluster.
When you compile TiKV, the tikv-ctl command is also compiled at the same time. If the cluster is deployed using Ansible, the tikv-ctl binary file exists in the corresponding tidb-ansible/resources/bin directory. If the cluster is deployed using the binary, the tikv-ctl file is in the bin directory together with other files such as tidb-server, pd-server, tikv-server, etc.</description>
    </item>
    
    <item>
      <title>TiSpark Quick Start Guide</title>
      <link>https://pingcap.com/docs/dev/how-to/deploy/tispark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/deploy/tispark/</guid>
      <description>TiSpark Quick Start Guide To make it easy to try TiSpark, the TiDB cluster installed using TiDB-Ansible integrates Spark, TiSpark jar package and TiSpark sample data by default.
Deployment information  Spark is deployed by default in the spark folder in the TiDB instance deployment directory. The TiSpark jar package is deployed by default in the jars folder in the Spark deployment directory.
spark/jars/tispark-SNAPSHOT-jar-with-dependencies.jar TiSpark sample data and import scripts are deployed by default in the TiDB-Ansible directory.</description>
    </item>
    
    <item>
      <title>TiSpark Quick Start Guide</title>
      <link>https://pingcap.com/docs/tispark/tispark-quick-start-guide_v1.x/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tispark/tispark-quick-start-guide_v1.x/</guid>
      <description>TiSpark Quick Start Guide To make it easy to try TiSpark, the TiDB cluster installed using TiDB-Ansible integrates Spark, TiSpark jar package and TiSpark sample data by default.
Deployment information  Spark is deployed by default in the spark folder in the TiDB instance deployment directory. The TiSpark jar package is deployed by default in the jars folder in the Spark deployment directory.
spark/jars/tispark-SNAPSHOT-jar-with-dependencies.jar TiSpark sample data and import scripts are deployed by default in the TiDB-Ansible directory.</description>
    </item>
    
    <item>
      <title>TiSpark Quick Start Guide</title>
      <link>https://pingcap.com/docs/v2.1/tispark/tispark-quick-start-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tispark/tispark-quick-start-guide/</guid>
      <description>TiSpark Quick Start Guide To make it easy to try TiSpark, the TiDB cluster installed using TiDB-Ansible integrates Spark, TiSpark jar package and TiSpark sample data by default.
Deployment information  Spark is deployed by default in the spark folder in the TiDB instance deployment directory. The TiSpark jar package is deployed by default in the jars folder in the Spark deployment directory.
spark/jars/tispark-SNAPSHOT-jar-with-dependencies.jar TiSpark sample data and import scripts are deployed by default in the TiDB-Ansible directory.</description>
    </item>
    
    <item>
      <title>TiSpark User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tispark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tispark/</guid>
      <description>TiSpark User Guide TiSpark is a thin layer built for running Apache Spark on top of TiDB/TiKV to answer the complex OLAP queries. It takes advantages of both the Spark platform and the distributed TiKV cluster and seamlessly glues to TiDB, the distributed OLTP database, to provide a Hybrid Transactional/Analytical Processing (HTAP) solution to serve as a one-stop solution for both online transactions and analysis.
TiSpark depends on the TiKV cluster and the PD cluster.</description>
    </item>
    
    <item>
      <title>TiSpark User Guide</title>
      <link>https://pingcap.com/docs/tispark/tispark-user-guide_v1.x/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tispark/tispark-user-guide_v1.x/</guid>
      <description>TiSpark User Guide TiSpark is a thin layer built for running Apache Spark on top of TiDB/TiKV to answer the complex OLAP queries. It takes advantages of both the Spark platform and the distributed TiKV cluster and seamlessly glues to TiDB, the distributed OLTP database, to provide a Hybrid Transactional/Analytical Processing (HTAP) solution to serve as a one-stop solution for both online transactions and analysis.
TiSpark depends on the TiKV cluster and the PD cluster.</description>
    </item>
    
    <item>
      <title>TiSpark User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tispark/tispark-user-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tispark/tispark-user-guide/</guid>
      <description>TiSpark User Guide TiSpark is a thin layer built for running Apache Spark on top of TiDB/TiKV to answer the complex OLAP queries. It takes advantages of both the Spark platform and the distributed TiKV cluster and seamlessly glues to TiDB, the distributed OLTP database, to provide a Hybrid Transactional/Analytical Processing (HTAP) solution to serve as a one-stop solution for both online transactions and analysis.
TiSpark depends on the TiKV cluster and the PD cluster.</description>
    </item>
    
    <item>
      <title>Time Zone Support</title>
      <link>https://pingcap.com/docs/dev/how-to/configure/time-zone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/configure/time-zone/</guid>
      <description>Time Zone Support The time zone in TiDB is decided by the global time_zone system variable and the session time_zone system variable. The default value of time_zone is SYSTEM. The actual time zone corresponding to System is configured when the TiDB cluster bootstrap is initialized. The detailed logic is as follows:
 Prioritize the use of the TZ environment variable. If the TZ environment variable fails, extract the time zone from the actual soft link address of /etc/localtime.</description>
    </item>
    
    <item>
      <title>Time Zone Support</title>
      <link>https://pingcap.com/docs/v2.1/sql/time-zone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/time-zone/</guid>
      <description>Time Zone Support The time zone in TiDB is decided by the global time_zone system variable and the session time_zone system variable. The default value of time_zone is SYSTEM. The actual time zone corresponding to System is configured when the TiDB cluster bootstrap is initialized. The detailed logic is as follows:
 Prioritize the use of the TZ environment variable. If the TZ environment variable fails, extract the time zone from the actual soft link address of /etc/localtime.</description>
    </item>
    
    <item>
      <title>Transaction Model</title>
      <link>https://pingcap.com/docs/dev/reference/transactions/transaction-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/transactions/transaction-model/</guid>
      <description>Transaction Model TiDB implements an optimistic transaction model. Unlike MySQL, which uses row-level locking to avoid write conflict, in TiDB, the write conflict is checked only in the commit process during the execution of the statements like Update, Insert, Delete, and so on.
Similarly, functions such as GET_LOCK() and RELEASE_LOCK() and statements such as SELECT .. FOR UPDATE do not work in the same way as in MySQL.
Note: &amp;gt; &amp;gt; On the application side, remember to check the returned results of COMMIT because even there is no error in the execution, there might be errors in the COMMIT process.</description>
    </item>
    
    <item>
      <title>Transactions</title>
      <link>https://pingcap.com/docs/dev/reference/transactions/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/transactions/overview/</guid>
      <description>Transactions TiDB supports distributed transactions. The statements that relate to transactions include the Autocommit variable, START TRANSACTION/BEGIN, COMMIT and ROLLBACK.
Autocommit Syntax:
SET autocommit = {0 | 1} If you set the value of autocommit to 1, the status of the current Session is autocommit. If you set the value of autocommit to 0, the status of the current Session is non-autocommit. The value of autocommit is 1 by default.</description>
    </item>
    
    <item>
      <title>Transactions</title>
      <link>https://pingcap.com/docs/v2.1/sql/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/transaction/</guid>
      <description>Transactions TiDB supports distributed transactions. The statements that relate to transactions include the Autocommit variable, START TRANSACTION/BEGIN, COMMIT and ROLLBACK.
Autocommit Syntax:
SET autocommit = {0 | 1} If you set the value of autocommit to 1, the status of the current Session is autocommit. If you set the value of autocommit to 0, the status of the current Session is non-autocommit. The value of autocommit is 1 by default.</description>
    </item>
    
    <item>
      <title>Troubleshooting Sharding DDL Locks</title>
      <link>https://pingcap.com/docs/v2.1/tools/troubleshooting-sharding-ddl-locks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/troubleshooting-sharding-ddl-locks/</guid>
      <description>Troubleshooting Sharding DDL Locks The Data Migration tool uses a sharding DDL lock to ensure operations are applied in the correct order. This locking mechanism works automatically, but in some abnormal conditions you might need to perform manual operations such as force-releasing the lock.
This document shows how to troubleshoot sharding DDL locks in different abnormal conditions.
The possible causes of an abnormal condition include:
 Some DM-workers go offline A DM-worker restarts (or is unreachable temporarily) DM-master restarts   Warning:</description>
    </item>
    
    <item>
      <title>Try TiDB</title>
      <link>https://pingcap.com/docs/v2.1/try-tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/try-tidb/</guid>
      <description>Try TiDB After you successfully deploy a TiDB cluster, you can run SQL statements in TiDB. Because TiDB is compatible with MySQL, you can use THE MySQL client to connect to TiDB and run MySQL statements directly in most of the cases. For more information, see Compatibility with MySQL.
This page includes some basic SQL statements such as CRUD operations. For a complete list of the statements, see TiDB SQL Syntax Diagram.</description>
    </item>
    
    <item>
      <title>Try Two Types of APIs</title>
      <link>https://pingcap.com/docs/tikv/go-client-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tikv/go-client-api/</guid>
      <description>Try Two Types of APIs To apply to different scenarios, TiKV provides two types of APIs for developers: the Raw Key-Value API and the Transactional Key-Value API. This document uses two examples to guide you through how to use the two APIs in TiKV.
The usage examples are based on the deployment of TiKV using binary files on multiple nodes for test. You can also quickly try the two types of APIs on a single machine.</description>
    </item>
    
    <item>
      <title>Try Two Types of APIs</title>
      <link>https://pingcap.com/docs/v2.1/tikv/go-client-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tikv/go-client-api/</guid>
      <description>Try Two Types of APIs To apply to different scenarios, TiKV provides two types of APIs for developers: the Raw Key-Value API and the Transactional Key-Value API. This document uses two examples to guide you through how to use the two APIs in TiKV.
The usage examples are based on the deployment of TiKV using binary files on multiple nodes for test. You can also quickly try the two types of APIs on a single machine.</description>
    </item>
    
    <item>
      <title>Tune TiKV Performance</title>
      <link>https://pingcap.com/docs/dev/reference/performance/tune-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/performance/tune-tikv/</guid>
      <description>Tune TiKV Performance This document describes how to tune the TiKV parameters for optimal performance.
TiKV uses RocksDB for persistent storage at the bottom level of the TiKV architecture. Therefore, many of the performance parameters are related to RocksDB. TiKV uses two RocksDB instances: the default RocksDB instance stores KV data, the Raft RocksDB instance (RaftDB) stores Raft logs.
TiKV implements Column Families (CF) from RocksDB.
 The default RocksDB instance stores KV data in the default, write and lock CFs.</description>
    </item>
    
    <item>
      <title>Tune TiKV Performance</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/tune-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/tune-tikv/</guid>
      <description>Tune TiKV Performance This document describes how to tune the TiKV parameters for optimal performance.
TiKV uses RocksDB for persistent storage at the bottom level of the TiKV architecture. Therefore, many of the performance parameters are related to RocksDB. TiKV uses two RocksDB instances: the default RocksDB instance stores KV data, the Raft RocksDB instance (RaftDB) stores Raft logs.
TiKV implements Column Families (CF) from RocksDB.
 The default RocksDB instance stores KV data in the default, write and lock CFs.</description>
    </item>
    
    <item>
      <title>Type Conversion in Expression Evaluation</title>
      <link>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/type-conversion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/functions-and-operators/type-conversion/</guid>
      <description>Type Conversion in Expression Evaluation TiDB behaves the same as MySQL: https://dev.mysql.com/doc/refman/5.7/en/type-conversion.html</description>
    </item>
    
    <item>
      <title>Type Conversion in Expression Evaluation</title>
      <link>https://pingcap.com/docs/v2.1/sql/type-conversion-in-expression-evaluation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/type-conversion-in-expression-evaluation/</guid>
      <description>Type Conversion in Expression Evaluation TiDB behaves the same as MySQL: https://dev.mysql.com/doc/refman/5.7/en/type-conversion.html</description>
    </item>
    
    <item>
      <title>UPDATE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/update/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/update/</guid>
      <description>UPDATE The UPDATE statement is used to modify data in a specified table.
Synopsis UpdateStmt:
TableRef:
TableRefs:
AssignmentList:
WhereClauseOptional:
Examples mysql&amp;gt; CREATE TABLE t1 (id INT NOT NULL PRIMARY KEY auto_increment, c1 INT NOT NULL); Query OK, 0 rows affected (0.11 sec) mysql&amp;gt; INSERT INTO t1 (c1) VALUES (1), (2), (3); Query OK, 3 rows affected (0.02 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql&amp;gt; SELECT * FROM t1; +----+----+ | id | c1 | +----+----+ | 1 | 1 | | 2 | 2 | | 3 | 3 | +----+----+ 3 rows in set (0.</description>
    </item>
    
    <item>
      <title>USE | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs/dev/reference/sql/statements/use/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/statements/use/</guid>
      <description>USE The USE statement selects a current database for the user session.
Synopsis UseStmt:
DBName:
Examples mysql&amp;gt; USE mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql&amp;gt; SHOW TABLES; +----------------------+ | Tables_in_mysql | +----------------------+ | GLOBAL_VARIABLES | | bind_info | | columns_priv | | db | | default_roles | | gc_delete_range | | gc_delete_range_done | | help_topic | | role_edges | | stats_buckets | | stats_feedback | | stats_histograms | | stats_meta | | tables_priv | | tidb | | user | +----------------------+ 16 rows in set (0.</description>
    </item>
    
    <item>
      <title>Understand the Query Execution Plan</title>
      <link>https://pingcap.com/docs/dev/reference/performance/understanding-the-query-execution-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/performance/understanding-the-query-execution-plan/</guid>
      <description>Understand the Query Execution Plan Based on the details of your tables, the TiDB optimizer chooses the most efficient query execution plan, which consists of a series of operators. This document details the execution plan information returned by the EXPLAIN statement in TiDB.
Optimize SQL statements using EXPLAIN The result of the EXPLAIN statement provides information about how TiDB executes SQL queries:
 EXPLAIN works together with SELECT, DELETE, INSERT, REPLACE, and UPDATE.</description>
    </item>
    
    <item>
      <title>Understand the Query Execution Plan</title>
      <link>https://pingcap.com/docs/v2.1/sql/understanding-the-query-execution-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/understanding-the-query-execution-plan/</guid>
      <description>Understand the Query Execution Plan Based on the details of your tables, the TiDB optimizer chooses the most efficient query execution plan, which consists of a series of operators. This document details the execution plan information returned by the EXPLAIN statement in TiDB.
Optimize SQL statements using EXPLAIN The result of the EXPLAIN statement provides information about how TiDB executes SQL queries:
 EXPLAIN works together with SELECT, DELETE, INSERT, REPLACE, and UPDATE.</description>
    </item>
    
    <item>
      <title>Upgrade Data Migration</title>
      <link>https://pingcap.com/docs/dev/how-to/upgrade/data-migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/upgrade/data-migration/</guid>
      <description>Upgrade Data Migration This document introduces how to upgrade your Data Migration (DM) version to an incompatible version.
Assuming that V-A, V-B, V-C are three DM versions in chronological order and they are not compatible with each other, you need to upgrade V-A to V-C. Upgrade-A-B means upgrading V-A to V-B and Upgrade-B-C means upgrading V-B to V-C.
 If Upgrade-A-B overlaps with Upgrade-B-C (e.g. different changes of a same configuration item), it is recommended to perform Upgrade-A-B to V-B and then perform Upgrade-B-C to V-C.</description>
    </item>
    
    <item>
      <title>Upgrade Loader or Syncer to Data Migration</title>
      <link>https://pingcap.com/docs/v2.1/tools/upgrade-loader-or-syncer-to-dm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/upgrade-loader-or-syncer-to-dm/</guid>
      <description>Upgrade Loader or Syncer to Data Migration This document introduces how to upgrade Loader or Syncer to DM (Data Migration).
Upgrade Loader to Data Migration Loader is a tool used to load the full data that is dumped from mydumper to TiDB.
When the task-mode of the task DM executes is full, DM automatically uses dumper to dump data and then uses loader to load the data.
To upgrade Loader to DM, perform the following steps:</description>
    </item>
    
    <item>
      <title>Upgrade TiDB Using TiDB-Ansible</title>
      <link>https://pingcap.com/docs/dev/how-to/upgrade/rolling-updates-with-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/how-to/upgrade/rolling-updates-with-ansible/</guid>
      <description>Upgrade TiDB Using TiDB-Ansible When you perform a rolling update for a TiDB cluster, the service is shut down serially and is started after you update the service binary and the configuration file. If the load balancing is configured in the front-end, the rolling update of TiDB does not impact the running applications. Minimum requirements: pd*3, tidb*2, tikv*3.
 Note:
If the binlog is enabled, and Pump and Drainer services are deployed in the TiDB cluster, stop the Drainer service before the rolling update.</description>
    </item>
    
    <item>
      <title>Upgrade TiDB Using TiDB-Ansible</title>
      <link>https://pingcap.com/docs/v2.1/op-guide/ansible-deployment-rolling-update/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/op-guide/ansible-deployment-rolling-update/</guid>
      <description>Upgrade TiDB Using TiDB-Ansible When you perform a rolling update for a TiDB cluster, the service is shut down serially and is started after you update the service binary and the configuration file. If the load balancing is configured in the front-end, the rolling update of TiDB does not impact the running applications. Minimum requirements: pd*3, tidb*2, tikv*3.
 Note:
If the binlog is enabled, and Pump and Drainer services are deployed in the TiDB cluster, stop the Drainer service before the rolling update.</description>
    </item>
    
    <item>
      <title>Use Encrypted Connections</title>
      <link>https://pingcap.com/docs/v2.1/sql/encrypted-connections/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/encrypted-connections/</guid>
      <description>Use Encrypted Connections It is recommended to use the encrypted connection to ensure data security because non-encrypted connection might lead to information leak.
The TiDB server supports the encrypted connection based on the TLS (Transport Layer Security). The protocol is consistent with MySQL encrypted connections and is directly supported by existing MySQL clients such as MySQL operation tools and MySQL drivers. TLS is sometimes referred to as SSL (Secure Sockets Layer).</description>
    </item>
    
    <item>
      <title>User-Defined Variables</title>
      <link>https://pingcap.com/docs/dev/reference/sql/language-structure/user-defined-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/sql/language-structure/user-defined-variables/</guid>
      <description>User-Defined Variables The format of the user-defined variables is @var_name. @var_name consists of alphanumeric characters, _, and $. The user-defined variables are case-insensitive.
The user-defined variables are session specific, which means a user variable defined by one client cannot be seen or used by other clients.
You can use the SET statement to set a user variable:
SET @var_name = expr [, @var_name = expr] ... or
SET @var_name := expr For SET, you can use = or := as the assignment operator.</description>
    </item>
    
    <item>
      <title>User-Defined Variables</title>
      <link>https://pingcap.com/docs/v2.1/sql/user-defined-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/user-defined-variables/</guid>
      <description>User-Defined Variables The format of the user-defined variables is @var_name. @var_name consists of alphanumeric characters, _, and $. The user-defined variables are case-insensitive.
The user-defined variables are session specific, which means a user variable defined by one client cannot be seen or used by other clients.
You can use the SET statement to set a user variable:
SET @var_name = expr [, @var_name = expr] ... or
SET @var_name := expr For SET, you can use = or := as the assignment operator.</description>
    </item>
    
    <item>
      <title>Utility Statements</title>
      <link>https://pingcap.com/docs/v2.1/sql/util/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/sql/util/</guid>
      <description>Utility Statements This document describes the utility statements, including the DESCRIBE, EXPLAIN, and USE statements.
DESCRIBE statement The DESCRIBE and EXPLAIN statements are synonyms, which can also be abbreviated as DESC. See the usage of the EXPLAIN statement.
EXPLAIN statement {EXPLAIN | DESCRIBE | DESC} tbl_name [col_name] {EXPLAIN | DESCRIBE | DESC} [explain_type] explainable_stmt explain_type: FORMAT = format_name format_name: &amp;#34;DOT&amp;#34; explainable_stmt: { SELECT statement | DELETE statement | INSERT statement | REPLACE statement | UPDATE statement } For more information about the EXPLAIN statement, see Understand the Query Execution Plan.</description>
    </item>
    
    <item>
      <title>mydumper Instructions</title>
      <link>https://pingcap.com/docs/dev/reference/tools/mydumper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/mydumper/</guid>
      <description>mydumper Instructions What is mydumper? mydumper is a fork of the mydumper project with additional functionality specific to TiDB. It is the recommended method to use for logical backups of TiDB.
It can be downloaded as part of the Enterprise Tools package.
What enhancements does this contain over regular mydumper?  Uses tidb_snapshot to provide backup consistency instead of FLUSH TABLES WITH READ LOCK
 Allows tidb_snapshot to be configurable (i.</description>
    </item>
    
    <item>
      <title>mydumper Instructions</title>
      <link>https://pingcap.com/docs/v2.1/tools/mydumper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/mydumper/</guid>
      <description>mydumper Instructions What is mydumper? mydumper is a fork of the mydumper project with additional functionality specific to TiDB. It is the recommended method to use for logical backups of TiDB.
Download the Binary.
What enhancements does this contain over regular mydumper?  Uses tidb_snapshot to provide backup consistency instead of FLUSH TABLES WITH READ LOCK
 Allows tidb_snapshot to be configurable (i.e. backup data as it appeared at an earlier point in time)</description>
    </item>
    
    <item>
      <title>sync-diff-inspector User Guide</title>
      <link>https://pingcap.com/docs/dev/reference/tools/sync-diff-inspector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev/reference/tools/sync-diff-inspector/</guid>
      <description>sync-diff-inspector User Guide sync-diff-inspector is a tool used to compare the data that is stored in databases with the MySQL protocol. For example, it can compare the data in MySQL with that in TiDB, the data in MySQL with that in MySQL, or the data in TiDB with that in TiDB. In addition, you can also use this tool to repair data in the scenario where a small amount of data is inconsistent.</description>
    </item>
    
    <item>
      <title>sync-diff-inspector User Guide</title>
      <link>https://pingcap.com/docs/v2.1/tools/sync-diff-inspector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/v2.1/tools/sync-diff-inspector/</guid>
      <description>sync-diff-inspector User Guide sync-diff-inspector is a tool used to compare the data that is stored in databases with the MySQL protocol. For example, it can compare the data in MySQL with that in TiDB, the data in MySQL with that in MySQL, or the data in TiDB with that in TiDB. In addition, you can also use this tool to repair data in the scenario where a small amount of data is inconsistent.</description>
    </item>
    
  </channel>
</rss>